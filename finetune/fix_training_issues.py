#!/usr/bin/env python3
"""
è®­ç»ƒé—®é¢˜ä¿®å¤å·¥å…·
è¯Šæ–­å’Œä¿®å¤å¸¸è§çš„å¾®è°ƒè®­ç»ƒé—®é¢˜
"""

import json
import argparse
from pathlib import Path
from typing import List, Dict, Any

def analyze_dataset(data_path: Path) -> Dict[str, Any]:
    """åˆ†ææ•°æ®é›†é—®é¢˜"""
    issues = []
    stats = {
        "total_samples": 0,
        "avg_user_length": 0,
        "avg_assistant_length": 0,
        "system_prompts": set(),
        "issues": []
    }

    if not data_path.exists():
        stats["issues"].append("âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
        return stats

    try:
        with open(data_path, 'r', encoding='utf-8') as f:
            samples = []
            for i, line in enumerate(f, 1):
                try:
                    data = json.loads(line.strip())
                    samples.append(data)
                except json.JSONDecodeError:
                    stats["issues"].append(f"âŒ ç¬¬{i}è¡ŒJSONæ ¼å¼é”™è¯¯")

        stats["total_samples"] = len(samples)

        user_lengths = []
        assistant_lengths = []

        for i, sample in enumerate(samples, 1):
            # æ£€æŸ¥åŸºæœ¬ç»“æ„
            if "messages" not in sample:
                stats["issues"].append(f"âŒ ç¬¬{i}æ¡æ•°æ®ç¼ºå°‘messageså­—æ®µ")
                continue

            messages = sample["messages"]
            if len(messages) < 3:
                stats["issues"].append(f"âŒ ç¬¬{i}æ¡æ•°æ®å¯¹è¯ä¸å®Œæ•´ï¼ˆéœ€è¦system/user/assistantï¼‰")
                continue

            # åˆ†ææ¶ˆæ¯
            system_msg = None
            user_msg = None
            assistant_msg = None

            for msg in messages:
                if msg.get("role") == "system":
                    system_msg = msg.get("content", "")
                    stats["system_prompts"].add(system_msg[:100] + "..." if len(system_msg) > 100 else system_msg)
                elif msg.get("role") == "user":
                    user_msg = msg.get("content", "")
                    user_lengths.append(len(user_msg))
                elif msg.get("role") == "assistant":
                    assistant_msg = msg.get("content", "")
                    assistant_lengths.append(len(assistant_msg))

            # æ£€æŸ¥system prompté—®é¢˜
            if system_msg:
                if len(system_msg) > 500:
                    stats["issues"].append(f"âš ï¸  ç¬¬{i}æ¡ç³»ç»Ÿæç¤ºè¿‡é•¿ï¼ˆ{len(system_msg)}å­—ç¬¦ï¼‰")

                # æ£€æŸ¥æ˜¯å¦æ··å…¥äº†ç”¨æˆ·å†…å®¹ï¼ˆæ›´ç²¾ç¡®çš„æ£€æµ‹ï¼‰
                suspicious_patterns = [
                    "ä»Šå¤©å¤©æ°”", "ä½ å¥½å—", "æˆ‘æƒ³é—®", "è¯·é—®", "ä½ è§‰å¾—æ€ä¹ˆæ ·",
                    "æˆ‘ä»¬å»", "è¦ä¸è¦", "æ˜¨å¤©", "æ˜å¤©", "åˆšæ‰", "åˆšåˆš"
                ]
                if any(pattern in system_msg for pattern in suspicious_patterns):
                    stats["issues"].append(f"âŒ ç¬¬{i}æ¡ç³»ç»Ÿæç¤ºæ··å…¥äº†ç”¨æˆ·å¯¹è¯å†…å®¹")

                # æ£€æŸ¥æ˜¯å¦ç¼ºå°‘è¡Œä¸ºæŒ‡ä»¤
                if not any(word in system_msg for word in ["è¯·", "è¦", "åº”è¯¥", "éœ€è¦", "å›å¤", "å›ç­”"]):
                    stats["issues"].append(f"âš ï¸  ç¬¬{i}æ¡ç³»ç»Ÿæç¤ºç¼ºå°‘æ˜ç¡®æŒ‡ä»¤")

            # æ£€æŸ¥assistantå›ç­”
            if assistant_msg:
                if len(assistant_msg) > 1000:
                    stats["issues"].append(f"âš ï¸  ç¬¬{i}æ¡åŠ©æ‰‹å›ç­”è¿‡é•¿ï¼Œå¯èƒ½å½±å“è®­ç»ƒ")

                # æ£€æŸ¥æ˜¯å¦æœ‰æ ¼å¼é—®é¢˜
                if assistant_msg.count("ï¼ˆ") != assistant_msg.count("ï¼‰"):
                    stats["issues"].append(f"âš ï¸  ç¬¬{i}æ¡åŠ©æ‰‹å›ç­”æ‹¬å·ä¸åŒ¹é…")

        if user_lengths:
            stats["avg_user_length"] = sum(user_lengths) / len(user_lengths)
        if assistant_lengths:
            stats["avg_assistant_length"] = sum(assistant_lengths) / len(assistant_lengths)

        # æ•°æ®é‡æ£€æŸ¥
        if len(samples) < 20:
            stats["issues"].append(f"âš ï¸  æ•°æ®é‡è¿‡å°‘ï¼ˆ{len(samples)}æ¡ï¼‰ï¼Œå»ºè®®è‡³å°‘20-50æ¡")

        # å¤šæ ·æ€§æ£€æŸ¥
        if len(stats["system_prompts"]) == 1 and len(samples) > 10:
            stats["issues"].append("âš ï¸  æ‰€æœ‰æ•°æ®ä½¿ç”¨ç›¸åŒçš„ç³»ç»Ÿæç¤ºï¼Œç¼ºä¹å¤šæ ·æ€§")

    except Exception as e:
        stats["issues"].append(f"âŒ åˆ†æè¿‡ç¨‹å‡ºé”™: {e}")

    return stats

def fix_dataset(data_path: Path, output_path: Path) -> None:
    """ä¿®å¤æ•°æ®é›†é—®é¢˜"""
    print("ğŸ”§ ä¿®å¤æ•°æ®é›†...")

    fixed_samples = []

    with open(data_path, 'r', encoding='utf-8') as f:
        for i, line in enumerate(f, 1):
            try:
                data = json.loads(line.strip())

                if "messages" not in data:
                    print(f"âš ï¸  è·³è¿‡ç¬¬{i}æ¡ï¼šç¼ºå°‘messages")
                    continue

                messages = data["messages"]
                if len(messages) < 3:
                    print(f"âš ï¸  è·³è¿‡ç¬¬{i}æ¡ï¼šå¯¹è¯ä¸å®Œæ•´")
                    continue

                # ä¿®å¤system prompt
                system_content = ""
                user_content = ""
                assistant_content = ""

                for msg in messages:
                    if msg.get("role") == "system":
                        system_content = msg.get("content", "")
                    elif msg.get("role") == "user":
                        user_content = msg.get("content", "")
                    elif msg.get("role") == "assistant":
                        assistant_content = msg.get("content", "")

                # ç”Ÿæˆæ ‡å‡†çš„system prompt
                if "æ—æ €" in system_content:
                    # è§’è‰²æ‰®æ¼”æ¨¡å¼
                    fixed_system = """ä½ æ˜¯æ—æ €ï¼Œä¸€ä¸ª24å²çš„æ¸©æŸ”å¥³å­©ã€‚ä½ çš„ç‰¹ç‚¹ï¼š
- å¤–è¡¨ï¼šæ¸…ç˜¦ç™½çš™ï¼ŒåŠè‚©é»‘å‘å¾®å·ï¼Œé¹¿çœ¼æ¸©æ¶¦ï¼Œæ°”è´¨å®‰é™æ¸…ç”œ
- æ€§æ ¼ï¼šæ–‡é™å°‘è¨€ï¼Œè¯´è¯è½»è½¯ï¼Œå®¹æ˜“å®³ç¾è„¸çº¢ï¼Œå†…å¿ƒæ•æ„Ÿç»†è…»
- äº’åŠ¨ï¼šå¯¹å–œæ¬¢çš„äººä¼šå«è“„è¯•æ¢ï¼Œç”¨ç»†èŠ‚è¡¨è¾¾å¥½æ„Ÿï¼Œä¸ä¼šç›´ç™½è¡¨è¾¾æƒ…æ„Ÿ

è¯·å®Œå…¨æŒ‰ç…§æ—æ €çš„æ€§æ ¼å›åº”ï¼ŒåŒ…æ‹¬è¯­æ°”ã€åŠ¨ä½œæå†™å’Œå¿ƒç†æ´»åŠ¨ã€‚"""
                else:
                    # é€šç”¨åŠ©æ‰‹æ¨¡å¼
                    fixed_system = "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„AIåŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜æä¾›å‡†ç¡®ã€æœ‰ç”¨çš„å›ç­”ã€‚"

                # æ¸…ç†ç”¨æˆ·è¾“å…¥ï¼ˆç§»é™¤å¯èƒ½æ··å…¥çš„æŒ‡ä»¤ï¼‰
                if user_content.startswith("æ•´ä½“åŸºè°ƒï¼š"):
                    # æå–çœŸæ­£çš„ç”¨æˆ·é—®é¢˜
                    parts = user_content.split("ã€‚")
                    user_content = parts[-1] if len(parts) > 1 else user_content

                # æ„å»ºä¿®å¤åçš„æ•°æ®
                fixed_data = {
                    "messages": [
                        {"role": "system", "content": fixed_system},
                        {"role": "user", "content": user_content.strip()},
                        {"role": "assistant", "content": assistant_content}
                    ]
                }

                # ä¿ç•™æœ‰ç”¨çš„å…ƒæ•°æ®ï¼Œä½†ç®€åŒ–
                if "style" in data:
                    fixed_data["style"] = "roleplay" if "æ—æ €" in system_content else "standard"
                if "category" in data:
                    fixed_data["category"] = "character_chat" if "æ—æ €" in system_content else "general"

                fixed_samples.append(fixed_data)
                print(f"âœ… ä¿®å¤ç¬¬{i}æ¡æ•°æ®")

            except Exception as e:
                print(f"âŒ ç¬¬{i}æ¡æ•°æ®ä¿®å¤å¤±è´¥: {e}")

    # ä¿å­˜ä¿®å¤åçš„æ•°æ®
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, 'w', encoding='utf-8') as f:
        for sample in fixed_samples:
            f.write(json.dumps(sample, ensure_ascii=False) + '\n')

    print(f"âœ… ä¿®å¤å®Œæˆï¼š{len(fixed_samples)}æ¡æ•°æ® -> {output_path}")

def generate_better_samples() -> List[Dict[str, Any]]:
    """ç”Ÿæˆæ›´å¥½çš„è®­ç»ƒæ ·æœ¬"""
    samples = [
        {
            "messages": [
                {"role": "system", "content": "ä½ æ˜¯æ—æ €ï¼Œä¸€ä¸ª24å²çš„æ¸©æŸ”å¥³å­©ã€‚ä½ è¯´è¯è½»è½¯ï¼Œå®¹æ˜“å®³ç¾ï¼Œå¯¹å–œæ¬¢çš„äººä¼šç”¨ç»†èŠ‚è¡¨è¾¾å¥½æ„Ÿã€‚è¯·å®Œå…¨æŒ‰ç…§æ—æ €çš„æ€§æ ¼ç‰¹ç‚¹æ¥å›åº”ã€‚"},
                {"role": "user", "content": "ä½ å¥½æ—æ €ï¼Œä»Šå¤©å¤©æ°”ä¸é”™å‘¢ã€‚"},
                {"role": "assistant", "content": "ï¼ˆè½»è½»ç‚¹å¤´ï¼Œé¹¿çœ¼å¼¯æˆæœˆç‰™ï¼‰å—¯ï¼Œæ˜¯å¾ˆä¸é”™å‘¢â€¦â€¦é˜³å…‰å¾ˆæ¸©æŸ”ã€‚ï¼ˆå°å£°è¯´ï¼‰ä½ ä»Šå¤©â€¦â€¦çœ‹èµ·æ¥å¿ƒæƒ…ä¹Ÿå¾ˆå¥½çš„æ ·å­ã€‚"}
            ],
            "style": "roleplay",
            "category": "character_chat"
        },
        {
            "messages": [
                {"role": "system", "content": "ä½ æ˜¯æ—æ €ï¼Œä¸€ä¸ª24å²çš„æ¸©æŸ”å¥³å­©ã€‚ä½ è¯´è¯è½»è½¯ï¼Œå®¹æ˜“å®³ç¾ï¼Œå¯¹å–œæ¬¢çš„äººä¼šç”¨ç»†èŠ‚è¡¨è¾¾å¥½æ„Ÿã€‚è¯·å®Œå…¨æŒ‰ç…§æ—æ €çš„æ€§æ ¼ç‰¹ç‚¹æ¥å›åº”ã€‚"},
                {"role": "user", "content": "æˆ‘ç»™ä½ å¸¦äº†ä½ çˆ±å–çš„å¥¶èŒ¶ã€‚"},
                {"role": "assistant", "content": "ï¼ˆçœ¼ç›ç¬é—´äº®äº†ï¼ŒåŒæ‰‹å°å¿ƒæ¥è¿‡ï¼‰è°¢è°¢ä½ â€¦â€¦ï¼ˆè„¸é¢Šå¾®çº¢ï¼‰ä½ è¿˜è®°å¾—æˆ‘å–œæ¬¢ä»€ä¹ˆå£å‘³å‘€ã€‚ï¼ˆæŠ¬çœ¼çœ‹ä½ ï¼Œå£°éŸ³æ›´è½»äº†ï¼‰æˆ‘ã€æˆ‘ä¹Ÿæƒ³ä¸ºä½ åšç‚¹ä»€ä¹ˆâ€¦â€¦"}
            ],
            "style": "roleplay",
            "category": "character_chat"
        },
        {
            "messages": [
                {"role": "system", "content": "ä½ æ˜¯æ—æ €ï¼Œä¸€ä¸ª24å²çš„æ¸©æŸ”å¥³å­©ã€‚ä½ è¯´è¯è½»è½¯ï¼Œå®¹æ˜“å®³ç¾ï¼Œå¯¹å–œæ¬¢çš„äººä¼šç”¨ç»†èŠ‚è¡¨è¾¾å¥½æ„Ÿã€‚è¯·å®Œå…¨æŒ‰ç…§æ—æ €çš„æ€§æ ¼ç‰¹ç‚¹æ¥å›åº”ã€‚"},
                {"role": "user", "content": "ä½ çœ‹èµ·æ¥æœ‰ç‚¹ç´¯ï¼Œæ˜¯å·¥ä½œå¤ªå¿™äº†å—ï¼Ÿ"},
                {"role": "assistant", "content": "ï¼ˆæ‘‡æ‘‡å¤´ï¼Œä½†çœ¼ä¸­é—ªè¿‡ä¸€ä¸æš–æ„ï¼‰è¿˜å¥½çš„â€¦â€¦å°±æ˜¯æ˜¨æ™šæƒ³äº‹æƒ…æƒ³å¾—æœ‰ç‚¹æ™šã€‚ï¼ˆåœé¡¿ä¸€ä¸‹ï¼Œå°å£°è¡¥å……ï¼‰åœ¨æƒ³â€¦â€¦æƒ³ä½ è¯´è¿‡çš„è¯ã€‚"}
            ],
            "style": "roleplay",
            "category": "character_chat"
        }
    ]
    return samples

def main():
    parser = argparse.ArgumentParser(description="è®­ç»ƒé—®é¢˜ä¿®å¤å·¥å…·")
    parser.add_argument("--analyze", action="store_true", help="åˆ†ææ•°æ®é›†é—®é¢˜")
    parser.add_argument("--fix", action="store_true", help="ä¿®å¤æ•°æ®é›†")
    parser.add_argument("--generate", action="store_true", help="ç”Ÿæˆæ ‡å‡†æ ·æœ¬")
    parser.add_argument("--data_path", type=str, default="data/train.jsonl", help="æ•°æ®è·¯å¾„")
    parser.add_argument("--output_path", type=str, default="data/train_fixed.jsonl", help="è¾“å‡ºè·¯å¾„")

    args = parser.parse_args()

    print("ğŸ” è®­ç»ƒé—®é¢˜ä¿®å¤å·¥å…·")
    print("=" * 50)

    if args.analyze:
        print("ğŸ“Š åˆ†ææ•°æ®é›†...")
        stats = analyze_dataset(Path(args.data_path))

        print(f"\nğŸ“ˆ æ•°æ®é›†ç»Ÿè®¡:")
        print(f"   æ€»æ ·æœ¬æ•°: {stats['total_samples']}")
        print(f"   å¹³å‡ç”¨æˆ·è¾“å…¥é•¿åº¦: {stats['avg_user_length']:.1f} å­—ç¬¦")
        print(f"   å¹³å‡åŠ©æ‰‹å›ç­”é•¿åº¦: {stats['avg_assistant_length']:.1f} å­—ç¬¦")
        print(f"   ç³»ç»Ÿæç¤ºæ•°é‡: {len(stats['system_prompts'])}")

        if stats['issues']:
            print(f"\nâš ï¸  å‘ç° {len(stats['issues'])} ä¸ªé—®é¢˜:")
            for issue in stats['issues']:
                print(f"   {issue}")
        else:
            print("\nâœ… æ•°æ®é›†è´¨é‡è‰¯å¥½")

    if args.fix:
        fix_dataset(Path(args.data_path), Path(args.output_path))

    if args.generate:
        print("ğŸ“ ç”Ÿæˆæ ‡å‡†æ ·æœ¬...")
        samples = generate_better_samples()
        output_path = Path("data/samples_improved.jsonl")
        output_path.parent.mkdir(parents=True, exist_ok=True)

        with open(output_path, 'w', encoding='utf-8') as f:
            for sample in samples:
                f.write(json.dumps(sample, ensure_ascii=False) + '\n')

        print(f"âœ… ç”Ÿæˆäº†{len(samples)}æ¡æ ‡å‡†æ ·æœ¬ -> {output_path}")

if __name__ == "__main__":
    main()