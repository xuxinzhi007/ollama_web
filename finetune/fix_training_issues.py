#!/usr/bin/env python3
"""
è®­ç»ƒé—®é¢˜è¯Šæ–­å’Œä¿®å¤è„šæœ¬
è§£å†³ï¼š
1. Lossé‡ç½®é—®é¢˜ï¼ˆç»§ç»­è®­ç»ƒæ—¶epochè®¡ç®—é”™è¯¯ï¼‰
2. æ¨¡å‹æ•ˆæœå·®ï¼ˆæ•°æ®æ ¼å¼ã€å‚æ•°ä¼˜åŒ–ï¼‰
"""

import json
import sys
from pathlib import Path

def check_data_format(data_file):
    """æ£€æŸ¥æ•°æ®æ ¼å¼"""
    print(f"\næ£€æŸ¥æ•°æ®æ ¼å¼: {data_file}")
    issues = []
    
    with open(data_file, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    print(f"æ€»æ ·æœ¬æ•°: {len(lines)}")
    
    # æ£€æŸ¥å‰å‡ ä¸ªæ ·æœ¬
    for i, line in enumerate(lines[:5]):
        try:
            data = json.loads(line.strip())
            messages = data.get('messages', [])
            
            # æ£€æŸ¥æ˜¯å¦æœ‰system message
            has_system = any(msg.get('role') == 'system' for msg in messages)
            if not has_system:
                issues.append(f"æ ·æœ¬ {i+1}: ç¼ºå°‘system message")
            
            # æ£€æŸ¥system messageæ˜¯å¦é‡å¤
            system_count = sum(1 for msg in messages if msg.get('role') == 'system')
            if system_count > 1:
                issues.append(f"æ ·æœ¬ {i+1}: æœ‰å¤šä¸ªsystem message")
            
            # æ£€æŸ¥æ¶ˆæ¯æ ¼å¼
            if len(messages) < 2:
                issues.append(f"æ ·æœ¬ {i+1}: æ¶ˆæ¯æ•°é‡ä¸è¶³ï¼ˆè‡³å°‘éœ€è¦userå’Œassistantï¼‰")
            
        except json.JSONDecodeError as e:
            issues.append(f"æ ·æœ¬ {i+1}: JSONæ ¼å¼é”™è¯¯ - {e}")
    
    if issues:
        print("âš ï¸  å‘ç°é—®é¢˜:")
        for issue in issues:
            print(f"  - {issue}")
    else:
        print("âœ… æ•°æ®æ ¼å¼æ£€æŸ¥é€šè¿‡")
    
    return len(issues) == 0

def optimize_training_params():
    """ä¼˜åŒ–è®­ç»ƒå‚æ•°å»ºè®®"""
    print("\nğŸ“Š è®­ç»ƒå‚æ•°ä¼˜åŒ–å»ºè®®:")
    print("=" * 50)
    
    print("\nå½“å‰é…ç½®é—®é¢˜:")
    print("1. LoRA rank=32 å¯èƒ½è¿‡å¤§ï¼Œå®¹æ˜“è¿‡æ‹Ÿåˆ")
    print("2. å­¦ä¹ ç‡ 1e-4 å¯èƒ½åé«˜ï¼Œå»ºè®®é™ä½")
    print("3. æ¯ä¸ªæ ·æœ¬éƒ½é‡å¤system promptï¼Œå¯èƒ½å¯¼è‡´è¿‡åº¦å…³æ³¨")
    
    print("\næ¨èé…ç½®:")
    print("- LoRA rank: 16 (é™ä½è¿‡æ‹Ÿåˆé£é™©)")
    print("- LoRA alpha: 32 (ä¿æŒalpha=2*rank)")
    print("- Learning rate: 5e-5 (æ›´ç¨³å®šçš„å­¦ä¹ )")
    print("- Epochs: 3-5 (æ ¹æ®lossæ›²çº¿è°ƒæ•´)")
    print("- Dropout: 0.1 (ä¿æŒä¸å˜)")
    
    print("\næ•°æ®ä¼˜åŒ–å»ºè®®:")
    print("- è€ƒè™‘ç§»é™¤æ¯ä¸ªæ ·æœ¬ä¸­çš„system messageï¼Œç»Ÿä¸€åœ¨Modelfileä¸­è®¾ç½®")
    print("- æˆ–è€…åªåœ¨ç¬¬ä¸€ä¸ªæ ·æœ¬ä¿ç•™system message")

def check_checkpoint_resume():
    """æ£€æŸ¥checkpointç»­è®­é—®é¢˜"""
    print("\nğŸ” æ£€æŸ¥checkpointç»­è®­é—®é¢˜:")
    print("=" * 50)
    
    print("\né—®é¢˜åˆ†æ:")
    print("å½“ä½¿ç”¨ --resume_from_checkpoint ç»§ç»­è®­ç»ƒæ—¶ï¼š")
    print("- num_train_epochs å‚æ•°æ˜¯æ€»epochsæ•°ï¼Œä¸æ˜¯å‰©ä½™epochsæ•°")
    print("- å¦‚æœä¹‹å‰è®­ç»ƒäº†0.71ä¸ªepochï¼Œè®¾ç½®epochs=5.0ï¼Œä¼šé‡æ–°å¼€å§‹è®­ç»ƒ")
    print("- è¿™å¯¼è‡´lossä»åˆå§‹å€¼é‡æ–°å¼€å§‹")
    
    print("\nè§£å†³æ–¹æ¡ˆ:")
    print("1. ç»§ç»­è®­ç»ƒæ—¶ï¼Œåº”è¯¥è®¡ç®—å‰©ä½™epochsæ•°")
    print("2. æˆ–è€…ä½¿ç”¨ --resume_from_checkpoint æ—¶ï¼Œä¸è®¾ç½®epochså‚æ•°")
    print("3. è®©è®­ç»ƒè„šæœ¬è‡ªåŠ¨ä»checkpointæ¢å¤è®­ç»ƒçŠ¶æ€")

def main():
    print("ğŸ”§ è®­ç»ƒé—®é¢˜è¯Šæ–­å·¥å…·")
    print("=" * 50)
    
    # æ£€æŸ¥æ•°æ®æ ¼å¼
    train_file = Path("datasets/linzhi/train.jsonl")
    if train_file.exists():
        check_data_format(train_file)
    else:
        print(f"âš ï¸  è®­ç»ƒæ–‡ä»¶ä¸å­˜åœ¨: {train_file}")
    
    # ä¼˜åŒ–å»ºè®®
    optimize_training_params()
    
    # checkpointé—®é¢˜
    check_checkpoint_resume()
    
    print("\n" + "=" * 50)
    print("âœ… è¯Šæ–­å®Œæˆ")

if __name__ == "__main__":
    main()
