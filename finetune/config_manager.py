#!/usr/bin/env python3
"""
é…ç½®ç®¡ç†å·¥å…· - è¯»å–å’Œç®¡ç†è®­ç»ƒå‚æ•°
"""

import yaml
import json
from pathlib import Path
from typing import Dict, Any

class ConfigManager:
    def __init__(self, config_path: str = "config.yaml"):
        self.config_path = Path(config_path)
        self.config = self.load_config()

    def load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        if not self.config_path.exists():
            print(f"âš ï¸  é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.config_path}")
            print("ğŸ’¡ ä½¿ç”¨é»˜è®¤é…ç½®")
            return self.get_default_config()

        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            print(f"âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ: {self.config_path}")
            return config
        except Exception as e:
            print(f"âŒ é…ç½®æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
            print("ğŸ’¡ ä½¿ç”¨é»˜è®¤é…ç½®")
            return self.get_default_config()

    def get_default_config(self) -> Dict[str, Any]:
        """é»˜è®¤é…ç½®"""
        return {
            "model": {
                "base_model": "Qwen/Qwen2.5-0.5B-Instruct",
                "model_type": "qwen"
            },
            "training": {
                "epochs": 2.0,
                "learning_rate": 2e-4,
                "warmup_ratio": 0.03,
                "weight_decay": 0.0,
                "seed": 42
            },
            "lora": {
                "rank": 8,
                "alpha": 16,
                "dropout": 0.05
            },
            "data": {
                "max_seq_length": 0,
                "batch_size": 0,
                "gradient_accumulation": 0
            },
            "logging": {
                "logging_steps": 10,
                "save_steps": 200,
                "eval_steps": 200
            },
            "ollama": {
                "temperature": 0.7,
                "top_p": 0.9,
                "top_k": 40,
                "repeat_penalty": 1.05,
                "context_length": 4096
            },
            "advanced": {
                "gradient_checkpointing": False,
                "no_eval": False,
                "report_to": "none"
            }
        }

    def get(self, key_path: str, default=None):
        """è·å–é…ç½®å€¼ (æ”¯æŒåµŒå¥—è·¯å¾„ï¼Œå¦‚ 'model.base_model')"""
        keys = key_path.split('.')
        value = self.config

        for key in keys:
            if isinstance(value, dict) and key in value:
                value = value[key]
            else:
                return default

        return value

    def get_training_args(self) -> Dict[str, Any]:
        """è·å–è®­ç»ƒå‚æ•° (ç”¨äº train_lora.py)"""
        return {
            "model_name_or_path": self.get("model.base_model"),
            "num_train_epochs": self.get("training.epochs"),
            "learning_rate": self.get("training.learning_rate"),
            "warmup_ratio": self.get("training.warmup_ratio"),
            "weight_decay": self.get("training.weight_decay"),
            "seed": self.get("training.seed"),
            "lora_r": self.get("lora.rank"),
            "lora_alpha": self.get("lora.alpha"),
            "lora_dropout": self.get("lora.dropout"),
            "max_seq_length": self.get("data.max_seq_length"),
            "per_device_train_batch_size": self.get("data.batch_size"),
            "gradient_accumulation_steps": self.get("data.gradient_accumulation"),
            "logging_steps": self.get("logging.logging_steps"),
            "save_steps": self.get("logging.save_steps"),
            "eval_steps": self.get("logging.eval_steps"),
            "gradient_checkpointing": self.get("advanced.gradient_checkpointing"),
            "no_eval": self.get("advanced.no_eval"),
            "report_to": self.get("advanced.report_to")
        }

    def get_ollama_params(self) -> Dict[str, Any]:
        """è·å– Ollama å‚æ•° (ç”¨äº Modelfile)"""
        return {
            "temperature": self.get("ollama.temperature"),
            "top_p": self.get("ollama.top_p"),
            "top_k": self.get("ollama.top_k"),
            "repeat_penalty": self.get("ollama.repeat_penalty"),
            "num_ctx": self.get("ollama.context_length")
        }

    def show_config(self):
        """æ˜¾ç¤ºå½“å‰é…ç½®"""
        print("\nğŸ“‹ å½“å‰é…ç½®:")
        print("=" * 50)
        print(f"ğŸ¤– åŸºç¡€æ¨¡å‹: {self.get('model.base_model')}")
        print(f"ğŸ”„ è®­ç»ƒè½®æ•°: {self.get('training.epochs')}")
        print(f"ğŸ“Š å­¦ä¹ ç‡: {self.get('training.learning_rate')}")
        print(f"ğŸ”§ LoRA rank: {self.get('lora.rank')}")
        print(f"ğŸ”§ LoRA alpha: {self.get('lora.alpha')}")
        print(f"ğŸŒ¡ï¸  æ¸©åº¦: {self.get('ollama.temperature')}")
        print("=" * 50)

    def save_model_config(self, merged_dir: Path, model_name: str, actual_args: Dict = None):
        """ä¿å­˜æ¨¡å‹ä¸“ç”¨é…ç½®åˆ°æ¨¡å‹ç›®å½•"""
        model_config = {
            "model_name": model_name,
            "base_model": self.get("model.base_model"),
            "config_snapshot": self.config.copy(),
            "ollama_params": self.get_ollama_params()
        }

        # å¦‚æœæœ‰å®é™…ä½¿ç”¨çš„å‚æ•°ï¼Œä¹Ÿä¿å­˜
        if actual_args:
            model_config["actual_training_args"] = actual_args

        config_file = merged_dir / "model_config.json"
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(model_config, f, indent=2, ensure_ascii=False)

        print(f"ğŸ’¾ æ¨¡å‹é…ç½®å·²ä¿å­˜åˆ°: {config_file}")

def load_config(config_path: str = "config.yaml") -> ConfigManager:
    """å¿«æ·åŠ è½½é…ç½®"""
    return ConfigManager(config_path)

if __name__ == "__main__":
    # æµ‹è¯•é…ç½®ç®¡ç†å™¨
    config = ConfigManager()
    config.show_config()

    print("\nğŸ”§ è®­ç»ƒå‚æ•°:")
    training_args = config.get_training_args()
    for key, value in training_args.items():
        print(f"  {key}: {value}")