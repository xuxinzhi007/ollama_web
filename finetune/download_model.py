#!/usr/bin/env python3
"""
æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹è„šæœ¬ - æ˜¾ç¤ºçœŸå®ä¸‹è½½è¿›åº¦
"""
import os
from huggingface_hub import snapshot_download
from tqdm import tqdm
import requests
from pathlib import Path

def download_qwen_model():
    """ä¸‹è½½ Qwen2.5-0.5B æ¨¡å‹"""
    model_name = "Qwen/Qwen2.5-0.5B"

    print(f"ğŸš€ å¼€å§‹ä¸‹è½½æ¨¡å‹: {model_name}")
    print("ğŸ“ æ¨¡å‹å°†ä¿å­˜åˆ° HuggingFace ç¼“å­˜ç›®å½•")
    print("ğŸ’¡ ä¸‹è½½å®Œæˆåå¯ä»¥ç¦»çº¿ä½¿ç”¨")
    print("-" * 50)

    try:
        # ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°ç¼“å­˜
        local_path = snapshot_download(
            repo_id=model_name,
            resume_download=True,  # æ”¯æŒæ–­ç‚¹ç»­ä¼ 
            local_files_only=False,  # å…è®¸ç½‘ç»œä¸‹è½½
        )

        print(f"âœ… æ¨¡å‹ä¸‹è½½å®Œæˆï¼")
        print(f"ğŸ“ æ¨¡å‹è·¯å¾„: {local_path}")
        return local_path

    except Exception as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
        return None

def check_model_cache():
    """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ç¼“å­˜"""
    from transformers import AutoTokenizer
    model_name = "Qwen/Qwen2.5-0.5B"

    try:
        # å°è¯•åŠ è½½ tokenizer æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²å­˜åœ¨
        tokenizer = AutoTokenizer.from_pretrained(model_name, local_files_only=True)
        print(f"âœ… æ¨¡å‹å·²ç¼“å­˜ï¼Œæ— éœ€é‡æ–°ä¸‹è½½")
        return True
    except Exception:
        print(f"ğŸ“¥ æ¨¡å‹æœªç¼“å­˜ï¼Œéœ€è¦ä¸‹è½½")
        return False

if __name__ == "__main__":
    print("ğŸ” æ£€æŸ¥æ¨¡å‹ç¼“å­˜çŠ¶æ€...")

    if not check_model_cache():
        print("\nå¼€å§‹ä¸‹è½½...")
        download_qwen_model()

    print("\nğŸ‰ æ¨¡å‹å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥å¼€å§‹è®­ç»ƒï¼")