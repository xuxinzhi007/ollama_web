#!/usr/bin/env python3
"""
åˆå¹¶å®‰å…¨æ€§éªŒè¯è„šæœ¬
éªŒè¯åˆå¹¶å‰åè®­ç»ƒå‚æ•°å’Œæµç¨‹çš„ä¸€è‡´æ€§ï¼Œç¡®ä¿ä¸å½±å“æ¨¡å‹è®­ç»ƒè´¨é‡
"""

import sys
import json
from pathlib import Path
from typing import Dict, Any, List, Tuple

# ç¡®ä¿èƒ½å¯¼å…¥ config_manager
sys.path.append(str(Path(__file__).parent))

from config_manager import ConfigManager

class MergeSafetyValidator:
    def __init__(self):
        self.root_dir = Path(__file__).parent
        self.issues = []

    def log_issue(self, level: str, message: str):
        """è®°å½•éªŒè¯é—®é¢˜"""
        self.issues.append({"level": level, "message": message})
        symbol = {"INFO": "ğŸ’¡", "WARNING": "âš ï¸", "ERROR": "âŒ"}
        print(f"{symbol.get(level, 'ğŸ“')} {level}: {message}")

    def validate_config_parameter_mapping(self) -> bool:
        """éªŒè¯é…ç½®å‚æ•°æ˜ å°„çš„æ­£ç¡®æ€§"""
        print("\nğŸ” éªŒè¯é…ç½®å‚æ•°æ˜ å°„...")

        try:
            # æµ‹è¯•è§’è‰²é…ç½®è¯»å–
            config_char = ConfigManager(character="linzhi")

            # å…³é”®è®­ç»ƒå‚æ•°æ£€æŸ¥
            critical_params = {
                'model.base_model': ('åŸºç¡€æ¨¡å‹', 'Qwen/Qwen2.5-0.5B-Instruct'),
                'training.epochs': ('è®­ç»ƒè½®æ•°', float),
                'training.learning_rate': ('å­¦ä¹ ç‡', float),
                'lora.rank': ('LoRA rank', int),
                'lora.alpha': ('LoRA alpha', int),
                'lora.dropout': ('LoRA dropout', float),
            }

            all_params_valid = True

            for param_path, (desc, expected_type) in critical_params.items():
                value = config_char.get(param_path)

                if value is None:
                    self.log_issue("ERROR", f"å…³é”®å‚æ•°ç¼ºå¤±: {desc} ({param_path})")
                    all_params_valid = False
                    continue

                # ç±»å‹æ£€æŸ¥
                if expected_type == str:
                    if not isinstance(value, str):
                        self.log_issue("ERROR", f"å‚æ•°ç±»å‹é”™è¯¯: {desc} åº”ä¸ºå­—ç¬¦ä¸²ï¼Œå®é™…ä¸º {type(value)}")
                        all_params_valid = False
                elif expected_type in [int, float]:
                    if not isinstance(value, (int, float)):
                        self.log_issue("ERROR", f"å‚æ•°ç±»å‹é”™è¯¯: {desc} åº”ä¸ºæ•°å­—ï¼Œå®é™…ä¸º {type(value)}")
                        all_params_valid = False
                else:  # ç‰¹å®šå€¼æ£€æŸ¥
                    if value != expected_type:
                        self.log_issue("WARNING", f"å‚æ•°å€¼å¼‚å¸¸: {desc} = {value}ï¼ŒæœŸæœ› {expected_type}")

                print(f"   âœ… {desc}: {value}")

            return all_params_valid

        except Exception as e:
            self.log_issue("ERROR", f"é…ç½®å‚æ•°éªŒè¯å¤±è´¥: {e}")
            return False

    def validate_training_args_generation(self) -> bool:
        """éªŒè¯è®­ç»ƒå‚æ•°ç”Ÿæˆçš„æ­£ç¡®æ€§"""
        print("\nğŸ” éªŒè¯è®­ç»ƒå‚æ•°ç”Ÿæˆ...")

        try:
            config_char = ConfigManager(character="linzhi")
            training_args = config_char.get_training_args()

            # æ£€æŸ¥å¿…è¦çš„è®­ç»ƒå‚æ•°
            required_args = [
                'model_name_or_path', 'num_train_epochs', 'learning_rate',
                'lora_r', 'lora_alpha', 'lora_dropout'
            ]

            missing_args = []
            for arg in required_args:
                if arg not in training_args or training_args[arg] is None:
                    missing_args.append(arg)

            if missing_args:
                self.log_issue("ERROR", f"è®­ç»ƒå‚æ•°ç¼ºå¤±: {missing_args}")
                return False

            # æ˜¾ç¤ºç”Ÿæˆçš„è®­ç»ƒå‚æ•°
            print("   ç”Ÿæˆçš„è®­ç»ƒå‚æ•°:")
            for key, value in training_args.items():
                if value is not None:
                    print(f"      {key}: {value}")

            self.log_issue("INFO", "è®­ç»ƒå‚æ•°ç”ŸæˆéªŒè¯é€šè¿‡")
            return True

        except Exception as e:
            self.log_issue("ERROR", f"è®­ç»ƒå‚æ•°ç”ŸæˆéªŒè¯å¤±è´¥: {e}")
            return False

    def simulate_training_command(self, character: str) -> Tuple[bool, List[str]]:
        """æ¨¡æ‹Ÿè®­ç»ƒå‘½ä»¤ç”Ÿæˆï¼ˆä¸å®é™…æ‰§è¡Œï¼‰"""
        print(f"\nğŸ” æ¨¡æ‹Ÿ {character} çš„è®­ç»ƒå‘½ä»¤ç”Ÿæˆ...")

        try:
            # æ¨¡æ‹Ÿ smart_train.py çš„å‘½ä»¤ç”Ÿæˆé€»è¾‘
            config = ConfigManager(character=character)

            # è·å–è®­ç»ƒå‚æ•°
            training_params = config.config.get('characters', {}).get(character, {}).get('training_params', {})

            # æ„å»ºæ¨¡æ‹Ÿå‘½ä»¤
            cmd = [
                sys.executable, "train_lora.py",
                "--train_jsonl", f"datasets/{character}/train.jsonl",
                "--output_dir", f"out/lora_{character}"
            ]

            # æ·»åŠ æ¨¡å‹å‚æ•°
            base_model = training_params.get("base_model")
            if base_model:
                cmd.extend(["--model_name_or_path", str(base_model)])

            # æ·»åŠ è®­ç»ƒå‚æ•°
            if 'epochs' in training_params:
                cmd.extend(["--num_train_epochs", str(training_params['epochs'])])
            if 'learning_rate' in training_params:
                cmd.extend(["--learning_rate", str(training_params['learning_rate'])])
            if 'lora_r' in training_params:
                cmd.extend(["--lora_r", str(training_params['lora_r'])])
            if 'lora_alpha' in training_params:
                cmd.extend(["--lora_alpha", str(training_params['lora_alpha'])])
            if 'lora_dropout' in training_params:
                cmd.extend(["--lora_dropout", str(training_params['lora_dropout'])])

            # é»˜è®¤å‚æ•°
            cmd.extend([
                "--merge_and_save",
                "--merged_dir", f"out/merged_{character}"
            ])

            print("   ç”Ÿæˆçš„è®­ç»ƒå‘½ä»¤:")
            print(f"      {' '.join(cmd)}")

            # éªŒè¯å‘½ä»¤å®Œæ•´æ€§
            required_params = ["--train_jsonl", "--output_dir", "--model_name_or_path"]
            missing_params = [p for p in required_params if p not in cmd]

            if missing_params:
                self.log_issue("ERROR", f"è®­ç»ƒå‘½ä»¤ç¼ºå¤±å¿…è¦å‚æ•°: {missing_params}")
                return False, cmd

            self.log_issue("INFO", f"{character} è®­ç»ƒå‘½ä»¤ç”ŸæˆéªŒè¯é€šè¿‡")
            return True, cmd

        except Exception as e:
            self.log_issue("ERROR", f"è®­ç»ƒå‘½ä»¤æ¨¡æ‹Ÿå¤±è´¥: {e}")
            return False, []

    def validate_data_file_access(self) -> bool:
        """éªŒè¯æ•°æ®æ–‡ä»¶è®¿é—®é€»è¾‘"""
        print("\nğŸ” éªŒè¯æ•°æ®æ–‡ä»¶è®¿é—®...")

        datasets_dir = self.root_dir / "datasets"
        if not datasets_dir.exists():
            self.log_issue("WARNING", "datasets ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡æ•°æ®æ–‡ä»¶éªŒè¯")
            return True

        valid_chars = []
        for char_dir in datasets_dir.iterdir():
            if not char_dir.is_dir() or char_dir.name == 'archive':
                continue

            char_name = char_dir.name
            train_files = list(char_dir.glob("*train*.jsonl"))
            val_files = list(char_dir.glob("*val*.jsonl"))

            if train_files:
                print(f"   âœ… {char_name}: æ‰¾åˆ° {len(train_files)} ä¸ªè®­ç»ƒæ–‡ä»¶")
                valid_chars.append(char_name)
            else:
                self.log_issue("WARNING", f"{char_name}: æœªæ‰¾åˆ°è®­ç»ƒæ–‡ä»¶")

        if valid_chars:
            self.log_issue("INFO", f"æ•°æ®æ–‡ä»¶éªŒè¯é€šè¿‡ï¼Œå¯ç”¨è§’è‰²: {', '.join(valid_chars)}")
            return True
        else:
            self.log_issue("ERROR", "æœªæ‰¾åˆ°ä»»ä½•å¯ç”¨çš„è®­ç»ƒæ•°æ®")
            return False

    def check_critical_file_integrity(self) -> bool:
        """æ£€æŸ¥å…³é”®æ–‡ä»¶å®Œæ•´æ€§"""
        print("\nğŸ” æ£€æŸ¥å…³é”®æ–‡ä»¶å®Œæ•´æ€§...")

        critical_files = {
            "character_configs.yaml": "è§’è‰²é…ç½®æ–‡ä»¶",
            "train_lora.py": "è®­ç»ƒè„šæœ¬",
            "config_manager.py": "é…ç½®ç®¡ç†å™¨",
            "smart_train.py": "æ™ºèƒ½è®­ç»ƒè„šæœ¬"
        }

        missing_files = []
        for file_name, desc in critical_files.items():
            file_path = self.root_dir / file_name
            if file_path.exists():
                print(f"   âœ… {desc}: {file_name}")
            else:
                missing_files.append(f"{desc} ({file_name})")

        if missing_files:
            self.log_issue("ERROR", f"å…³é”®æ–‡ä»¶ç¼ºå¤±: {', '.join(missing_files)}")
            return False

        self.log_issue("INFO", "å…³é”®æ–‡ä»¶å®Œæ•´æ€§æ£€æŸ¥é€šè¿‡")
        return True

    def generate_safety_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆå®‰å…¨æ€§è¯„ä¼°æŠ¥å‘Š"""
        error_count = len([i for i in self.issues if i["level"] == "ERROR"])
        warning_count = len([i for i in self.issues if i["level"] == "WARNING"])

        safety_level = "SAFE"
        if error_count > 0:
            safety_level = "UNSAFE"
        elif warning_count > 2:
            safety_level = "RISKY"

        return {
            "safety_level": safety_level,
            "error_count": error_count,
            "warning_count": warning_count,
            "issues": self.issues,
            "recommendation": self._get_recommendation(safety_level)
        }

    def _get_recommendation(self, safety_level: str) -> str:
        """è·å–å®‰å…¨å»ºè®®"""
        if safety_level == "SAFE":
            return "âœ… å®‰å…¨ï¼šå¯ä»¥è¿›è¡Œåˆå¹¶æ“ä½œ"
        elif safety_level == "RISKY":
            return "âš ï¸  æœ‰é£é™©ï¼šå»ºè®®å…ˆè§£å†³è­¦å‘Šé¡¹ï¼Œå†è¿›è¡Œåˆå¹¶"
        else:
            return "âŒ ä¸å®‰å…¨ï¼šå¿…é¡»å…ˆè§£å†³æ‰€æœ‰é”™è¯¯ï¼Œæ‰èƒ½è¿›è¡Œåˆå¹¶"

def main():
    """ä¸»éªŒè¯æµç¨‹"""
    print("ğŸ›¡ï¸  åˆå¹¶å®‰å…¨æ€§éªŒè¯")
    print("=" * 60)

    validator = MergeSafetyValidator()

    # æ‰§è¡Œå„é¡¹éªŒè¯
    tests = [
        ("å…³é”®æ–‡ä»¶å®Œæ•´æ€§", validator.check_critical_file_integrity),
        ("é…ç½®å‚æ•°æ˜ å°„", validator.validate_config_parameter_mapping),
        ("è®­ç»ƒå‚æ•°ç”Ÿæˆ", validator.validate_training_args_generation),
        ("æ•°æ®æ–‡ä»¶è®¿é—®", validator.validate_data_file_access),
    ]

    results = {}
    for test_name, test_func in tests:
        try:
            results[test_name] = test_func()
        except Exception as e:
            validator.log_issue("ERROR", f"{test_name} æ‰§è¡Œå¤±è´¥: {e}")
            results[test_name] = False

    # æµ‹è¯•å‘½ä»¤ç”Ÿæˆï¼ˆå¦‚æœæœ‰å¯ç”¨è§’è‰²ï¼‰
    try:
        validator.simulate_training_command("linzhi")
    except Exception as e:
        validator.log_issue("WARNING", f"å‘½ä»¤ç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")

    # ç”Ÿæˆå®‰å…¨æŠ¥å‘Š
    report = validator.generate_safety_report()

    print("\n" + "=" * 60)
    print("ğŸ“Š å®‰å…¨æ€§è¯„ä¼°æŠ¥å‘Š")
    print("=" * 60)
    print(f"å®‰å…¨ç­‰çº§: {report['safety_level']}")
    print(f"é”™è¯¯æ•°é‡: {report['error_count']}")
    print(f"è­¦å‘Šæ•°é‡: {report['warning_count']}")
    print(f"å»ºè®®: {report['recommendation']}")

    # æ˜¾ç¤ºæµ‹è¯•ç»“æœæ‘˜è¦
    print(f"\nğŸ“‹ æµ‹è¯•ç»“æœæ‘˜è¦:")
    for test_name, passed in results.items():
        status = "âœ… é€šè¿‡" if passed else "âŒ å¤±è´¥"
        print(f"   {test_name}: {status}")

    # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
    report_file = Path("merge_safety_report.json")
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)

    print(f"\nğŸ’¾ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")

    if report['safety_level'] == "SAFE":
        print(f"\nğŸ‰ éªŒè¯å®Œæˆï¼å¯ä»¥å®‰å…¨è¿›è¡Œåˆå¹¶æ“ä½œ")
        return True
    else:
        print(f"\nâš ï¸  è¯·å…ˆè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œå†è¿›è¡Œåˆå¹¶")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)