# LoRA å¾®è°ƒé…ç½®æ–‡ä»¶
# é’ˆå¯¹è§’è‰²æ‰®æ¼”/å¯¹è¯ä»»åŠ¡ä¼˜åŒ–

# åŸºç¡€æ¨¡å‹é…ç½®
model:
  # å¼€æ”¾æ¨¡å‹é€‰é¡¹ï¼ˆæŒ‰æ¨èé¡ºåºï¼‰:
  # 1. "Qwen/Qwen2.5-1.5B" - åŸºç¡€ç‰ˆï¼Œæ— å®¡æŸ¥ï¼Œéœ€è¦æ›´å¤šæ•°æ®
  # 2. "mistralai/Mistral-7B-v0.1" - å¼€æ”¾ï¼Œæ— å®¡æŸ¥ï¼Œéœ€è¦æ›´å¤šæ˜¾å­˜
  # 3. "TinyLlama/TinyLlama-1.1B-Chat-v1.0" - å°å·§å¼€æ”¾
  # 4. "THUDM/glm-4-9b" - ä¸­æ–‡ä¼˜åŒ–ï¼Œè¾ƒå¼€æ”¾
  # 5. "01-ai/Yi-1.5-6B" - ä¸­æ–‡å¥½ï¼Œç›¸å¯¹å¼€æ”¾
  base_model: "Qwen/Qwen2.5-0.5B"
  model_type: "qwen"

# è®­ç»ƒå‚æ•°
training:
  epochs: 5.0                 # è®­ç»ƒè½®æ•°ï¼ˆæ•°æ®å°‘å¯ä»¥é€‚å½“å¢åŠ åˆ°4-5ï¼‰
  learning_rate: 1e-4         # ğŸ‘ˆ é™ä½å­¦ä¹ ç‡ï¼Œé¿å…ç ´ååŸæœ‰èƒ½åŠ›
  warmup_ratio: 0.1           # ğŸ‘ˆ å¢åŠ warmupï¼Œè®©è®­ç»ƒæ›´ç¨³å®š
  weight_decay: 0.01          # ğŸ‘ˆ æ·»åŠ æƒé‡è¡°å‡ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
  seed: 42

# LoRA å‚æ•° (é’ˆå¯¹0.5Bå°æ¨¡å‹ä¼˜åŒ–)
lora:
  rank: 16                    # ğŸ‘ˆ å°æ¨¡å‹ç”¨å°rankï¼Œ16-32è¶³å¤Ÿ
  alpha: 32                   # ğŸ‘ˆ alpha = 2 * rank æ˜¯å¸¸è§é…ç½®
  dropout: 0.1                # dropoutä¿æŒ0.1

# æ•°æ®å‚æ•°
data:
  max_seq_length: 0
  batch_size: 0
  gradient_accumulation: 0

# æ—¥å¿—å’Œä¿å­˜
logging:
  logging_steps: 10
  save_steps: 200
  eval_steps: 200

# Ollama å‚æ•° (ç”Ÿæˆæ—¶ä½¿ç”¨)
ollama:
  temperature: 0.7            # ğŸ‘ˆ 0.7-0.8 æ¯”è¾ƒå¹³è¡¡ï¼Œå¤ªé«˜ä¼šèƒ¡è¯´
  top_p: 0.9
  top_k: 40
  repeat_penalty: 1.1         # ğŸ‘ˆ ç¨å¾®æé«˜ï¼Œå‡å°‘é‡å¤
  context_length: 2048        # ğŸ‘ˆ å°æ¨¡å‹ç”¨2048è¶³å¤Ÿ

# é«˜çº§é€‰é¡¹
advanced:
  gradient_checkpointing: false
  no_eval: false
  report_to: "none"