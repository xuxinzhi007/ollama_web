#!/usr/bin/env python3
"""
ç»ˆæ LoRA -> Ollama è§£å†³æ–¹æ¡ˆ
å®Œå…¨é¿å¼€ sentencepiece ç¼–è¯‘é—®é¢˜ï¼Œæ”¯æŒæ‰¹é‡å¯¼å…¥
"""

import argparse
import subprocess
import sys
from pathlib import Path
import tempfile
import json


def run_cmd(cmd: str) -> tuple[int, str]:
    """è¿è¡Œå‘½ä»¤"""
    print(f"[æ‰§è¡Œ] {cmd}")
    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
    if result.stdout:
        print(result.stdout.strip())
    if result.returncode != 0 and result.stderr:
        print(f"[é”™è¯¯] {result.stderr.strip()}")
    return result.returncode, result.stdout.strip()


def check_ollama():
    """æ£€æŸ¥ Ollama æœåŠ¡"""
    ret, _ = run_cmd("ollama --version")
    if ret != 0:
        print("âŒ è¯·å…ˆå®‰è£… Ollama: https://ollama.ai")
        return False

    # æ£€æŸ¥æœåŠ¡çŠ¶æ€
    ret, _ = run_cmd("ollama list")
    if ret != 0:
        print("ğŸ”„ å¯åŠ¨ Ollama æœåŠ¡...")
        subprocess.Popen("ollama serve", shell=True)
        import time
        time.sleep(3)

    print("âœ… Ollama æœåŠ¡æ­£å¸¸")
    return True


def create_modelfile(merged_dir: Path, model_name: str, system_prompt: str = None) -> str:
    """åˆ›å»º Modelfile"""

    # è¯»å–é…ç½®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    config = {}
    config_path = merged_dir / "config.json"
    if config_path.exists():
        with open(config_path) as f:
            config = json.load(f)

    # é»˜è®¤ç³»ç»Ÿæç¤º
    if not system_prompt:
        system_prompt = "ä½ æ˜¯ä¸€ä¸ªç»è¿‡ä¸“é—¨å¾®è°ƒçš„AIåŠ©æ‰‹ã€‚è¯·æä¾›æœ‰å¸®åŠ©ã€å‡†ç¡®å’Œå‹å¥½çš„å›ç­”ã€‚"

    return f"""# LoRA å¾®è°ƒæ¨¡å‹: {model_name}
# è‡ªåŠ¨ç”Ÿæˆçš„ Modelfile

FROM {merged_dir.absolute()}

# æ€§èƒ½å‚æ•°
PARAMETER temperature 0.7
PARAMETER top_p 0.9
PARAMETER top_k 40
PARAMETER repeat_penalty 1.05
PARAMETER num_ctx 4096

# ç³»ç»Ÿæç¤º
SYSTEM \"\"\"{system_prompt}\"\"\"
"""


def import_to_ollama(merged_dir: str, ollama_name: str, force: bool = False, system_prompt: str = None) -> bool:
    """å¯¼å…¥æ¨¡å‹åˆ° Ollama"""

    merged_path = Path(merged_dir)
    if not merged_path.exists():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {merged_path}")
        return False

    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
    if not force:
        ret, output = run_cmd(f"ollama list | grep {ollama_name}")
        if ret == 0:
            print(f"âš ï¸  æ¨¡å‹ '{ollama_name}' å·²å­˜åœ¨ï¼Œä½¿ç”¨ --force è¦†ç›–")
            return False

    # åˆ›å»ºä¸´æ—¶ Modelfile
    with tempfile.NamedTemporaryFile(mode='w', suffix='', delete=False) as f:
        content = create_modelfile(merged_path, ollama_name, system_prompt)
        f.write(content)
        modelfile = f.name

    try:
        print(f"ğŸ“¦ å¯¼å…¥ {ollama_name}...")
        ret, _ = run_cmd(f"ollama create {ollama_name} -f {modelfile}")

        if ret == 0:
            print(f"âœ… å¯¼å…¥æˆåŠŸ: {ollama_name}")
            return True
        else:
            print(f"âŒ å¯¼å…¥å¤±è´¥")
            return False

    finally:
        Path(modelfile).unlink(missing_ok=True)


def batch_import(base_dir: str = "out") -> list[str]:
    """æ‰¹é‡å¯¼å…¥æ‰€æœ‰åˆå¹¶æ¨¡å‹"""

    base_path = Path(base_dir)
    if not base_path.exists():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {base_path}")
        return []

    # æŸ¥æ‰¾æ‰€æœ‰ merged ç›®å½•
    merged_dirs = []
    for p in base_path.rglob("*merged*"):
        if p.is_dir() and (p / "config.json").exists():
            merged_dirs.append(p)

    if not merged_dirs:
        print("âŒ æœªæ‰¾åˆ°åˆå¹¶æ¨¡å‹ç›®å½•")
        return []

    imported = []
    for merged_dir in merged_dirs:
        model_name = f"lora-{merged_dir.name}"
        print(f"\nğŸ”„ å¤„ç†: {merged_dir}")

        if import_to_ollama(str(merged_dir), model_name):
            imported.append(model_name)

    return imported


def main():
    parser = argparse.ArgumentParser(description="ç»ˆæ LoRA -> Ollama å¯¼å…¥å·¥å…·")

    # æ¨¡å¼é€‰æ‹©
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument("--single", type=str, help="å•ä¸ªæ¨¡å‹ç›®å½•è·¯å¾„")
    group.add_argument("--batch", action="store_true", help="æ‰¹é‡å¯¼å…¥æ‰€æœ‰æ¨¡å‹")

    # å‚æ•°
    parser.add_argument("--name", type=str, help="Ollama æ¨¡å‹åç§°ï¼ˆå•ä¸ªæ¨¡å¼å¿…å¡«ï¼‰")
    parser.add_argument("--force", action="store_true", help="å¼ºåˆ¶è¦†ç›–å·²å­˜åœ¨æ¨¡å‹")
    parser.add_argument("--system", type=str, help="è‡ªå®šä¹‰ç³»ç»Ÿæç¤º")
    parser.add_argument("--base_dir", type=str, default="out", help="æ‰¹é‡æ¨¡å¼çš„åŸºç¡€ç›®å½•")

    args = parser.parse_args()

    print("ğŸš€ ç»ˆæ LoRA -> Ollama å¯¼å…¥å·¥å…·")
    print("=" * 50)

    if not check_ollama():
        sys.exit(1)

    try:
        if args.single:
            # å•ä¸ªå¯¼å…¥
            if not args.name:
                print("âŒ å•ä¸ªæ¨¡å¼éœ€è¦æŒ‡å®š --name")
                sys.exit(1)

            success = import_to_ollama(args.single, args.name, args.force, args.system)
            if success:
                print(f"\nğŸ‰ å®Œæˆ! ä½¿ç”¨å‘½ä»¤æµ‹è¯•:")
                print(f"   ollama run {args.name}")
            else:
                sys.exit(1)

        else:
            # æ‰¹é‡å¯¼å…¥
            imported = batch_import(args.base_dir)

            if imported:
                print(f"\nğŸ‰ æˆåŠŸå¯¼å…¥ {len(imported)} ä¸ªæ¨¡å‹:")
                for name in imported:
                    print(f"  âœ… {name}")
                print(f"\nğŸš€ æµ‹è¯•å‘½ä»¤:")
                for name in imported:
                    print(f"   ollama run {name}")
            else:
                print("âŒ æ²¡æœ‰æˆåŠŸå¯¼å…¥ä»»ä½•æ¨¡å‹")
                sys.exit(1)

    except KeyboardInterrupt:
        print("\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()