#!/usr/bin/env python3
"""
è‡ªå®šä¹‰æ•°æ®é›†ç”Ÿæˆå·¥å…·
æ”¯æŒå¤šç§æ–¹å¼åˆ›å»ºè®­ç»ƒæ•°æ®ï¼š
1. ä½¿ç”¨å†…ç½®ç”Ÿæˆå™¨ï¼ˆmake_dataset.pyï¼‰
2. ä»CSV/Excelå¯¼å…¥
3. ä»JSONå¯¼å…¥
4. äº¤äº’å¼åˆ›å»º
5. æ¨¡æ¿å¼•å¯¼åˆ›å»º
"""

import argparse
import json
import csv
import sys
from pathlib import Path
from typing import Dict, List, Any, Optional
import pandas as pd


class DatasetBuilder:
    def __init__(self):
        self.data: List[Dict[str, Any]] = []

    def add_conversation(self, system_prompt: str, user_message: str, assistant_message: str,
                        category: str = "custom", style: str = "standard") -> None:
        """æ·»åŠ ä¸€æ¡å¯¹è¯æ•°æ®"""
        conversation = {
            "style": style,
            "category": category,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_message},
                {"role": "assistant", "content": assistant_message}
            ]
        }
        self.data.append(conversation)

    def load_from_csv(self, csv_path: Path) -> None:
        """ä»CSVæ–‡ä»¶åŠ è½½æ•°æ®

        CSVæ ¼å¼è¦æ±‚ï¼š
        system_prompt, user_message, assistant_message, category, style
        """
        print(f"ğŸ“Š ä»CSVåŠ è½½æ•°æ®: {csv_path}")

        try:
            df = pd.read_csv(csv_path)
            required_columns = ['system_prompt', 'user_message', 'assistant_message']

            # æ£€æŸ¥å¿…éœ€åˆ—
            missing_cols = [col for col in required_columns if col not in df.columns]
            if missing_cols:
                print(f"âŒ CSVæ–‡ä»¶ç¼ºå°‘å¿…éœ€åˆ—: {missing_cols}")
                print("ğŸ’¡ è¯·ç¡®ä¿CSVåŒ…å«: system_prompt, user_message, assistant_message")
                return

            # è®¾ç½®é»˜è®¤å€¼
            if 'category' not in df.columns:
                df['category'] = 'custom'
            if 'style' not in df.columns:
                df['style'] = 'standard'

            # è½¬æ¢æ•°æ®
            for _, row in df.iterrows():
                self.add_conversation(
                    system_prompt=str(row['system_prompt']),
                    user_message=str(row['user_message']),
                    assistant_message=str(row['assistant_message']),
                    category=str(row.get('category', 'custom')),
                    style=str(row.get('style', 'standard'))
                )

            print(f"âœ… æˆåŠŸåŠ è½½ {len(df)} æ¡å¯¹è¯")

        except Exception as e:
            print(f"âŒ CSVåŠ è½½å¤±è´¥: {e}")

    def load_from_json(self, json_path: Path) -> None:
        """ä»JSONæ–‡ä»¶åŠ è½½æ•°æ®

        JSONæ ¼å¼ï¼š
        [
            {
                "system_prompt": "...",
                "user_message": "...",
                "assistant_message": "...",
                "category": "...",
                "style": "..."
            }
        ]
        """
        print(f"ğŸ“Š ä»JSONåŠ è½½æ•°æ®: {json_path}")

        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                json_data = json.load(f)

            if not isinstance(json_data, list):
                print("âŒ JSONæ ¼å¼é”™è¯¯ï¼šæ ¹å…ƒç´ åº”è¯¥æ˜¯æ•°ç»„")
                return

            for item in json_data:
                if not isinstance(item, dict):
                    print("âš ï¸  è·³è¿‡éå¯¹è±¡å…ƒç´ ")
                    continue

                required_fields = ['system_prompt', 'user_message', 'assistant_message']
                missing_fields = [field for field in required_fields if field not in item]
                if missing_fields:
                    print(f"âš ï¸  è·³è¿‡ç¼ºå°‘å­—æ®µçš„æ¡ç›®: {missing_fields}")
                    continue

                self.add_conversation(
                    system_prompt=item['system_prompt'],
                    user_message=item['user_message'],
                    assistant_message=item['assistant_message'],
                    category=item.get('category', 'custom'),
                    style=item.get('style', 'standard')
                )

            print(f"âœ… æˆåŠŸåŠ è½½ {len(self.data)} æ¡å¯¹è¯")

        except Exception as e:
            print(f"âŒ JSONåŠ è½½å¤±è´¥: {e}")

    def interactive_create(self) -> None:
        """äº¤äº’å¼åˆ›å»ºæ•°æ®é›†"""
        print("\nğŸ¯ äº¤äº’å¼æ•°æ®é›†åˆ›å»º")
        print("=" * 50)

        # è·å–åŸºç¡€è®¾ç½®
        print("ğŸ“‹ é¦–å…ˆè®¾ç½®åŸºç¡€ä¿¡æ¯:")
        system_prompt = input("ç³»ç»Ÿæç¤º (æè¿°AIçš„è§’è‰²å’Œè¡Œä¸º): ").strip()
        if not system_prompt:
            system_prompt = "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„AIåŠ©æ‰‹ã€‚è¯·æä¾›å‡†ç¡®ã€æœ‰ç”¨çš„å›ç­”ã€‚"

        category = input("æ•°æ®ç±»åˆ« (å¦‚: coding, writing, qa): ").strip() or "custom"
        style = input("å¯¹è¯é£æ ¼ (å¦‚: professional, friendly, casual): ").strip() or "standard"

        print(f"\nâœ… è®¾ç½®å®Œæˆ:")
        print(f"   ç³»ç»Ÿæç¤º: {system_prompt}")
        print(f"   æ•°æ®ç±»åˆ«: {category}")
        print(f"   å¯¹è¯é£æ ¼: {style}")
        print("\nğŸ’¡ å¼€å§‹æ·»åŠ å¯¹è¯ (è¾“å…¥ç©ºè¡Œç»“æŸ):")

        count = 0
        while True:
            print(f"\n--- å¯¹è¯ {count + 1} ---")
            user_msg = input("ç”¨æˆ·æ¶ˆæ¯: ").strip()
            if not user_msg:
                break

            assistant_msg = input("åŠ©æ‰‹å›å¤: ").strip()
            if not assistant_msg:
                print("âš ï¸  åŠ©æ‰‹å›å¤ä¸èƒ½ä¸ºç©ºï¼Œè·³è¿‡æ­¤æ¡")
                continue

            self.add_conversation(system_prompt, user_msg, assistant_msg, category, style)
            count += 1
            print(f"âœ… å·²æ·»åŠ  {count} æ¡å¯¹è¯")

        print(f"\nğŸ‰ äº¤äº’å¼åˆ›å»ºå®Œæˆï¼å…±æ·»åŠ  {count} æ¡å¯¹è¯")

    def create_from_template(self, template_type: str) -> None:
        """ä»æ¨¡æ¿åˆ›å»ºæ•°æ®é›†"""
        templates = {
            "qa": {
                "system_prompt": "ä½ æ˜¯ä¸€ä¸ªçŸ¥è¯†æ¸Šåšçš„AIåŠ©æ‰‹ï¼Œä¸“é—¨å›ç­”å„ç§é—®é¢˜ã€‚è¯·æä¾›å‡†ç¡®ã€è¯¦ç»†çš„ç­”æ¡ˆã€‚",
                "category": "qa",
                "style": "informative",
                "examples": [
                    {
                        "user": "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
                        "assistant": "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒè®©è®¡ç®—æœºç³»ç»Ÿèƒ½å¤Ÿä»æ•°æ®ä¸­è‡ªåŠ¨å­¦ä¹ å’Œæ”¹è¿›ï¼Œè€Œæ— éœ€è¢«æ˜ç¡®ç¼–ç¨‹ã€‚ä¸»è¦åŒ…æ‹¬ç›‘ç£å­¦ä¹ ã€æ— ç›‘ç£å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ä¸‰å¤§ç±»å‹ã€‚"
                    },
                    {
                        "user": "Pythonå’ŒJavaçš„ä¸»è¦åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ",
                        "assistant": "Pythonå’ŒJavaçš„ä¸»è¦åŒºåˆ«åŒ…æ‹¬ï¼š1) è¯­æ³•ç®€æ´æ€§ï¼šPythonæ›´ç®€æ´æ˜“è¯»ï¼›2) æ‰§è¡Œæ–¹å¼ï¼šPythonæ˜¯è§£é‡Šå‹ï¼ŒJavaæ˜¯ç¼–è¯‘å‹ï¼›3) æ€§èƒ½ï¼šJavaé€šå¸¸æ‰§è¡Œæ›´å¿«ï¼›4) åº”ç”¨åœºæ™¯ï¼šPythonæ“…é•¿æ•°æ®ç§‘å­¦ï¼ŒJavaæ“…é•¿ä¼ä¸šåº”ç”¨ã€‚"
                    }
                ]
            },
            "assistant": {
                "system_prompt": "ä½ æ˜¯ä¸€ä¸ªå‹å¥½ã€ä¹äºåŠ©äººçš„AIåŠ©æ‰‹ã€‚ç”¨æ¸©æš–çš„è¯­æ°”å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œæä¾›å®ç”¨çš„å¸®åŠ©å’Œå»ºè®®ã€‚",
                "category": "assistant",
                "style": "friendly",
                "examples": [
                    {
                        "user": "æˆ‘æ„Ÿè§‰å·¥ä½œå‹åŠ›å¾ˆå¤§ï¼Œæ€ä¹ˆåŠï¼Ÿ",
                        "assistant": "æˆ‘ç†è§£å·¥ä½œå‹åŠ›ç¡®å®ä¼šè®©äººæ„Ÿåˆ°ç–²æƒ«ã€‚å»ºè®®ä½ å¯ä»¥å°è¯•ï¼š1) åˆ—å‡ºä¼˜å…ˆçº§ï¼Œä¸“æ³¨æœ€é‡è¦çš„äº‹ï¼›2) é€‚å½“ä¼‘æ¯ï¼Œä¿è¯ç¡çœ è´¨é‡ï¼›3) ä¸åŒäº‹æˆ–æœ‹å‹äº¤æµï¼Œåˆ†äº«å‹åŠ›ï¼›4) å­¦ä¹ æ”¾æ¾æŠ€å·§ï¼Œå¦‚æ·±å‘¼å¸æˆ–å†¥æƒ³ã€‚è®°ä½ï¼Œé€‚åº¦çš„å‹åŠ›æ˜¯æ­£å¸¸çš„ï¼Œå…³é”®æ˜¯æ‰¾åˆ°å¹³è¡¡ã€‚"
                    },
                    {
                        "user": "æ¨èä¸€äº›æé«˜æ•ˆç‡çš„å·¥å…·",
                        "assistant": "å¾ˆé«˜å…´ä¸ºä½ æ¨èä¸€äº›æ•ˆç‡å·¥å…·ï¼š1) æ—¶é—´ç®¡ç†ï¼šNotionã€Todoistï¼›2) ç¬”è®°æ•´ç†ï¼šObsidianã€RoamResearchï¼›3) ä¸“æ³¨å·¥å…·ï¼šForestã€ç•ªèŒ„å·¥ä½œæ³•åº”ç”¨ï¼›4) åä½œæ²Ÿé€šï¼šSlackã€Zoomï¼›5) è‡ªåŠ¨åŒ–ï¼šZapierã€IFTTTã€‚é€‰æ‹©é€‚åˆä½ å·¥ä½œæµç¨‹çš„1-2ä¸ªå·¥å…·å³å¯ï¼Œé¿å…å·¥å…·è¿‡å¤šåè€Œé™ä½æ•ˆç‡ã€‚"
                    }
                ]
            },
            "coding": {
                "system_prompt": "ä½ æ˜¯ä¸€ä¸ªèµ„æ·±ç¨‹åºå‘˜ï¼Œæ“…é•¿å¤šç§ç¼–ç¨‹è¯­è¨€å’ŒæŠ€æœ¯ã€‚è¯·æä¾›å‡†ç¡®çš„ä»£ç ç¤ºä¾‹å’ŒæŠ€æœ¯è§£é‡Šã€‚",
                "category": "coding",
                "style": "technical",
                "examples": [
                    {
                        "user": "å¦‚ä½•åœ¨Pythonä¸­è¯»å–CSVæ–‡ä»¶ï¼Ÿ",
                        "assistant": "åœ¨Pythonä¸­è¯»å–CSVæ–‡ä»¶æœ‰å‡ ç§æ–¹æ³•ï¼š\n\nä½¿ç”¨pandasï¼ˆæ¨èï¼‰ï¼š\n```python\nimport pandas as pd\ndf = pd.read_csv('file.csv')\nprint(df.head())\n```\n\nä½¿ç”¨å†…ç½®csvæ¨¡å—ï¼š\n```python\nimport csv\nwith open('file.csv', 'r') as f:\n    reader = csv.DictReader(f)\n    for row in reader:\n        print(row)\n```\n\npandasæ›´é€‚åˆæ•°æ®åˆ†æï¼Œcsvæ¨¡å—æ›´è½»é‡ã€‚"
                    }
                ]
            }
        }

        if template_type not in templates:
            print(f"âŒ æœªçŸ¥æ¨¡æ¿ç±»å‹: {template_type}")
            print(f"ğŸ’¡ å¯ç”¨æ¨¡æ¿: {', '.join(templates.keys())}")
            return

        template = templates[template_type]
        print(f"\nğŸ“ ä½¿ç”¨ {template_type} æ¨¡æ¿åˆ›å»ºæ•°æ®é›†")
        print(f"ğŸ“‹ ç³»ç»Ÿæç¤º: {template['system_prompt']}")

        for example in template['examples']:
            self.add_conversation(
                system_prompt=template['system_prompt'],
                user_message=example['user'],
                assistant_message=example['assistant'],
                category=template['category'],
                style=template['style']
            )

        print(f"âœ… æ¨¡æ¿æ•°æ®æ·»åŠ å®Œæˆï¼Œå…± {len(template['examples'])} æ¡")

    def save_dataset(self, output_dir: Path, train_ratio: float = 0.9) -> None:
        """ä¿å­˜æ•°æ®é›†ä¸ºJSONLæ ¼å¼"""
        if not self.data:
            print("âŒ æ²¡æœ‰æ•°æ®å¯ä¿å­˜")
            return

        output_dir.mkdir(parents=True, exist_ok=True)

        # åˆ†å‰²è®­ç»ƒå’ŒéªŒè¯é›†
        total = len(self.data)
        train_count = int(total * train_ratio)

        train_data = self.data[:train_count]
        val_data = self.data[train_count:]

        # ä¿å­˜è®­ç»ƒé›†
        train_path = output_dir / "train.jsonl"
        with open(train_path, 'w', encoding='utf-8') as f:
            for item in train_data:
                f.write(json.dumps(item, ensure_ascii=False) + '\n')

        # ä¿å­˜éªŒè¯é›†
        val_path = output_dir / "val.jsonl"
        with open(val_path, 'w', encoding='utf-8') as f:
            for item in val_data:
                f.write(json.dumps(item, ensure_ascii=False) + '\n')

        print(f"âœ… æ•°æ®é›†ä¿å­˜å®Œæˆ:")
        print(f"   ğŸ“ˆ è®­ç»ƒé›†: {len(train_data)} æ¡ -> {train_path}")
        print(f"   ğŸ“Š éªŒè¯é›†: {len(val_data)} æ¡ -> {val_path}")
        print(f"   ğŸ“ æ€»è®¡: {total} æ¡å¯¹è¯")

    def export_template_csv(self, output_path: Path) -> None:
        """å¯¼å‡ºCSVæ¨¡æ¿æ–‡ä»¶"""
        template_data = [
            {
                'system_prompt': 'ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„AIåŠ©æ‰‹ã€‚è¯·æä¾›å‡†ç¡®ã€æœ‰ç”¨çš„å›ç­”ã€‚',
                'user_message': 'ä½ å¥½ï¼Œä½ èƒ½å¸®æˆ‘ä»€ä¹ˆï¼Ÿ',
                'assistant_message': 'ä½ å¥½ï¼æˆ‘æ˜¯AIåŠ©æ‰‹ï¼Œå¯ä»¥å¸®ä½ è§£ç­”é—®é¢˜ã€æä¾›å»ºè®®ã€ååŠ©æ€è€ƒç­‰ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ',
                'category': 'greeting',
                'style': 'friendly'
            },
            {
                'system_prompt': 'ä½ æ˜¯ä¸€ä¸ªç¼–ç¨‹åŠ©æ‰‹ï¼Œæ“…é•¿å¤šç§ç¼–ç¨‹è¯­è¨€ã€‚',
                'user_message': 'å¦‚ä½•å­¦ä¹ Pythonï¼Ÿ',
                'assistant_message': 'å­¦ä¹ Pythonå»ºè®®æŒ‰ä»¥ä¸‹æ­¥éª¤ï¼š1) æŒæ¡åŸºç¡€è¯­æ³•ï¼›2) ç»ƒä¹ å°é¡¹ç›®ï¼›3) å­¦ä¹ å¸¸ç”¨åº“ï¼›4) å‚ä¸å¼€æºé¡¹ç›®ã€‚æ¨èèµ„æºï¼šPythonå®˜æ–¹æ•™ç¨‹ã€LeetCodeç»ƒä¹ ã€‚',
                'category': 'coding',
                'style': 'educational'
            }
        ]

        df = pd.DataFrame(template_data)
        df.to_csv(output_path, index=False, encoding='utf-8')
        print(f"âœ… CSVæ¨¡æ¿å·²å¯¼å‡º: {output_path}")
        print("ğŸ’¡ ç¼–è¾‘æ­¤æ–‡ä»¶åå¯ä½¿ç”¨ --csv å‚æ•°å¯¼å…¥")


def main():
    parser = argparse.ArgumentParser(description="è‡ªå®šä¹‰æ•°æ®é›†åˆ›å»ºå·¥å…·")

    # æ•°æ®æºé€‰é¡¹
    parser.add_argument("--csv", type=str, help="ä»CSVæ–‡ä»¶å¯¼å…¥æ•°æ®")
    parser.add_argument("--json", type=str, help="ä»JSONæ–‡ä»¶å¯¼å…¥æ•°æ®")
    parser.add_argument("--interactive", action="store_true", help="äº¤äº’å¼åˆ›å»ºæ•°æ®é›†")
    parser.add_argument("--template", type=str, choices=["qa", "assistant", "coding"],
                       help="ä»æ¨¡æ¿åˆ›å»ºæ•°æ®é›†")

    # è¾“å‡ºé€‰é¡¹
    parser.add_argument("--output_dir", type=str, default="data",
                       help="è¾“å‡ºç›®å½• (é»˜è®¤: data)")
    parser.add_argument("--train_ratio", type=float, default=0.9,
                       help="è®­ç»ƒé›†æ¯”ä¾‹ (é»˜è®¤: 0.9)")

    # å·¥å…·é€‰é¡¹
    parser.add_argument("--export_csv_template", type=str,
                       help="å¯¼å‡ºCSVæ¨¡æ¿æ–‡ä»¶")
    parser.add_argument("--merge_with_existing", action="store_true",
                       help="ä¸ç°æœ‰æ•°æ®é›†åˆå¹¶")

    args = parser.parse_args()

    # å¯¼å‡ºCSVæ¨¡æ¿
    if args.export_csv_template:
        builder = DatasetBuilder()
        builder.export_template_csv(Path(args.export_csv_template))
        return

    print("ğŸ¯ è‡ªå®šä¹‰æ•°æ®é›†åˆ›å»ºå·¥å…·")
    print("=" * 50)

    builder = DatasetBuilder()

    # å¦‚æœè¦åˆå¹¶ç°æœ‰æ•°æ®ï¼Œå…ˆåŠ è½½
    if args.merge_with_existing:
        existing_train = Path(args.output_dir) / "train.jsonl"
        if existing_train.exists():
            print(f"ğŸ“Š åŠ è½½ç°æœ‰è®­ç»ƒæ•°æ®: {existing_train}")
            try:
                with open(existing_train, 'r', encoding='utf-8') as f:
                    for line in f:
                        data = json.loads(line.strip())
                        builder.data.append(data)
                print(f"âœ… åŠ è½½äº† {len(builder.data)} æ¡ç°æœ‰æ•°æ®")
            except Exception as e:
                print(f"âš ï¸  åŠ è½½ç°æœ‰æ•°æ®å¤±è´¥: {e}")

    # å¤„ç†æ•°æ®æº
    if args.csv:
        builder.load_from_csv(Path(args.csv))
    elif args.json:
        builder.load_from_json(Path(args.json))
    elif args.interactive:
        builder.interactive_create()
    elif args.template:
        builder.create_from_template(args.template)
    else:
        print("âŒ è¯·æŒ‡å®šæ•°æ®æº:")
        print("   --csv FILE           # ä»CSVå¯¼å…¥")
        print("   --json FILE          # ä»JSONå¯¼å…¥")
        print("   --interactive        # äº¤äº’å¼åˆ›å»º")
        print("   --template TYPE      # ä½¿ç”¨æ¨¡æ¿ (qa/assistant/coding)")
        print("\nğŸ’¡ å·¥å…·é€‰é¡¹:")
        print("   --export_csv_template FILE  # å¯¼å‡ºCSVæ¨¡æ¿")
        sys.exit(1)

    # ä¿å­˜æ•°æ®é›†
    if builder.data:
        builder.save_dataset(Path(args.output_dir), args.train_ratio)

        # æ˜¾ç¤ºæ•°æ®é›†ç»Ÿè®¡
        print(f"\nğŸ“Š æ•°æ®é›†ç»Ÿè®¡:")
        categories = {}
        styles = {}
        for item in builder.data:
            cat = item.get('category', 'unknown')
            style = item.get('style', 'unknown')
            categories[cat] = categories.get(cat, 0) + 1
            styles[style] = styles.get(style, 0) + 1

        print(f"   ğŸ·ï¸  ç±»åˆ«åˆ†å¸ƒ: {dict(sorted(categories.items()))}")
        print(f"   ğŸ¨ é£æ ¼åˆ†å¸ƒ: {dict(sorted(styles.items()))}")

        print(f"\nğŸš€ ä¸‹ä¸€æ­¥:")
        print(f"   python train_to_ollama.py --ollama_name 'your-model-name'")
    else:
        print("âŒ æ²¡æœ‰ç”Ÿæˆä»»ä½•æ•°æ®")


if __name__ == "__main__":
    main()