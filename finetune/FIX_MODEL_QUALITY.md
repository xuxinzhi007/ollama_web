# 修复模型质量问题 - 回复不搭边

## 🔴 当前问题

1. **模型输出包含"system"** - 说明可能过拟合
2. **回复完全不搭边** - 答非所问
3. **训练了10轮** - 太多了，容易过拟合

## ✅ 解决方案

### 1. 降低训练轮数（已修复）

**问题**: `epochs: 10` 太多，导致过拟合

**修复**: 已改为 `epochs: 3.0`

```yaml
training_params:
  epochs: 3.0  # 从10改为3.0
```

**原因**:
- 小数据集（450样本）训练10轮会过拟合
- 模型会"背诵"训练数据，无法泛化
- 3轮通常足够学习角色特征

### 2. 重新训练（必须）

**步骤**:

1. **删除旧模型**:
   ```powershell
   .\quick_fix.ps1
   ```

2. **重新训练**:
   ```powershell
   .\train.ps1 linzhi
   ```
   选择"1) 重新训练"

3. **监控训练过程**:
   - Loss应该从 4.0+ 降到 0.2-0.3
   - 不要训练到loss < 0.1（过拟合）
   - 如果loss降到0.1以下，提前停止

### 3. 检查训练数据质量

**可能的问题**:
- 训练数据中有"system"这个词
- 数据质量不好（回复不自然）
- 数据量太少（450样本可能不够）

**检查方法**:
```bash
python check_data_format.py
```

**如果数据有问题**:
- 检查 `datasets/linzhi/train.jsonl`
- 确保回复自然、符合角色性格
- 考虑增加更多高质量数据

### 4. 调整训练参数（如果3轮还不够）

如果3轮训练后效果还是不好，可以尝试：

```yaml
training_params:
  epochs: 5.0              # 增加到5轮（但不要超过5）
  learning_rate: 3e-5      # 进一步降低学习率
  lora_r: 8                # 降低rank（减少过拟合）
  lora_alpha: 16           # alpha = 2 * rank
```

### 5. 检查模型输出

**训练完成后测试**:
```bash
ollama run linzhi-lora
```

**期望的输出**:
- ✅ 符合角色性格（温柔、害羞）
- ✅ 回复自然、不重复
- ✅ 不包含"system"等格式标记
- ✅ 正常对话，不答非所问

**如果还是不好**:
- 检查训练数据质量
- 考虑增加更多训练数据
- 调整学习率或LoRA参数

## 📊 训练指标参考

### 正常训练过程:
- **Epoch 1**: Loss 4.0+ → 0.5-0.8
- **Epoch 2**: Loss 0.5-0.8 → 0.3-0.5
- **Epoch 3**: Loss 0.3-0.5 → 0.2-0.3

### 过拟合信号:
- ❌ Loss < 0.1（模型"背诵"训练数据）
- ❌ 训练loss很低，但测试效果差
- ❌ 输出包含训练数据的格式标记
- ❌ 回复重复、不自然

### 欠拟合信号:
- ❌ Loss > 1.0（模型没学到）
- ❌ 回复完全不符合角色
- ❌ 输出很通用、没有角色特征

## 🎯 推荐配置

```yaml
training_params:
  epochs: 3.0              # 3轮足够
  learning_rate: 5e-5      # 稳定学习率
  lora_r: 16               # 适中的rank
  lora_alpha: 32           # alpha = 2 * rank
  lora_dropout: 0.1        # 防止过拟合
```

## 💡 总结

1. ✅ **已修复**: epochs从10改为3.0
2. 🔄 **需要操作**: 删除旧模型，重新训练
3. 📊 **监控**: 观察loss变化，不要过拟合
4. 🧪 **测试**: 训练完成后测试模型效果

**记住**: 训练轮数不是越多越好！3-5轮通常足够，10轮会过拟合。

