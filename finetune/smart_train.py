#!/usr/bin/env python3
"""
æ™ºèƒ½LoRAè®­ç»ƒè„šæœ¬ - è‡ªåŠ¨åŒ¹é…æ•°æ®æ–‡ä»¶ï¼Œç®€åŒ–å·¥ä½œæµç¨‹
è§£å†³é—®é¢˜ï¼š
1. è‡ªåŠ¨æ£€æµ‹å’ŒåŒ¹é…æ•°æ®é›†æ–‡ä»¶
2. æ— éœ€æ‰‹åŠ¨æŒ‡å®šæ–‡ä»¶è·¯å¾„
3. æ™ºèƒ½å¤„ç†ç¼ºå¤±æ–‡ä»¶æƒ…å†µ
4. æé«˜æµ‹è¯•æ•ˆç‡

ä½¿ç”¨æ–¹æ³•ï¼š
  python smart_train.py                    # äº¤äº’å¼é€‰æ‹©è§’è‰²
  python smart_train.py --character linzhi # ç›´æ¥æŒ‡å®šè§’è‰²
  python smart_train.py --list             # åˆ—å‡ºæ‰€æœ‰å¯ç”¨é…ç½®
  python smart_train.py --scan             # æ‰«ææ•°æ®é›†çŠ¶æ€
"""

import os
import sys
import argparse
import json
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import subprocess
import time
import shutil
import zipfile
import urllib.request
import urllib.error

# Windowsç¼–ç å¤„ç†ï¼šè®¾ç½®UTF-8è¾“å‡ºä»¥æ”¯æŒemojiå’Œä¸­æ–‡
if sys.platform == 'win32':
    try:
        # è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆå¦‚æœæœªè®¾ç½®ï¼‰
        if 'PYTHONIOENCODING' not in os.environ:
            os.environ['PYTHONIOENCODING'] = 'utf-8'
        if 'PYTHONUTF8' not in os.environ:
            os.environ['PYTHONUTF8'] = '1'
        
        # å°è¯•è®¾ç½®æ§åˆ¶å°ç¼–ç ä¸ºUTF-8
        import io
        # é‡æ–°æ‰“å¼€stdoutå’Œstderrä»¥åº”ç”¨UTF-8ç¼–ç 
        if hasattr(sys.stdout, 'buffer'):
            sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace', line_buffering=True)
        if hasattr(sys.stderr, 'buffer'):
            sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace', line_buffering=True)
    except Exception:
        # å¦‚æœè®¾ç½®å¤±è´¥ï¼Œä½¿ç”¨replaceæ¨¡å¼é¿å…å´©æºƒ
        pass

class SmartTrainer:
    def __init__(self):
        self.root_dir = Path(__file__).parent
        self.datasets_dir = self.root_dir / "datasets"
        self.config_file = self.root_dir / "character_configs.yaml"
        self.config = None  # å»¶è¿ŸåŠ è½½é…ç½®

        # å·¥å…·ç›®å½•ï¼ˆæ”¾ä¸‹è½½çš„ llama.cppï¼Œä¸éœ€è¦ç¼–è¯‘ï¼Œåªç”¨è½¬æ¢è„šæœ¬ï¼‰
        self.tools_dir = self.root_dir / ".tools"
        self.llama_cpp_dir = self.tools_dir / "llama.cpp"

    def _ensure_llama_cpp_converter(self) -> Optional[Path]:
        """
        ç¡®ä¿ llama.cpp çš„ convert_hf_to_gguf.py å¯ç”¨ã€‚
        ä¼˜å…ˆï¼š
        - å·²å­˜åœ¨çš„ .tools/llama.cpp
        - git cloneï¼ˆå¦‚æœæœ‰ gitï¼‰
        - ä¸‹è½½ zip è§£å‹ï¼ˆæ²¡æœ‰ git ä¹Ÿèƒ½ç”¨ï¼‰
        è¿”å›è½¬æ¢è„šæœ¬è·¯å¾„æˆ– Noneã€‚
        """
        convert_py = self.llama_cpp_dir / "convert_hf_to_gguf.py"
        gguf_py_dir = self.llama_cpp_dir / "gguf-py"
        if convert_py.exists() and gguf_py_dir.exists():
            return convert_py

        self.tools_dir.mkdir(parents=True, exist_ok=True)

        # å¦‚æœç›®å½•å­˜åœ¨ä½†ä¸å®Œæ•´ï¼Œå…ˆæ¸…ç†ï¼Œé¿å…åŠæ‹‰å­çŠ¶æ€
        if self.llama_cpp_dir.exists() and not (convert_py.exists() and gguf_py_dir.exists()):
            try:
                shutil.rmtree(self.llama_cpp_dir)
            except Exception:
                pass

        print("\nğŸ“¦ æœªæ‰¾åˆ° GGUF è½¬æ¢å·¥å…·ï¼Œå‡†å¤‡è‡ªåŠ¨è·å– llama.cppï¼ˆæ— éœ€ç¼–è¯‘ï¼Œä»…ä¸‹è½½æºç ï¼‰...")

        git = shutil.which("git")
        if git:
            try:
                cmd = [git, "clone", "--depth", "1", "https://github.com/ggerganov/llama.cpp.git", str(self.llama_cpp_dir)]
                print(f"æ‰§è¡Œ: {' '.join(cmd)}")
                r = subprocess.run(cmd, capture_output=True, text=True)
                if r.returncode != 0:
                    print(f"âš ï¸ git clone å¤±è´¥ï¼Œå°†å°è¯• zip ä¸‹è½½ã€‚é”™è¯¯: {r.stderr.strip()}")
                else:
                    if convert_py.exists() and gguf_py_dir.exists():
                        print("âœ… llama.cpp å·²ä¸‹è½½å®Œæˆ")
                        return convert_py
            except Exception as e:
                print(f"âš ï¸ git clone å¼‚å¸¸ï¼Œå°†å°è¯• zip ä¸‹è½½: {e}")

        # zip ä¸‹è½½å…œåº•
        try:
            zip_url = "https://github.com/ggerganov/llama.cpp/archive/refs/heads/master.zip"
            zip_path = self.tools_dir / "llama.cpp-master.zip"
            print(f"ä¸‹è½½: {zip_url}")
            urllib.request.urlretrieve(zip_url, zip_path)

            with zipfile.ZipFile(zip_path, "r") as zf:
                zf.extractall(self.tools_dir)

            extracted = self.tools_dir / "llama.cpp-master"
            if extracted.exists():
                extracted.rename(self.llama_cpp_dir)
            try:
                zip_path.unlink(missing_ok=True)
            except Exception:
                pass

            if convert_py.exists() and gguf_py_dir.exists():
                print("âœ… llama.cpp å·²ä¸‹è½½å®Œæˆï¼ˆzipï¼‰")
                return convert_py

            print("âŒ llama.cpp ä¸‹è½½åæœªæ‰¾åˆ°è½¬æ¢è„šæœ¬/gguf-pyï¼Œå¯èƒ½ç½‘ç»œè¢«æ‹¦æˆªæˆ–ä¸‹è½½ä¸å®Œæ•´ã€‚")
            return None
        except urllib.error.URLError as e:
            print(f"âŒ ä¸‹è½½ llama.cpp å¤±è´¥ï¼ˆç½‘ç»œé”™è¯¯ï¼‰: {e}")
            return None
        except Exception as e:
            print(f"âŒ ä¸‹è½½/è§£å‹ llama.cpp å¤±è´¥: {e}")
            return None

    def _convert_merged_to_gguf(self, merged_dir: Path, gguf_out: Path, outtype: str = "f16") -> bool:
        """
        ä½¿ç”¨ llama.cpp çš„ convert_hf_to_gguf.py æŠŠ HuggingFace merged ç›®å½•è½¬æ¢ä¸º GGUFã€‚
        æ³¨æ„ï¼šä¸åšé‡åŒ–ï¼ˆé‡åŒ–éœ€è¦ç¼–è¯‘å‡ºæ¥çš„ quantize å¯æ‰§è¡Œæ–‡ä»¶ï¼‰ï¼Œè¿™é‡Œåªç”Ÿæˆ f16 ä»¥ä¿è¯â€œèƒ½è·‘â€ã€‚
        """
        convert_py = self._ensure_llama_cpp_converter()
        if not convert_py:
            return False

        gguf_py_dir = self.llama_cpp_dir / "gguf-py"
        env = os.environ.copy()
        env["PYTHONUTF8"] = "1"
        env["PYTHONIOENCODING"] = "utf-8"
        # è®© convert_hf_to_gguf.py èƒ½ import gguf
        env["PYTHONPATH"] = str(gguf_py_dir) + (os.pathsep + env["PYTHONPATH"] if env.get("PYTHONPATH") else "")

        # è®¸å¤šæ¨¡å‹ï¼ˆåŒ…å« Qwen ç³»åˆ—çš„éƒ¨åˆ†å˜ä½“ï¼‰åœ¨å†™å…¥è¯è¡¨æ—¶ä¼šç”¨åˆ° sentencepiece
        # Windows ä¸Šé€šå¸¸æœ‰é¢„ç¼–è¯‘ wheelï¼Œç›´æ¥ pip å®‰è£…å³å¯ï¼ˆæ— éœ€ç¼–è¯‘ï¼‰ã€‚
        try:
            import sentencepiece  # noqa: F401
        except Exception:
            print("\nğŸ“¦ æ£€æµ‹åˆ°ç¼ºå°‘ä¾èµ–: sentencepieceï¼ˆGGUF è½¬æ¢éœ€è¦ï¼‰")
            print("   å°†è‡ªåŠ¨å®‰è£…ï¼ˆä¸éœ€è¦ç¼–è¯‘ï¼‰ã€‚")
            try:
                r = subprocess.run(
                    [sys.executable, "-m", "pip", "install", "-U", "sentencepiece"],
                    capture_output=True,
                    text=True,
                )
                if r.returncode != 0:
                    print("âŒ å®‰è£… sentencepiece å¤±è´¥ï¼š")
                    if r.stdout.strip():
                        print(r.stdout.strip())
                    if r.stderr.strip():
                        print(r.stderr.strip())
                    return False
            except Exception as e:
                print(f"âŒ å®‰è£… sentencepiece å¼‚å¸¸: {e}")
                return False

        def _run_convert_once() -> tuple[bool, str]:
            cmd = [
                sys.executable,
                str(convert_py),
                str(merged_dir),
                "--outtype",
                outtype,
                "--outfile",
                str(gguf_out),
            ]

            print("\nğŸ”„ æ­£åœ¨è½¬æ¢ GGUFï¼ˆé¦–æ¬¡ä¼šæ¯”è¾ƒæ…¢ï¼‰...")
            print(f"è¾“å‡º: {gguf_out}")
            print(f"æ‰§è¡Œ: {' '.join(cmd)}")

            combined = []
            try:
                p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, env=env)
                # å®æ—¶æ‰“å°ï¼ˆé¿å…å¡ä½æ²¡åé¦ˆï¼‰
                assert p.stdout is not None
                for line in p.stdout:
                    line = line.rstrip()
                    if line:
                        print(line)
                        # ä¿å­˜å°‘é‡å°¾éƒ¨è¾“å‡ºç”¨äºé”™è¯¯è¯Šæ–­ï¼ˆé¿å…å ç”¨å¤ªå¤šå†…å­˜ï¼‰
                        combined.append(line)
                        if len(combined) > 300:
                            combined = combined[-300:]
                p.wait()
                if p.returncode != 0:
                    return False, "\n".join(combined[-80:])
                return True, "\n".join(combined[-80:])
            except Exception as e:
                return False, f"{e}"

        ok, tail = _run_convert_once()
        if not ok:
            print(f"âŒ GGUF è½¬æ¢å¤±è´¥ã€‚æœ«å°¾æ—¥å¿—ï¼š\n{tail}")
            return False

        if gguf_out.exists() and gguf_out.stat().st_size > 0:
            print("âœ… GGUF è½¬æ¢å®Œæˆ")
            return True
        print("âŒ GGUF æ–‡ä»¶æœªç”Ÿæˆæˆ–ä¸ºç©º")
        return False

    def _ensure_config_loaded(self):
        """ç¡®ä¿é…ç½®å·²åŠ è½½"""
        if self.config is None:
            self.config = self._load_config()

    def _load_config(self) -> Dict:
        """åŠ è½½è§’è‰²é…ç½®"""
        try:
            import yaml
            with open(self.config_file, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except FileNotFoundError:
            print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.config_file}")
            sys.exit(1)
        except Exception as e:
            print(f"âŒ åŠ è½½é…ç½®å¤±è´¥: {e}")
            sys.exit(1)

    def check_model_cache(self):
        """æ£€æŸ¥æ¨¡å‹ç¼“å­˜çŠ¶æ€"""
        self._ensure_config_loaded()
        try:
            from model_cache import print_cache_status

            print("\nğŸ” æ£€æŸ¥æ¨¡å‹ç¼“å­˜çŠ¶æ€")
            print("=" * 50)

            # æ£€æŸ¥é…ç½®ä¸­çš„æ‰€æœ‰æ¨¡å‹
            models_to_check = set()

            for char_name, char_config in self.config.get('characters', {}).items():
                training_params = char_config.get('training_params', {})
                base_model = training_params.get('base_model', 'Qwen/Qwen2.5-0.5B')

                # æ ‡å‡†åŒ–æ¨¡å‹åç§°
                if base_model == 'Qwen/Qwen2.5-0.5B':
                    base_model = 'Qwen/Qwen2.5-0.5B-Instruct'

                models_to_check.add(base_model)

            # å¦‚æœæ²¡æœ‰é…ç½®ï¼Œæ£€æŸ¥é»˜è®¤æ¨¡å‹
            if not models_to_check:
                models_to_check.add('Qwen/Qwen2.5-0.5B-Instruct')

            for model in models_to_check:
                print_cache_status(model)
                print()

        except ImportError:
            print("âŒ æ— æ³•å¯¼å…¥æ¨¡å‹ç¼“å­˜æ£€æµ‹æ¨¡å—")
        except Exception as e:
            print(f"âŒ æ£€æŸ¥ç¼“å­˜æ—¶å‡ºé”™: {e}")

    def scan_datasets(self) -> Dict[str, Dict]:
        """æ‰«ææ•°æ®é›†ç›®å½•ï¼Œè‡ªåŠ¨å‘ç°å¯ç”¨çš„æ•°æ®æ–‡ä»¶"""
        print("ğŸ” æ‰«ææ•°æ®é›†...")

        dataset_info = {}

        if not self.datasets_dir.exists():
            print(f"ğŸ“ æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨: {self.datasets_dir}")
            return dataset_info

        # æ‰«æå„ä¸ªè§’è‰²ç›®å½•
        for char_dir in self.datasets_dir.iterdir():
            if not char_dir.is_dir() or char_dir.name == 'archive':
                continue

            char_name = char_dir.name
            train_files = []
            val_files = []

            # æŸ¥æ‰¾è®­ç»ƒå’ŒéªŒè¯æ–‡ä»¶
            for file_path in char_dir.glob("*.jsonl"):
                if "train" in file_path.name.lower():
                    train_files.append(file_path)
                elif "val" in file_path.name.lower():
                    val_files.append(file_path)

            if train_files or val_files:
                dataset_info[char_name] = {
                    'train_files': train_files,
                    'val_files': val_files,
                    'dir': char_dir
                }

        # æ‰«æarchiveç›®å½•ä¸­çš„å†å²æ•°æ®
        archive_dir = self.datasets_dir / "archive"
        if archive_dir.exists():
            archive_files = list(archive_dir.glob("*.jsonl"))
            if archive_files:
                dataset_info['archive'] = {
                    'train_files': [f for f in archive_files if "train" in f.name.lower()],
                    'val_files': [f for f in archive_files if "val" in f.name.lower()],
                    'dir': archive_dir
                }

        return dataset_info

    def count_samples(self, file_path: Path) -> int:
        """ç»Ÿè®¡JSONLæ–‡ä»¶ä¸­çš„æ ·æœ¬æ•°é‡"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return sum(1 for line in f if line.strip())
        except:
            return 0

    def validate_jsonl(self, file_path: Path) -> Tuple[bool, str]:
        """éªŒè¯JSONLæ–‡ä»¶æ ¼å¼"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                for i, line in enumerate(f):
                    if not line.strip():
                        continue
                    try:
                        data = json.loads(line)
                        if 'messages' not in data:
                            return False, f"ç¬¬{i+1}è¡Œç¼ºå°‘'messages'å­—æ®µ"
                        if not isinstance(data['messages'], list):
                            return False, f"ç¬¬{i+1}è¡Œ'messages'ä¸æ˜¯æ•°ç»„"
                    except json.JSONDecodeError as e:
                        return False, f"ç¬¬{i+1}è¡ŒJSONæ ¼å¼é”™è¯¯: {e}"
            return True, "æ ¼å¼æ­£ç¡®"
        except Exception as e:
            return False, f"æ–‡ä»¶è¯»å–é”™è¯¯: {e}"

    def list_configurations(self):
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„è§’è‰²é…ç½®"""
        self._ensure_config_loaded()
        print("\nğŸ“‹ å¯ç”¨è§’è‰²é…ç½®:")
        print("=" * 50)

        dataset_info = self.scan_datasets()

        for char_name, char_config in self.config.get('characters', {}).items():
            print(f"\nğŸ­ è§’è‰²: {char_name}")
            print(f"   åç§°: {char_config.get('name', 'N/A')}")
            print(f"   æè¿°: {char_config.get('description', 'N/A')}")

            # æ£€æŸ¥é…ç½®çš„æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            data_files = char_config.get('data_files', {})
            train_file = data_files.get('train')
            val_file = data_files.get('val')

            print(f"   é…ç½®çš„è®­ç»ƒæ–‡ä»¶: {train_file}")
            print(f"   é…ç½®çš„éªŒè¯æ–‡ä»¶: {val_file}")

            # æ£€æŸ¥å®é™…æ–‡ä»¶çŠ¶æ€
            if char_name in dataset_info:
                info = dataset_info[char_name]
                print(f"   ğŸ” å‘ç°çš„è®­ç»ƒæ–‡ä»¶: {len(info['train_files'])}ä¸ª")
                for tf in info['train_files']:
                    count = self.count_samples(tf)
                    print(f"      ğŸ“„ {tf.name} ({count}æ ·æœ¬)")

                print(f"   ğŸ” å‘ç°çš„éªŒè¯æ–‡ä»¶: {len(info['val_files'])}ä¸ª")
                for vf in info['val_files']:
                    count = self.count_samples(vf)
                    print(f"      ğŸ“„ {vf.name} ({count}æ ·æœ¬)")
            else:
                print(f"   âš ï¸  æœªå‘ç° {char_name} çš„æ•°æ®æ–‡ä»¶")

        # æ˜¾ç¤ºæœªé…ç½®çš„æ•°æ®é›†
        unconfigured = set(dataset_info.keys()) - set(self.config.get('characters', {}).keys())
        if unconfigured:
            print(f"\nğŸ“‚ å‘ç°æœªé…ç½®çš„æ•°æ®é›†:")
            for char_name in unconfigured:
                if char_name == 'archive':
                    continue
                info = dataset_info[char_name]
                print(f"   ğŸ“ {char_name}/")
                print(f"      è®­ç»ƒæ–‡ä»¶: {len(info['train_files'])}ä¸ª")
                print(f"      éªŒè¯æ–‡ä»¶: {len(info['val_files'])}ä¸ª")

    def auto_match_files(self, character: str) -> Tuple[Optional[str], Optional[str]]:
        """è‡ªåŠ¨åŒ¹é…è§’è‰²çš„è®­ç»ƒå’ŒéªŒè¯æ–‡ä»¶"""
        self._ensure_config_loaded()
        dataset_info = self.scan_datasets()

        # é¦–å…ˆæ£€æŸ¥é…ç½®æ–‡ä»¶ä¸­æŒ‡å®šçš„è·¯å¾„
        char_config = self.config.get('characters', {}).get(character)
        if char_config:
            data_files = char_config.get('data_files', {})
            train_path = data_files.get('train')
            val_path = data_files.get('val')

            if train_path and val_path:
                train_full = self.root_dir / train_path
                val_full = self.root_dir / val_path

                if train_full.exists() and val_full.exists():
                    print(f"âœ… ä½¿ç”¨é…ç½®æ–‡ä»¶æŒ‡å®šçš„æ•°æ®:")
                    print(f"   è®­ç»ƒ: {train_path} ({self.count_samples(train_full)}æ ·æœ¬)")
                    print(f"   éªŒè¯: {val_path} ({self.count_samples(val_full)}æ ·æœ¬)")
                    return str(train_full), str(val_full)

        # å¦‚æœé…ç½®æ–‡ä»¶è·¯å¾„ä¸å­˜åœ¨ï¼Œå°è¯•è‡ªåŠ¨åŒ¹é…
        if character in dataset_info:
            info = dataset_info[character]

            # é€‰æ‹©æœ€å¤§çš„è®­ç»ƒæ–‡ä»¶
            train_file = None
            if info['train_files']:
                train_file = max(info['train_files'], key=lambda f: self.count_samples(f))

            # é€‰æ‹©éªŒè¯æ–‡ä»¶
            val_file = None
            if info['val_files']:
                val_file = info['val_files'][0]  # é€šå¸¸åªæœ‰ä¸€ä¸ªéªŒè¯æ–‡ä»¶

            if train_file and val_file:
                print(f"ğŸ¯ è‡ªåŠ¨åŒ¹é…çš„æ•°æ®æ–‡ä»¶:")
                print(f"   è®­ç»ƒ: {train_file.name} ({self.count_samples(train_file)}æ ·æœ¬)")
                print(f"   éªŒè¯: {val_file.name} ({self.count_samples(val_file)}æ ·æœ¬)")
                return str(train_file), str(val_file)

            elif train_file:
                print(f"âš ï¸  åªæ‰¾åˆ°è®­ç»ƒæ–‡ä»¶: {train_file.name} ({self.count_samples(train_file)}æ ·æœ¬)")
                print(f"   ç¼ºå°‘éªŒè¯æ–‡ä»¶ï¼Œå¯èƒ½å½±å“è®­ç»ƒæ•ˆæœ")
                return str(train_file), None

        return None, None

    def interactive_select(self) -> str:
        """äº¤äº’å¼é€‰æ‹©è§’è‰²"""
        self._ensure_config_loaded()
        dataset_info = self.scan_datasets()
        characters = list(self.config.get('characters', {}).keys())

        print("\nğŸ­ è¯·é€‰æ‹©è¦è®­ç»ƒçš„è§’è‰²:")
        print("=" * 40)

        for i, char_name in enumerate(characters, 1):
            char_config = self.config['characters'][char_name]
            name = char_config.get('name', char_name)
            desc = char_config.get('description', 'æ— æè¿°')

            # æ£€æŸ¥æ•°æ®å¯ç”¨æ€§ï¼ˆä¼˜å…ˆæ£€æŸ¥é…ç½®æ–‡ä»¶è·¯å¾„ï¼‰
            status = "âŒ æ— æ•°æ®"

            # é¦–å…ˆæ£€æŸ¥é…ç½®æ–‡ä»¶ä¸­æŒ‡å®šçš„è·¯å¾„
            char_config = self.config['characters'][char_name]
            data_files = char_config.get('data_files', {})
            train_path = data_files.get('train')
            val_path = data_files.get('val')

            train_count = 0
            val_count = 0

            # ä¼˜å…ˆæ£€æŸ¥é…ç½®æ–‡ä»¶æŒ‡å®šçš„è·¯å¾„
            config_files_exist = False
            if train_path:
                train_full = self.root_dir / train_path
                if train_full.exists():
                    train_count = self.count_samples(train_full)
                    config_files_exist = True

            if val_path:
                val_full = self.root_dir / val_path
                if val_full.exists():
                    val_count = self.count_samples(val_full)

            # å¦‚æœé…ç½®æ–‡ä»¶è·¯å¾„æ— æ•ˆæˆ–ä¸å­˜åœ¨ï¼Œå†æ£€æŸ¥æ‰«æç»“æœ
            if not config_files_exist and char_name in dataset_info:
                info = dataset_info[char_name]
                if info['train_files']:
                    train_count = sum(self.count_samples(f) for f in info['train_files'])
                if info['val_files']:
                    val_count = sum(self.count_samples(f) for f in info['val_files'])

            if train_count > 0:
                status = f"âœ… {train_count}è®­ç»ƒæ ·æœ¬"
                if val_count > 0:
                    status += f", {val_count}éªŒè¯æ ·æœ¬"

            print(f"{i:2d}. {name} - {desc}")
            print(f"    {status}")

        while True:
            try:
                choice = input(f"\nè¯·è¾“å…¥é€‰æ‹© (1-{len(characters)}): ").strip()
                if not choice:
                    continue

                idx = int(choice) - 1
                if 0 <= idx < len(characters):
                    return characters[idx]
                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
            except ValueError:
                print("âŒ è¯·è¾“å…¥æ•°å­—")
            except KeyboardInterrupt:
                print("\nğŸ‘‹ è®­ç»ƒå·²å–æ¶ˆ")
                sys.exit(0)

    def check_prerequisites(self, character: str) -> bool:
        """æ£€æŸ¥è®­ç»ƒå‰ç½®æ¡ä»¶"""
        self._ensure_config_loaded()
        print(f"\nğŸ” æ£€æŸ¥ {character} çš„è®­ç»ƒå‰ç½®æ¡ä»¶...")

        # æ£€æŸ¥è§’è‰²é…ç½®
        if character not in self.config.get('characters', {}):
            print(f"âŒ è§’è‰²é…ç½®ä¸å­˜åœ¨: {character}")
            return False

        # æ£€æŸ¥æ•°æ®æ–‡ä»¶
        train_path, val_path = self.auto_match_files(character)
        if not train_path:
            print(f"âŒ æœªæ‰¾åˆ° {character} çš„è®­ç»ƒæ•°æ®")
            print(f"   è¯·ç¡®ä¿åœ¨ä»¥ä¸‹ä½ç½®æ”¾ç½®æ•°æ®æ–‡ä»¶:")
            print(f"   - datasets/{character}/train.jsonl")
            print(f"   - datasets/{character}/val.jsonl")
            return False

        # éªŒè¯æ•°æ®æ ¼å¼
        print("ğŸ” éªŒè¯æ•°æ®æ ¼å¼...")
        valid, msg = self.validate_jsonl(Path(train_path))
        if not valid:
            print(f"âŒ è®­ç»ƒæ•°æ®æ ¼å¼é”™è¯¯: {msg}")
            return False

        if val_path:
            valid, msg = self.validate_jsonl(Path(val_path))
            if not valid:
                print(f"âŒ éªŒè¯æ•°æ®æ ¼å¼é”™è¯¯: {msg}")
                return False

        # æ£€æŸ¥æ ·æœ¬æ•°é‡
        train_count = self.count_samples(Path(train_path))
        if train_count < 10:
            print(f"âš ï¸  è®­ç»ƒæ ·æœ¬æ•°é‡è¾ƒå°‘: {train_count} (å»ºè®® â‰¥ 10)")

        print(f"âœ… å‰ç½®æ¡ä»¶æ£€æŸ¥é€šè¿‡")
        return True

    def show_main_menu(self):
        """æ˜¾ç¤ºä¸»èœå•ï¼ˆæ•´åˆquick_start.shåŠŸèƒ½ï¼‰"""
        while True:
            print("\n" + "="*50)
            print("ğŸš€ æ™ºèƒ½LoRAè®­ç»ƒç³»ç»Ÿ - ä¸»èœå•")
            print("="*50)
            print("1) ğŸ­ è§’è‰²è®­ç»ƒï¼ˆæ™ºèƒ½æ–‡ä»¶åŒ¹é…ï¼‰")
            print("2) ğŸ“Š æ•°æ®é›†ç®¡ç†")
            print("3) ğŸ” ç³»ç»ŸçŠ¶æ€æ£€æŸ¥")
            print("4) ğŸ¤– Ollamaæ¨¡å‹ç®¡ç†")
            print("5) ğŸ§ª æ¨¡å‹æµ‹è¯•")
            print("0) é€€å‡º")
            print()

            try:
                choice = input("è¯·é€‰æ‹© (0-5): ").strip()

                if choice == "1":
                    self._menu_character_training()
                elif choice == "2":
                    self._menu_dataset_management()
                elif choice == "3":
                    self._menu_system_status()
                elif choice == "4":
                    self._menu_ollama_management()
                elif choice == "5":
                    self._menu_model_testing()
                elif choice == "0":
                    print("ğŸ‘‹ å†è§ï¼")
                    break
                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©")

            except (KeyboardInterrupt, EOFError):
                print("\nğŸ‘‹ å†è§ï¼")
                break

    def _menu_character_training(self):
        """èœå•ï¼šè§’è‰²è®­ç»ƒ"""
        print("\nğŸ­ è§’è‰²è®­ç»ƒé€‰é¡¹:")
        print("1) äº¤äº’å¼é€‰æ‹©è§’è‰²")
        print("2) æŸ¥çœ‹æ‰€æœ‰é…ç½®")
        print("3) æ‰«ææ•°æ®é›†çŠ¶æ€")
        print("4) æ£€æŸ¥æ¨¡å‹ç¼“å­˜")

        choice = input("é€‰æ‹© (1-4): ").strip()

        if choice == "1":
            character = self.interactive_select()
            if self.check_prerequisites(character):
                self._confirm_and_train(character)
        elif choice == "2":
            self.list_configurations()
        elif choice == "3":
            self._show_dataset_scan()
        elif choice == "4":
            self.check_model_cache()

    def _menu_dataset_management(self):
        """èœå•ï¼šæ•°æ®é›†ç®¡ç†"""
        print("\nğŸ“Š æ•°æ®é›†ç®¡ç†:")
        print("1) æ‰«ææ‰€æœ‰æ•°æ®é›†")
        print("2) éªŒè¯æ•°æ®æ ¼å¼")
        print("3) æŸ¥çœ‹æ•°æ®ç»Ÿè®¡")

        choice = input("é€‰æ‹© (1-3): ").strip()

        if choice == "1":
            self._show_dataset_scan()
        elif choice == "2":
            self._validate_all_datasets()
        elif choice == "3":
            self._show_dataset_stats()

    def _menu_system_status(self):
        """èœå•ï¼šç³»ç»ŸçŠ¶æ€"""
        print("\nğŸ” ç³»ç»ŸçŠ¶æ€æ£€æŸ¥:")
        print("1) æ£€æŸ¥æ¨¡å‹ç¼“å­˜")
        print("2) æ£€æŸ¥è®­ç»ƒç¯å¢ƒ")
        print("3) å…¨é¢ç¯å¢ƒè¯Šæ–­")  # æ–°å¢
        print("4) ç¯å¢ƒè®¾ç½®åŠ©æ‰‹")   # æ–°å¢
        print("5) æŸ¥çœ‹ç£ç›˜ä½¿ç”¨")

        choice = input("é€‰æ‹© (1-5): ").strip()

        if choice == "1":
            self.check_model_cache()
        elif choice == "2":
            self._check_training_environment()
        elif choice == "3":
            self._comprehensive_environment_check()  # æ–°å¢
        elif choice == "4":
            self._environment_setup_helper()  # æ–°å¢
        elif choice == "5":
            self._check_disk_usage()

    def _comprehensive_environment_check(self):
        """å…¨é¢ç¯å¢ƒè¯Šæ–­"""
        issues = self._check_environment_comprehensive()

        if not issues:
            print("\nğŸ‰ ç¯å¢ƒæ£€æŸ¥å®Œæˆ - æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼")
        else:
            print(f"\nâš ï¸  å‘ç° {len(issues)} ä¸ªç¯å¢ƒé—®é¢˜")
            print("\nğŸ’¡ è§£å†³å»ºè®®:")

            if 'python_version' in issues:
                print("   â€¢ Pythonç‰ˆæœ¬: è¯·å‡çº§åˆ°3.10+")
            if 'virtual_env' in issues:
                print("   â€¢ è™šæ‹Ÿç¯å¢ƒ: è¿è¡Œ python smart_train.py --setup åˆ›å»ºç¯å¢ƒ")
            if 'dependencies' in issues:
                print("   â€¢ ä¾èµ–åŒ…: è¿è¡Œ pip install -r requirements.txt")
            if 'ollama' in issues:
                print("   â€¢ OllamaæœåŠ¡: è®¿é—® https://ollama.com/ å®‰è£…")

            print(f"\nğŸ› ï¸  å¿«é€Ÿä¿®å¤: python smart_train.py --setup")

    def _environment_setup_helper(self):
        """ç¯å¢ƒè®¾ç½®åŠ©æ‰‹"""
        print("\nğŸ› ï¸  ç¯å¢ƒè®¾ç½®åŠ©æ‰‹")
        print("=" * 40)

        print("1) ğŸ”§ è‡ªåŠ¨ç¯å¢ƒå‡†å¤‡ (æ¨è)")
        print("2) ğŸ“‹ æ‰‹åŠ¨è®¾ç½®æŒ‡å—")
        print("3) ğŸ” é—®é¢˜è¯Šæ–­")
        print("4) ğŸ”„ é‡ç½®ç¯å¢ƒ")

        choice = input("\né€‰æ‹©æ“ä½œ (1-4): ").strip()

        if choice == "1":
            # è‡ªåŠ¨ç¯å¢ƒå‡†å¤‡
            issues = self._check_environment_comprehensive()
            if not issues:
                print("\nâœ… ç¯å¢ƒå·²ç»å‡†å¤‡å¥½äº†ï¼")
            else:
                confirm = input("\næ£€æµ‹åˆ°ç¯å¢ƒé—®é¢˜ï¼Œæ˜¯å¦è‡ªåŠ¨ä¿®å¤? (Y/n): ").strip().lower()
                if confirm in ['', 'y', 'yes']:
                    self._auto_setup_environment(issues)

        elif choice == "2":
            # æ‰‹åŠ¨è®¾ç½®æŒ‡å—
            self._show_manual_setup_guide()

        elif choice == "3":
            # é—®é¢˜è¯Šæ–­
            self._diagnose_environment_issues()

        elif choice == "4":
            # é‡ç½®ç¯å¢ƒ
            self._reset_environment()

    def _show_manual_setup_guide(self):
        """æ˜¾ç¤ºæ‰‹åŠ¨è®¾ç½®æŒ‡å—"""
        print("\nğŸ“‹ æ‰‹åŠ¨ç¯å¢ƒè®¾ç½®æŒ‡å—")
        print("=" * 40)

        print("\n1ï¸âƒ£ åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ:")
        print("   python3 -m venv .venv")

        print("\n2ï¸âƒ£ æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ:")
        import platform
        if platform.system() == 'Windows':
            print("   .venv\\Scripts\\activate")
        else:
            print("   source .venv/bin/activate")

        print("\n3ï¸âƒ£ å®‰è£…ä¾èµ–:")
        print("   pip install -U pip")
        print("   pip install -r requirements.txt")

        print("\n4ï¸âƒ£ éªŒè¯å®‰è£…:")
        print("   python smart_train.py --env-check")

        print("\n5ï¸âƒ£ å®‰è£…Ollama (å¯é€‰):")
        print("   è®¿é—® https://ollama.com/ ä¸‹è½½å®‰è£…")

    def _diagnose_environment_issues(self):
        """è¯Šæ–­ç¯å¢ƒé—®é¢˜"""
        print("\nğŸ” ç¯å¢ƒé—®é¢˜è¯Šæ–­")
        print("=" * 40)

        issues = self._check_environment_comprehensive()

        if not issues:
            print("\nâœ… æ²¡æœ‰å‘ç°é—®é¢˜ï¼ç¯å¢ƒé…ç½®è‰¯å¥½ã€‚")
            return

        print(f"\nğŸ”§ è¯Šæ–­ç»“æœå’Œè§£å†³æ–¹æ¡ˆ:")

        for issue in issues:
            if issue == 'python_version':
                print(f"\nâŒ Pythonç‰ˆæœ¬é—®é¢˜:")
                print(f"   å½“å‰ç‰ˆæœ¬è¿‡ä½ï¼Œéœ€è¦Python 3.10+")
                self._show_python_upgrade_guide()

            elif issue == 'virtual_env':
                print(f"\nâŒ è™šæ‹Ÿç¯å¢ƒé—®é¢˜:")
                print(f"   æœªæ£€æµ‹åˆ°è™šæ‹Ÿç¯å¢ƒ")
                print(f"   è§£å†³æ–¹æ¡ˆ: python3 -m venv .venv")

            elif issue == 'dependencies':
                print(f"\nâŒ ä¾èµ–åŒ…é—®é¢˜:")
                print(f"   è®­ç»ƒä¾èµ–æœªå®Œæ•´å®‰è£…")
                print(f"   è§£å†³æ–¹æ¡ˆ: pip install -r requirements.txt")

            elif issue == 'ollama':
                print(f"\nâš ï¸  OllamaæœåŠ¡é—®é¢˜:")
                print(f"   Ollamaæœªå®‰è£…æˆ–ä¸å¯ç”¨")
                print(f"   è§£å†³æ–¹æ¡ˆ: è®¿é—® https://ollama.com/ å®‰è£…")
                print(f"   æ³¨æ„: Ollamaä¸æ˜¯è®­ç»ƒå¿…éœ€çš„ï¼Œåªåœ¨å¯¼å…¥æ¨¡å‹æ—¶éœ€è¦")

    def _reset_environment(self):
        """é‡ç½®ç¯å¢ƒ"""
        print("\nğŸ”„ ç¯å¢ƒé‡ç½®")
        print("=" * 40)

        print("âš ï¸  è¿™å°†åˆ é™¤ç°æœ‰çš„è™šæ‹Ÿç¯å¢ƒå¹¶é‡æ–°åˆ›å»º")
        confirm = input("ç¡®è®¤è¦é‡ç½®ç¯å¢ƒå—? (y/N): ").strip().lower()

        if confirm in ['y', 'yes']:
            import shutil

            # åˆ é™¤ç°æœ‰è™šæ‹Ÿç¯å¢ƒ
            if Path('.venv').exists():
                print("ğŸ—‘ï¸  åˆ é™¤ç°æœ‰è™šæ‹Ÿç¯å¢ƒ...")
                shutil.rmtree('.venv')
                print("   âœ… åˆ é™¤å®Œæˆ")

            # é‡æ–°åˆ›å»ºç¯å¢ƒ
            print("ğŸ”§ é‡æ–°åˆ›å»ºç¯å¢ƒ...")
            if self._create_virtual_environment():
                print("   âœ… è™šæ‹Ÿç¯å¢ƒåˆ›å»ºæˆåŠŸ")

                if self._install_dependencies():
                    print("   âœ… ä¾èµ–å®‰è£…å®Œæˆ")
                    print("\nğŸ‰ ç¯å¢ƒé‡ç½®å®Œæˆï¼")
                else:
                    print("   âŒ ä¾èµ–å®‰è£…å¤±è´¥")
            else:
                print("   âŒ è™šæ‹Ÿç¯å¢ƒåˆ›å»ºå¤±è´¥")
        else:
            print("ğŸ‘‹ é‡ç½®å·²å–æ¶ˆ")

    def _menu_ollama_management(self):
        """èœå•ï¼šOllamaç®¡ç†"""
        print("\nğŸ¤– Ollamaæ¨¡å‹ç®¡ç†:")
        print("1) æŸ¥çœ‹Ollamaæ¨¡å‹åˆ—è¡¨")
        print("2) å¯¼å…¥è®­ç»ƒå¥½çš„æ¨¡å‹åˆ°Ollama")
        print("3) åˆ é™¤Ollamaæ¨¡å‹")

        choice = input("é€‰æ‹© (1-3): ").strip()

        if choice == "1":
            self._show_ollama_models()
        elif choice == "2":
            self._import_to_ollama()
        elif choice == "3":
            self._delete_ollama_model()

    def _menu_model_testing(self):
        """èœå•ï¼šæ¨¡å‹æµ‹è¯•"""
        self._test_ollama_model()

    def start_training(self, character: str, background: bool = False, export_ollama: bool = False, ollama_name: str = None):
        """å¯åŠ¨è®­ç»ƒ"""
        self._ensure_config_loaded()
        print(f"\nğŸš€ å¯åŠ¨ {character} çš„LoRAè®­ç»ƒ...")

        # è·å–è§’è‰²é…ç½®
        char_config = self.config.get('characters', {}).get(character)
        if not char_config:
            print(f"âŒ æœªæ‰¾åˆ°è§’è‰²é…ç½®: {character}")
            return

        # è·å–æ•°æ®æ–‡ä»¶è·¯å¾„
        train_path, val_path = self.auto_match_files(character)
        if not train_path:
            print(f"âŒ æœªæ‰¾åˆ°è®­ç»ƒæ•°æ®æ–‡ä»¶")
            return

        # è·å–è®­ç»ƒå‚æ•°
        training_params = char_config.get('training_params', {})

        # æ£€æŸ¥æ˜¯å¦å·²æœ‰è®­ç»ƒç»“æœå¹¶å¤„ç†ç”¨æˆ·é€‰æ‹©
        choice = self.handle_existing_training_choice(character)
        if choice == "cancel":
            return

        resume_from_checkpoint = None
        remaining_epochs = None
        if choice == "resume":
            # æ–­ç‚¹ç»­è®­æ¨¡å¼
            lora_dir = Path(f"out/lora_{character}")
            checkpoint_files = list(lora_dir.glob('checkpoint-*'))
            if checkpoint_files:
                # æ‰¾åˆ°æœ€æ–°çš„checkpointï¼ˆä¼˜å…ˆæŒ‰epochï¼Œå…¶æ¬¡æŒ‰ä¿®æ”¹æ—¶é—´ï¼‰
                latest_checkpoint = None
                latest_epoch = -1
                checkpoint_info = []
                
                # æ”¶é›†æ‰€æœ‰checkpointçš„ä¿¡æ¯
                for cp_dir in checkpoint_files:
                    trainer_state_file = cp_dir / "trainer_state.json"
                    if trainer_state_file.exists():
                        try:
                            import json
                            with open(trainer_state_file, 'r', encoding='utf-8') as f:
                                trainer_state = json.load(f)
                                epoch = trainer_state.get('epoch', 0)
                                checkpoint_info.append({
                                    'dir': cp_dir,
                                    'epoch': epoch,
                                    'step': trainer_state.get('global_step', 0),
                                    'mtime': cp_dir.stat().st_mtime
                                })
                        except Exception:
                            # å¦‚æœæ— æ³•è¯»å–ï¼Œè®°å½•ä½†æ ‡è®°epochä¸º-1
                            checkpoint_info.append({
                                'dir': cp_dir,
                                'epoch': -1,
                                'step': 0,
                                'mtime': cp_dir.stat().st_mtime
                            })
                
                if checkpoint_info:
                    # ä¼˜å…ˆé€‰æ‹©epochæœ€å¤§çš„checkpoint
                    valid_checkpoints = [cp for cp in checkpoint_info if cp['epoch'] >= 0]
                    if valid_checkpoints:
                        latest_checkpoint_info = max(valid_checkpoints, key=lambda x: (x['epoch'], x['mtime']))
                        latest_checkpoint = latest_checkpoint_info['dir']
                        latest_epoch = latest_checkpoint_info['epoch']
                    else:
                        # å¦‚æœæ‰€æœ‰checkpointéƒ½æ— æ³•è¯»å–epochï¼Œä½¿ç”¨ä¿®æ”¹æ—¶é—´
                        latest_checkpoint_info = max(checkpoint_info, key=lambda x: x['mtime'])
                        latest_checkpoint = latest_checkpoint_info['dir']
                
                # å¦‚æœè¿˜æ˜¯æ²¡æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨ä¿®æ”¹æ—¶é—´
                if latest_checkpoint is None:
                    latest_checkpoint = max(checkpoint_files, key=lambda x: x.stat().st_mtime)
                
                # ä½¿ç”¨ç»å¯¹è·¯å¾„ï¼Œç¡®ä¿è·¨å¹³å°å…¼å®¹
                resume_from_checkpoint = str(latest_checkpoint.resolve())
                
                # è¯»å–checkpointçš„è®­ç»ƒçŠ¶æ€
                try:
                    import json
                    trainer_state_file = Path(latest_checkpoint) / "trainer_state.json"
                    if trainer_state_file.exists():
                        with open(trainer_state_file, 'r', encoding='utf-8') as f:
                            trainer_state = json.load(f)
                            current_epoch = trainer_state.get('epoch', 0)
                            global_step = trainer_state.get('global_step', 0)
                            log_history = trainer_state.get('log_history', [])
                            last_loss = log_history[-1].get('loss', 'N/A') if log_history else 'N/A'
                            
                            total_epochs = training_params.get('epochs', 3.0)
                            remaining_epochs = max(0.1, total_epochs - current_epoch)
                            
                            print(f"ğŸ“ å°†ä»æ£€æŸ¥ç‚¹ç»§ç»­è®­ç»ƒ: {latest_checkpoint.name}")
                            print(f"   å½“å‰epoch: {current_epoch:.2f}")
                            print(f"   è®­ç»ƒæ­¥æ•°: {global_step}")
                            print(f"   æœ€æ–°loss: {last_loss}")
                            print(f"   å‰©ä½™epochs: {remaining_epochs:.2f}")
                            
                            if current_epoch >= total_epochs - 0.1:
                                print(f"âš ï¸  è­¦å‘Šï¼šè®­ç»ƒå·²æ¥è¿‘å®Œæˆï¼ˆ{current_epoch:.2f}/{total_epochs} epochsï¼‰")
                                print(f"   å»ºè®®ï¼šå¦‚æœéœ€è¦æ›´å¤šè®­ç»ƒï¼Œè¯·å¢åŠ æ€»epochsæ•°")
                            
                            # æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨checkpointä¾›å‚è€ƒ
                            if len(checkpoint_info) > 1:
                                print(f"\nğŸ“‹ æ‰€æœ‰å¯ç”¨checkpoint:")
                                sorted_checkpoints = sorted([cp for cp in checkpoint_info if cp['epoch'] >= 0], 
                                                          key=lambda x: x['epoch'], reverse=True)
                                for cp in sorted_checkpoints[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                                    marker = " â† å°†ä½¿ç”¨" if cp['dir'] == latest_checkpoint else ""
                                    print(f"   {cp['dir'].name}: epoch={cp['epoch']:.2f}, step={cp['step']}{marker}")
                except Exception as e:
                    print(f"âš ï¸  æ— æ³•è¯»å–checkpointçŠ¶æ€: {e}")
                    print(f"ğŸ“ å°†ä»æ£€æŸ¥ç‚¹ç»§ç»­è®­ç»ƒ: {latest_checkpoint.name}")

        # æ„å»ºè®­ç»ƒå‘½ä»¤
        cmd = [
            sys.executable, "train_lora.py",
            "--train_jsonl", train_path,
            "--output_dir", f"out/lora_{character}"
        ]

        # é€‰æ‹©åŸºç¡€æ¨¡å‹ï¼šæ¥è‡ª character_configs.yaml çš„ training_params.base_model
        # ï¼ˆæ³¨æ„ï¼štrain_lora.py çš„é»˜è®¤å€¼æ˜¯ Qwen/Qwen2.5-0.5B-Instructï¼Œä½†å¦‚æœä½ åœ¨ YAML é‡Œé…ç½®äº† base_modelï¼Œ
        # è¿™é‡Œå¿…é¡»æ˜¾å¼ä¼ å…¥ï¼Œå¦åˆ™ä½ ä¿®æ”¹é…ç½®ä¸ä¼šç”Ÿæ•ˆï¼‰
        base_model = training_params.get("base_model")
        if base_model:
            cmd.extend(["--model_name_or_path", str(base_model)])
            print(f"ğŸ¤– Base model: {base_model}")

        # æ·»åŠ éªŒè¯æ•°æ®
        if val_path:
            cmd.extend(["--val_jsonl", val_path])

        # æ·»åŠ è®­ç»ƒå‚æ•°
        # é‡è¦ï¼šå¦‚æœç»§ç»­è®­ç»ƒï¼Œä½¿ç”¨å‰©ä½™epochsæ•°ï¼Œè€Œä¸æ˜¯æ€»epochsæ•°
        if resume_from_checkpoint and remaining_epochs:
            cmd.extend(["--num_train_epochs", str(remaining_epochs)])
            print(f"ğŸ“Š ç»§ç»­è®­ç»ƒå‰©ä½™ {remaining_epochs:.2f} epochs")
        elif 'epochs' in training_params:
            cmd.extend(["--num_train_epochs", str(training_params['epochs'])])
        if 'learning_rate' in training_params:
            cmd.extend(["--learning_rate", str(training_params['learning_rate'])])
        if 'lora_r' in training_params:
            cmd.extend(["--lora_r", str(training_params['lora_r'])])
        if 'lora_alpha' in training_params:
            cmd.extend(["--lora_alpha", str(training_params['lora_alpha'])])
        if 'lora_dropout' in training_params:
            cmd.extend(["--lora_dropout", str(training_params['lora_dropout'])])

        # æ–­ç‚¹ç»­è®­å‚æ•°
        if resume_from_checkpoint:
            cmd.extend(["--resume_from_checkpoint", resume_from_checkpoint])

        # é»˜è®¤å‚æ•°
        cmd.extend([
            "--merge_and_save",  # è‡ªåŠ¨åˆå¹¶å¹¶ä¿å­˜
            "--merged_dir", f"out/merged_{character}"
        ])

        print(f"ğŸ“ æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")

        if background:
            print("ğŸ”„ åå°è®­ç»ƒæ¨¡å¼...")
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                bufsize=1,
                universal_newlines=True
            )

            # å®æ—¶æ˜¾ç¤ºè¾“å‡º
            for line in process.stdout:
                print(line.rstrip())

            process.wait()

            if process.returncode == 0:
                print(f"ğŸ‰ {character} è®­ç»ƒå®Œæˆ!")
                print(f"   LoRAæ¨¡å‹: out/lora_{character}")
                print(f"   åˆå¹¶æ¨¡å‹: out/merged_{character}")
                return_code = process.returncode
            else:
                print(f"âŒ {character} è®­ç»ƒå¤±è´¥ (é€€å‡ºç : {process.returncode})")
                return_code = process.returncode
        else:
            # ç›´æ¥æ‰§è¡Œï¼Œç”¨æˆ·å¯ä»¥çœ‹åˆ°å®æ—¶è¾“å‡º
            result = subprocess.run(cmd)
            if result.returncode == 0:
                print(f"ğŸ‰ {character} è®­ç»ƒå®Œæˆ!")
                print(f"   LoRAæ¨¡å‹: out/lora_{character}")
                print(f"   åˆå¹¶æ¨¡å‹: out/merged_{character}")
            else:
                print(f"âŒ {character} è®­ç»ƒå¤±è´¥")
            return_code = result.returncode

        # è®­ç»ƒå®Œæˆåçš„å‹å¥½æç¤ºå’ŒOllamaå¯¼å…¥å¤„ç†
        if return_code == 0:
            if export_ollama:
                self._export_to_ollama(character, ollama_name)
            else:
                self._show_post_training_options(character, ollama_name)

    def _show_post_training_options(self, character: str, ollama_name: str = None):
        """è®­ç»ƒå®Œæˆåæ˜¾ç¤ºåç»­é€‰é¡¹"""
        print("\n" + "=" * 60)
        print("ğŸ‰ è®­ç»ƒå®Œæˆï¼ä¸‹ä¸€æ­¥æ“ä½œ")
        print("=" * 60)
        print(f"âœ… æ¨¡å‹å·²è®­ç»ƒå®Œæˆï¼š{character}")
        print(f"ğŸ“ æ–‡ä»¶ä½ç½®ï¼šout/merged_{character}/")
        print()
        print("âš ï¸  æ³¨æ„ï¼šæ¨¡å‹ç›®å‰è¿˜æ²¡æœ‰å¯¼å…¥åˆ°Ollamaï¼Œæ— æ³•ç›´æ¥ä½¿ç”¨")
        print()
        print("ğŸ“‹ åç»­é€‰é¡¹ï¼š")
        print("1) ğŸš€ å¯¼å…¥åˆ°Ollamaï¼ˆæ¨èï¼‰- å¯ä»¥ç«‹å³ä½¿ç”¨ ollama run å‘½ä»¤")
        print("2) ğŸ“¦ ç¨åå¯¼å…¥ - è¿”å›ä¸»èœå•ï¼Œé€šè¿‡ 4)Ollamaæ¨¡å‹ç®¡ç† å¯¼å…¥")
        print("3) ğŸ  è¿”å›ä¸»èœå• - ç»§ç»­å…¶ä»–æ“ä½œ")
        print("4) ğŸ‘‹ é€€å‡ºç³»ç»Ÿ")
        print()

        while True:
            try:
                choice = input("è¯·é€‰æ‹© (1-4): ").strip()

                if choice == "1":
                    # è¯¢é—®Ollamaæ¨¡å‹åç§°
                    if not ollama_name:
                        default_name = f"{character}-lora"
                        ollama_name = input(f"è¯·è¾“å…¥Ollamaæ¨¡å‹åç§° (é»˜è®¤: {default_name}): ").strip()
                        if not ollama_name:
                            ollama_name = default_name

                    success = self._export_to_ollama(character, ollama_name)
                    if success:
                        print(f"\nğŸ‰ å¯¼å…¥æˆåŠŸï¼ç°åœ¨å¯ä»¥ä½¿ç”¨ï¼š")
                        print(f"   ollama run {ollama_name}")
                        print()
                        input("æŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")
                    break

                elif choice == "2":
                    print("\nğŸ’¡ æç¤ºï¼šç¨åå¯é€šè¿‡ä¸»èœå• -> 4)Ollamaæ¨¡å‹ç®¡ç† -> 2)å¯¼å…¥è®­ç»ƒå¥½çš„æ¨¡å‹ æ¥å¯¼å…¥")
                    input("æŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")
                    break

                elif choice == "3":
                    print("\nğŸ  è¿”å›ä¸»èœå•...")
                    break

                elif choice == "4":
                    print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼")
                    sys.exit(0)

                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥1-4")

            except (KeyboardInterrupt, EOFError):
                print("\n\nğŸ  è¿”å›ä¸»èœå•...")
                break

    def _export_to_ollama(self, character: str, ollama_name: str = None):
        """å¯¼å‡ºåˆ°Ollama"""
        if not ollama_name:
            ollama_name = f"{character}-lora"

        print(f"\nğŸš€ å¯¼å‡ºåˆ°Ollama: {ollama_name}")

        # ä½¿ç”¨ç»å¯¹è·¯å¾„å¹¶éªŒè¯ç›®å½•å­˜åœ¨
        merged_dir = Path(f"out/merged_{character}").resolve()
        if not merged_dir.exists():
            print(f"âŒ åˆå¹¶æ¨¡å‹ä¸å­˜åœ¨: {merged_dir}")
            print("   è¯·ç¡®ä¿è®­ç»ƒæ—¶ä½¿ç”¨äº† --merge_and_save å‚æ•°")
            return False

        # é‡è¦è¯´æ˜ï¼š
        # Ollama çš„ Modelfile `FROM` éœ€è¦æ˜¯ Ollama æ¨¡å‹åæˆ–æœ¬åœ° GGUF æ–‡ä»¶è·¯å¾„ã€‚
        # HuggingFace åˆå¹¶ç›®å½•ï¼ˆconfig.json + safetensorsï¼‰ä¸èƒ½å¯é åœ°ç›´æ¥ä½œä¸º `FROM <dir>` ä½¿ç”¨ã€‚
        # è¿™ä¼šå¯¼è‡´â€œçœ‹ä¼¼å¯¼å…¥æˆåŠŸï¼Œä½†å®é™…è¿è¡Œçš„ä¸æ˜¯è®­ç»ƒåçš„æƒé‡â€ï¼Œå‡ºç°ä½ çœ‹åˆ°çš„â€œåˆ·é¢˜/ä¸æ­è¾¹â€è¾“å‡ºã€‚
        gguf_files = sorted(merged_dir.glob("*.gguf"))
        if not gguf_files:
            print(f"âš ï¸  æœªæ‰¾åˆ° GGUF æ–‡ä»¶ï¼ˆ{merged_dir}/*.ggufï¼‰ï¼Œå°†å°è¯•è‡ªåŠ¨è½¬æ¢...")

            gguf_out = (merged_dir / f"{character}.gguf").resolve()
            # å¦‚æœå·²æœ‰åŒåä½†ä¸ºç©º/æŸåï¼Œå…ˆåˆ 
            if gguf_out.exists() and gguf_out.stat().st_size == 0:
                try:
                    gguf_out.unlink()
                except Exception:
                    pass

            ok = self._convert_merged_to_gguf(merged_dir=merged_dir, gguf_out=gguf_out, outtype="f16")
            if not ok:
                print("\nâŒ è‡ªåŠ¨è½¬æ¢å¤±è´¥ã€‚ä½ ä¹Ÿå¯ä»¥æ‰‹åŠ¨è½¬æ¢ï¼š")
                print(f"   python /path/to/llama.cpp/convert_hf_to_gguf.py \"{merged_dir}\" --outtype f16 --outfile \"{gguf_out}\"")
                return False

            gguf_files = sorted(merged_dir.glob("*.gguf"))
            if not gguf_files:
                print("âŒ è‡ªåŠ¨è½¬æ¢å®Œæˆä½†æœªå‘ç° .gguf æ–‡ä»¶")
                return False

        gguf_path = gguf_files[-1].resolve()
        print(f"ğŸ“¦ å°†ä½¿ç”¨ GGUF: {gguf_path}")

        # åˆ›å»ºOllama Modelfile (ä½¿ç”¨å®Œæ•´è§’è‰²é…ç½®å’Œä¼˜åŒ–æ¨ç†å‚æ•°)
        self._ensure_config_loaded()
        char_config = self.config.get('characters', {}).get(character, {})

        # ç®€åŒ–system_promptï¼Œé¿å…æ ¼å¼åŒ–çš„åˆ—è¡¨ï¼ˆé˜²æ­¢æ¨¡å‹è¾“å‡ºæ ¼å¼æ ‡è®°ï¼‰
        raw_system_prompt = char_config.get('system_prompt', f'ä½ æ˜¯{character}ï¼Œè¯·ä¿æŒè§’è‰²ç‰¹å¾è¿›è¡Œå¯¹è¯ã€‚').strip()
        
        # ç®€åŒ–system promptï¼šç§»é™¤æ ¼å¼åŒ–çš„åˆ—è¡¨ï¼Œåªä¿ç•™æ ¸å¿ƒè§’è‰²è®¾å®š
        # é¿å…æ¨¡å‹å­¦ä¼šè¾“å‡º"ä½ çš„ç‰¹ç‚¹ï¼š"ã€"å¤–è¡¨ï¼š"ç­‰æ ¼å¼æ ‡è®°
        system_prompt = raw_system_prompt
        if "ä½ çš„ç‰¹ç‚¹ï¼š" in system_prompt or "- å¤–è¡¨ï¼š" in system_prompt:
            # æå–æ ¸å¿ƒè§’è‰²è®¾å®šï¼Œç§»é™¤æ ¼å¼åŒ–å†…å®¹
            lines = system_prompt.split('\n')
            simplified_lines = []
            skip_format = False
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                # è·³è¿‡æ ¼å¼åŒ–çš„åˆ—è¡¨
                if line.startswith('- ') or line.startswith('ä½ çš„ç‰¹ç‚¹ï¼š') or line.startswith('å¤–è¡¨ï¼š') or line.startswith('æ€§æ ¼ï¼š') or line.startswith('äº’åŠ¨ï¼š'):
                    skip_format = True
                    continue
                if skip_format and not line.startswith('è¯·'):
                    continue
                skip_format = False
                # ä¿ç•™æ ¸å¿ƒè®¾å®š
                if 'ä½ æ˜¯' in line or 'è¯·' in line:
                    simplified_lines.append(line)
            
            if simplified_lines:
                # æ„å»ºç®€åŒ–çš„system prompt
                system_prompt = ' '.join(simplified_lines)
                # è¿›ä¸€æ­¥ç®€åŒ–ï¼šç§»é™¤å¤šä½™çš„æ ¼å¼
                system_prompt = system_prompt.replace('ä½ çš„ç‰¹ç‚¹ï¼š', '').replace('å¤–è¡¨ï¼š', '').replace('æ€§æ ¼ï¼š', '').replace('äº’åŠ¨ï¼š', '')
                system_prompt = ' '.join(system_prompt.split())  # æ¸…ç†å¤šä½™ç©ºæ ¼
            else:
                # å¦‚æœç®€åŒ–å¤±è´¥ï¼Œä½¿ç”¨æœ€åŸºæœ¬çš„è®¾å®š
                system_prompt = f"ä½ æ˜¯{char_config.get('name', character)}ï¼Œè¯·æŒ‰ç…§è§’è‰²æ€§æ ¼è¿›è¡Œå¯¹è¯ã€‚"

        # å¼ºçº¦æŸï¼šé˜²æ­¢è¾“å‡ºâ€œé¢˜ç›®/ç­”æ¡ˆ/è§£æ/é€‰æ‹©é¢˜â€ç­‰è·‘åå†…å®¹ï¼Œä»¥åŠé¿å…è¾“å‡ºè§’è‰²æ ‡ç­¾
        # è¿™äº›å†…å®¹é€šå¸¸æ˜¯åº•åº§æ¨¡å‹çš„â€œé€šç”¨åº”è¯•/è§£é¢˜â€å€¾å‘ï¼Œè§’è‰²æ‰®æ¼”åœºæ™¯ä¸‹éœ€è¦æ˜ç¡®ç¦æ­¢ã€‚
        system_prompt = (
            f"{system_prompt}\n\n"
            "è¾“å‡ºè§„åˆ™ï¼š\n"
            "1) ä½ å¿…é¡»ç”¨ç¬¬ä¸€äººç§°ï¼Œä»¥è§’è‰²å£å»ä¸ç”¨æˆ·å¯¹è¯ã€‚\n"
            "2) ç¦æ­¢è¾“å‡ºï¼šé¢˜ç›®ã€ç­”æ¡ˆã€è§£æã€åˆ¤æ–­é¢˜ã€é€‰æ‹©é¢˜ã€A/B/C/D é€‰é¡¹ã€å¡«ç©ºé¢˜ã€ææ–™åˆ†æç­‰åº”è¯•å†…å®¹ã€‚\n"
            "3) ç¦æ­¢è¾“å‡ºï¼šsystem/user/assistant ç­‰è§’è‰²æ ‡ç­¾æˆ–æç¤ºè¯æ ¼å¼ã€‚\n"
            "4) å›å¤è‡ªç„¶ç®€çŸ­ï¼Œé¿å…é‡å¤åŒä¸€å¥è¯ã€‚\n"
            "5) é‡åˆ°å®¢è§‚é—®é¢˜ï¼ˆå¦‚æ•°å­¦ã€æ—¶é—´ã€å¸¸è¯†ï¼‰ï¼šå¿…é¡»å…ˆç»™å‡ºå‡†ç¡®ç­”æ¡ˆï¼›ä¸è¦èƒ¡ç¼–ã€‚\n"
            "   ä¾‹å¦‚ï¼šç”¨æˆ·é—®â€œ1+1ç­‰äºå‡ â€ï¼Œä½ è¦å›ç­”â€œ2â€ï¼Œç„¶åå†ç”¨æ—æ €å£å»è¡¥ä¸€å¥ä¹Ÿå¯ä»¥ã€‚\n"
        )
        
        # è·å–è§’è‰²çš„ä¸­æ–‡åç§°ç”¨äºæ˜¾ç¤º
        char_name = char_config.get('name', character)

        print(f"ğŸ“ è§’è‰²é…ç½®: {char_name}")
        print(f"ğŸ“„ System Prompt (åŸå§‹): {raw_system_prompt[:100]}..." if len(raw_system_prompt) > 100 else f"ğŸ“„ System Prompt (åŸå§‹): {raw_system_prompt}")
        print(f"ğŸ“„ System Prompt (ç®€åŒ–): {system_prompt[:100]}..." if len(system_prompt) > 100 else f"ğŸ“„ System Prompt (ç®€åŒ–): {system_prompt}")

        # ä¼˜åŒ–æ¨ç†å‚æ•°ï¼Œæ›´é€‚åˆè§’è‰²æ‰®æ¼”
        # å…³é”®ï¼šæ˜¾å¼æŒ‡å®š Qwen çš„å¯¹è¯æ¨¡æ¿ï¼Œé¿å… Ollama ä½¿ç”¨ä¸åŒ¹é…çš„é»˜è®¤æ¨¡æ¿å¯¼è‡´è¾“å‡ºâ€œsystem/å‚è€ƒç­”æ¡ˆ/åˆ·é¢˜é£â€ã€‚
        # è¿™é‡Œç”¨ Qwen2 çš„ <|im_start|>/<|im_end|> æ ¼å¼ï¼Œå…¼å®¹å¤šè½®å¯¹è¯ã€‚
        template = r"""{{- if .System -}}<|im_start|>system
{{ .System }}<|im_end|>
{{- else -}}<|im_start|>system
You are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>
{{- end -}}
{{- range .Messages }}
{{- if eq .Role "system" }}<|im_start|>system
{{ .Content }}<|im_end|>
{{- else if eq .Role "user" }}<|im_start|>user
{{ .Content }}<|im_end|>
{{- else if eq .Role "assistant" }}<|im_start|>assistant
{{ .Content }}<|im_end|>
{{- end }}
{{- end }}
<|im_start|>assistant
"""

        modelfile_content = f"""FROM {gguf_path}
# æ›´ç¨³çš„è§’è‰²æ‰®æ¼”æ¨ç†å‚æ•°ï¼ˆå‡å°‘è·‘åä¸é•¿ç¯‡åˆ·é¢˜ï¼‰
PARAMETER temperature 0.5
PARAMETER top_p 0.9
PARAMETER top_k 40
PARAMETER repeat_penalty 1.15
PARAMETER num_predict 256
PARAMETER stop "<|im_end|>"

TEMPLATE \"\"\"{template}\"\"\"
SYSTEM \"\"\"{system_prompt}\"\"\"
"""

        try:
            # ä½¿ç”¨ollama createå‘½ä»¤
            import tempfile
            with tempfile.NamedTemporaryFile(mode='w', suffix='.modelfile', delete=False) as f:
                f.write(modelfile_content)
                modelfile_path = f.name

            cmd = f"ollama create {ollama_name} -f {modelfile_path}"
            print(f"æ‰§è¡Œ: {cmd}")

            result = subprocess.run(cmd, shell=True, capture_output=True, text=True)

            if result.returncode == 0:
                print(f"âœ… æˆåŠŸå¯¼å…¥åˆ°Ollama: {ollama_name}")
                print(f"ğŸ§ª æµ‹è¯•å‘½ä»¤: ollama run {ollama_name}")
                return True
            else:
                print(f"âŒ å¯¼å…¥å¤±è´¥: {result.stderr}")
                return False

        except Exception as e:
            print(f"âŒ å¯¼å‡ºè¿‡ç¨‹å‡ºé”™: {e}")
            return False

    def _show_dataset_scan(self):
        """æ˜¾ç¤ºæ•°æ®é›†æ‰«æç»“æœ"""
        dataset_info = self.scan_datasets()
        print("\nğŸ“Š æ•°æ®é›†æ‰«æç»“æœ:")
        print("=" * 50)
        for char_name, info in dataset_info.items():
            print(f"\nğŸ“ {char_name}/")
            print(f"   è®­ç»ƒæ–‡ä»¶: {len(info['train_files'])}ä¸ª")
            for tf in info['train_files']:
                print(f"      ğŸ“„ {tf.name} ({self.count_samples(tf)}æ ·æœ¬)")
            print(f"   éªŒè¯æ–‡ä»¶: {len(info['val_files'])}ä¸ª")
            for vf in info['val_files']:
                print(f"      ğŸ“„ {vf.name} ({self.count_samples(vf)}æ ·æœ¬)")

    def _validate_all_datasets(self):
        """éªŒè¯æ‰€æœ‰æ•°æ®é›†æ ¼å¼"""
        dataset_info = self.scan_datasets()
        print("\nğŸ” éªŒè¯æ•°æ®é›†æ ¼å¼...")

        for char_name, info in dataset_info.items():
            print(f"\nğŸ“ {char_name}:")

            for file_list, file_type in [(info['train_files'], 'è®­ç»ƒ'), (info['val_files'], 'éªŒè¯')]:
                for file_path in file_list:
                    valid, msg = self.validate_jsonl(file_path)
                    status = "âœ…" if valid else "âŒ"
                    print(f"   {status} {file_type}æ–‡ä»¶ {file_path.name}: {msg}")

    def _show_dataset_stats(self):
        """æ˜¾ç¤ºæ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
        dataset_info = self.scan_datasets()
        print("\nğŸ“Š æ•°æ®é›†ç»Ÿè®¡:")
        print("=" * 50)

        total_train = 0
        total_val = 0

        for char_name, info in dataset_info.items():
            train_count = sum(self.count_samples(f) for f in info['train_files'])
            val_count = sum(self.count_samples(f) for f in info['val_files'])

            print(f"ğŸ“ {char_name}: {train_count}è®­ç»ƒæ ·æœ¬ + {val_count}éªŒè¯æ ·æœ¬")
            total_train += train_count
            total_val += val_count

        print(f"\nğŸ“ˆ æ€»è®¡: {total_train}è®­ç»ƒæ ·æœ¬ + {total_val}éªŒè¯æ ·æœ¬")

    def _check_training_environment(self):
        """æ£€æŸ¥è®­ç»ƒç¯å¢ƒ"""
        print("\nğŸ” æ£€æŸ¥è®­ç»ƒç¯å¢ƒ...")

        try:
            # æ£€æŸ¥Pythonç‰ˆæœ¬
            import sys
            print(f"   ğŸ Python: {sys.version}")

            # æ£€æŸ¥å…³é”®åº“
            libs = ['torch', 'transformers', 'peft', 'trl', 'datasets']
            for lib in libs:
                try:
                    module = __import__(lib)
                    version = getattr(module, '__version__', 'unknown')
                    print(f"   âœ… {lib}: {version}")
                except ImportError:
                    print(f"   âŒ {lib}: æœªå®‰è£…")

            # æ£€æŸ¥è®¾å¤‡
            try:
                import torch
                device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
                print(f"   ğŸ–¥ï¸  è®¾å¤‡: {device}")
            except:
                print(f"   âš ï¸  è®¾å¤‡: æ— æ³•æ£€æµ‹")

        except Exception as e:
            print(f"   âŒ ç¯å¢ƒæ£€æŸ¥å¤±è´¥: {e}")

    def first_time_setup(self):
        """é¦–æ¬¡è¿è¡Œå¼•å¯¼è®¾ç½®"""
        print("ğŸš€ LoRAæ™ºèƒ½è®­ç»ƒç³»ç»Ÿ - é¦–æ¬¡è¿è¡Œæ£€æµ‹")
        print("=" * 50)

        # å…¨é¢ç¯å¢ƒæ£€æµ‹
        issues = self._check_environment_comprehensive()

        if not issues:
            print("\nğŸ‰ ç¯å¢ƒæ£€æŸ¥å®Œæˆ - æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼")
            print("ç°åœ¨å¯ä»¥å¼€å§‹ä½¿ç”¨è®­ç»ƒç³»ç»Ÿäº†ï¼\n")
            self.show_main_menu()
            return

        # æ˜¾ç¤ºé—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ
        print(f"\nâš ï¸  å‘ç° {len(issues)} ä¸ªç¯å¢ƒé—®é¢˜ï¼Œéœ€è¦åˆå§‹åŒ–è®¾ç½®")
        print("\nğŸ“‹ æ¨èæ“ä½œæµç¨‹ï¼š")
        if 'python_version' in issues:
            print("1ï¸âƒ£ å‡çº§Pythonç‰ˆæœ¬ (å¿…éœ€)")
        if 'virtual_env' in issues:
            print("1ï¸âƒ£ åˆ›å»ºè™šæ‹Ÿç¯å¢ƒå¹¶å®‰è£…ä¾èµ– (å¿…éœ€)")
        if 'dependencies' in issues:
            print("2ï¸âƒ£ å®‰è£…è®­ç»ƒä¾èµ– (å¿…éœ€)")
        if 'ollama' in issues:
            print("3ï¸âƒ£ å®‰è£…OllamaæœåŠ¡ (è®­ç»ƒå®Œæˆåå¯¼å…¥æ¨¡å‹éœ€è¦)")

        try:
            # è¯¢é—®æ˜¯å¦è‡ªåŠ¨ä¿®å¤
            if 'python_version' in issues:
                print("\nâŒ Pythonç‰ˆæœ¬è¿‡ä½ï¼Œè¯·å…ˆå‡çº§Pythonå†è¿è¡Œ")
                self._show_python_upgrade_guide()
                return

            confirm = input("\næ˜¯å¦ç«‹å³è¿›è¡Œç¯å¢ƒåˆå§‹åŒ–? (Y/n): ").strip().lower()
            if confirm in ['', 'y', 'yes']:
                success = self._auto_setup_environment(issues)
                if success:
                    print("\nğŸ‰ ç¯å¢ƒå‡†å¤‡å®Œæˆï¼")

                    cont = input("ç»§ç»­è¿›å…¥è®­ç»ƒç³»ç»Ÿ? (Y/n): ").strip().lower()
                    if cont in ['', 'y', 'yes']:
                        self.show_main_menu()
                else:
                    print("\nâš ï¸  ç¯å¢ƒå‡†å¤‡é‡åˆ°é—®é¢˜ï¼Œè¯·æŸ¥çœ‹ä¸Šæ–¹é”™è¯¯ä¿¡æ¯")
                    print("å¯ä»¥å°è¯•æ‰‹åŠ¨è§£å†³é—®é¢˜åé‡æ–°è¿è¡Œ")
            else:
                print("\nğŸ’¡ æ‚¨å¯ä»¥ç¨åä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è¿›è¡Œç¯å¢ƒå‡†å¤‡ï¼š")
                print("   python smart_train.py --setup")

        except (KeyboardInterrupt, EOFError):
            print("\n\nğŸ‘‹ è®¾ç½®å·²å–æ¶ˆ")

    def _check_environment_comprehensive(self):
        """å…¨é¢ç¯å¢ƒæ£€æŸ¥"""
        print("\nğŸ” æ­£åœ¨æ£€æŸ¥è¿è¡Œç¯å¢ƒ...")

        issues = []

        # 1. ç³»ç»Ÿå¹³å°æ£€æµ‹
        import platform
        system = platform.system()
        print(f"   ğŸ’» æ“ä½œç³»ç»Ÿ: {system} {platform.release()}")

        # 2. Pythonç‰ˆæœ¬æ£€æŸ¥
        python_status = self._check_python_version()
        if not python_status['compatible']:
            issues.append('python_version')

        # 3. è™šæ‹Ÿç¯å¢ƒæ£€æµ‹
        venv_status = self._check_virtual_environment()
        if not venv_status['active'] and not venv_status['exists']:
            issues.append('virtual_env')
        elif venv_status['exists'] and not venv_status['active']:
            print(f"   ğŸ’¡ æç¤º: æ£€æµ‹åˆ°è™šæ‹Ÿç¯å¢ƒä½†æœªæ¿€æ´»ï¼Œè¯·è¿è¡Œ: source .venv/bin/activate")

        # 4. ä¾èµ–æ£€æŸ¥ï¼ˆåªæœ‰åœ¨è™šæ‹Ÿç¯å¢ƒæ¿€æ´»æ—¶æ‰æ£€æŸ¥ï¼‰
        if venv_status['active'] or not Path('.venv').exists():
            deps_status = self._check_dependencies_simple()
            if deps_status['missing']:
                issues.append('dependencies')
        else:
            print(f"   ğŸ“š è®­ç»ƒä¾èµ–: éœ€è¦æ¿€æ´»è™šæ‹Ÿç¯å¢ƒåæ£€æŸ¥")

        # 5. OllamaæœåŠ¡æ£€æµ‹
        ollama_status = self._check_ollama_service()
        if not ollama_status['available']:
            issues.append('ollama')

        return issues

    def _check_python_version(self):
        """æ£€æŸ¥Pythonç‰ˆæœ¬"""
        import sys

        version = sys.version_info
        version_str = f"{version.major}.{version.minor}.{version.micro}"

        # è¦æ±‚Python >= 3.10
        compatible = version.major >= 3 and version.minor >= 10

        if compatible:
            print(f"   ğŸ Python: {version_str} âœ…")
        else:
            print(f"   ğŸ Python: {version_str} âŒ (éœ€è¦ â‰¥ 3.10)")

        return {
            'compatible': compatible,
            'version': version_str,
            'major': version.major,
            'minor': version.minor
        }

    def _check_virtual_environment(self):
        """æ£€æŸ¥è™šæ‹Ÿç¯å¢ƒçŠ¶æ€"""
        import sys

        # æ£€æŸ¥æ˜¯å¦åœ¨è™šæ‹Ÿç¯å¢ƒä¸­
        in_venv = (hasattr(sys, 'real_prefix') or
                   (hasattr(sys, 'base_prefix') and sys.base_prefix != sys.prefix))

        venv_exists = Path('.venv').exists()

        if in_venv and venv_exists:
            print(f"   ğŸ“¦ è™šæ‹Ÿç¯å¢ƒ: å·²æ¿€æ´» âœ…")
        elif venv_exists:
            print(f"   ğŸ“¦ è™šæ‹Ÿç¯å¢ƒ: å­˜åœ¨ä½†æœªæ¿€æ´» âš ï¸")
        elif in_venv:
            print(f"   ğŸ“¦ è™šæ‹Ÿç¯å¢ƒ: åœ¨å…¶ä»–è™šæ‹Ÿç¯å¢ƒä¸­ âš ï¸")
        else:
            print(f"   ğŸ“¦ è™šæ‹Ÿç¯å¢ƒ: ä¸å­˜åœ¨ âŒ")

        return {
            'active': in_venv,
            'exists': venv_exists,
            'path': Path('.venv').resolve() if venv_exists else None
        }

    def _check_dependencies_simple(self):
        """ç®€å•ä¾èµ–æ£€æŸ¥"""
        required_libs = ['torch', 'transformers', 'peft', 'trl', 'datasets']
        missing = []
        installed = []

        for lib in required_libs:
            try:
                module = __import__(lib)
                version = getattr(module, '__version__', 'unknown')
                print(f"   ğŸ“š {lib}: {version} âœ…")
                installed.append(lib)
            except ImportError:
                print(f"   ğŸ“š {lib}: æœªå®‰è£… âŒ")
                missing.append(lib)

        return {
            'missing': missing,
            'installed': installed
        }

    def _check_ollama_service(self):
        """æ£€æŸ¥OllamaæœåŠ¡çŠ¶æ€"""
        try:
            result = subprocess.run(['ollama', '--version'],
                                  capture_output=True, text=True, timeout=5)
            if result.returncode == 0:
                version = result.stdout.strip().split()[-1] if result.stdout.strip() else "æœªçŸ¥ç‰ˆæœ¬"
                print(f"   ğŸ¤– OllamaæœåŠ¡: {version} âœ…")
                return {'available': True, 'version': version}

        except (subprocess.TimeoutExpired, FileNotFoundError, subprocess.CalledProcessError):
            print(f"   ğŸ¤– OllamaæœåŠ¡: æœªå®‰è£… âš ï¸ (è®­ç»ƒåå¯¼å…¥æ¨¡å‹éœ€è¦)")

        return {'available': False, 'version': None}

    def _show_python_upgrade_guide(self):
        """æ˜¾ç¤ºPythonå‡çº§æŒ‡å—"""
        import platform
        system = platform.system().lower()

        print(f"\nğŸ’¡ Pythonå‡çº§æŒ‡å—:")
        if 'darwin' in system:  # macOS
            print("   # macOS (æ¨èä½¿ç”¨Homebrew)")
            print("   brew install python@3.11")
            print("   # æˆ–ä½¿ç”¨pyenv")
            print("   brew install pyenv")
            print("   pyenv install 3.11.5")
            print("   pyenv global 3.11.5")
        elif 'linux' in system:  # Linux
            print("   # Ubuntu/Debian")
            print("   sudo apt update")
            print("   sudo apt install python3.11 python3.11-venv python3.11-pip")
            print("   # CentOS/RHEL")
            print("   sudo yum install python3.11")
        elif 'windows' in system:  # Windows
            print("   # Windows")
            print("   1. è®¿é—® https://www.python.org/downloads/")
            print("   2. ä¸‹è½½Python 3.11+å®‰è£…åŒ…")
            print("   3. å®‰è£…æ—¶å‹¾é€‰ 'Add Python to PATH'")

        print(f"\nç„¶åé‡æ–°è¿è¡Œ: python3.11 smart_train.py")

    def _auto_setup_environment(self, issues):
        """è‡ªåŠ¨ç¯å¢ƒè®¾ç½®"""
        print(f"\nğŸ”§ å¼€å§‹ç¯å¢ƒåˆå§‹åŒ–...")

        success = True

        # 1. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
        if 'virtual_env' in issues:
            print(f"\n1ï¸âƒ£ åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ...")
            if self._create_virtual_environment():
                print(f"   âœ… è™šæ‹Ÿç¯å¢ƒåˆ›å»ºæˆåŠŸ: .venv/")
            else:
                print(f"   âŒ è™šæ‹Ÿç¯å¢ƒåˆ›å»ºå¤±è´¥")
                success = False
                return False

        # 2. å®‰è£…ä¾èµ–
        if 'dependencies' in issues or 'virtual_env' in issues:
            print(f"\n2ï¸âƒ£ å®‰è£…è®­ç»ƒä¾èµ–...")
            if self._install_dependencies():
                print(f"   âœ… ä¾èµ–å®‰è£…å®Œæˆ")
            else:
                print(f"   âŒ ä¾èµ–å®‰è£…å¤±è´¥")
                success = False

        # 3. éªŒè¯ç¯å¢ƒ
        if success:
            print(f"\n3ï¸âƒ£ éªŒè¯ç¯å¢ƒ...")
            issues_after = self._check_environment_comprehensive()
            # å¿½ç•¥ollamaé—®é¢˜ï¼Œå› ä¸ºä¸æ˜¯å¿…éœ€çš„
            critical_issues = [i for i in issues_after if i != 'ollama']
            if not critical_issues:
                print(f"   âœ… ç¯å¢ƒéªŒè¯é€šè¿‡")
            else:
                print(f"   âš ï¸  ä»æœ‰é—®é¢˜: {', '.join(critical_issues)}")
                success = False

        # 4. Ollamaæç¤º
        if 'ollama' in issues:
            print(f"\nğŸ’¡ å…³äºOllamaæœåŠ¡ï¼š")
            print(f"   è®­ç»ƒå®Œæˆåéœ€è¦Ollamaæ¥ä½¿ç”¨æ¨¡å‹")
            print(f"   å®‰è£…æ–¹æ³•: https://ollama.com/")
            print(f"   ä¹Ÿå¯ä»¥è®­ç»ƒå®Œæˆåå†å®‰è£…")

        return success

    def _create_virtual_environment(self):
        """åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ"""
        try:
            # ä½¿ç”¨å½“å‰Pythonåˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
            result = subprocess.run([sys.executable, '-m', 'venv', '.venv'],
                                  capture_output=True, text=True, timeout=60)
            return result.returncode == 0
        except Exception as e:
            print(f"   åˆ›å»ºè™šæ‹Ÿç¯å¢ƒæ—¶å‡ºé”™: {e}")
            return False

    def _install_dependencies(self):
        """å®‰è£…ä¾èµ–"""
        try:
            # ç¡®å®špythonå¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„
            if Path('.venv').exists():
                if sys.platform == 'win32':
                    python_exe = Path('.venv/Scripts/python.exe')
                else:
                    python_exe = Path('.venv/bin/python')
            else:
                python_exe = Path(sys.executable)

            if not python_exe.exists():
                print(f"   âŒ Pythonå¯æ‰§è¡Œæ–‡ä»¶ä¸å­˜åœ¨: {python_exe}")
                return False

            # å‡çº§pip
            print(f"   ğŸ“¦ å‡çº§pipå·¥å…·...")
            result = subprocess.run([str(python_exe), '-m', 'pip', 'install', '-U', 'pip'],
                                  capture_output=True, text=True, timeout=120)

            if result.returncode != 0:
                print(f"   âš ï¸  pipå‡çº§å¤±è´¥: {result.stderr}")

            # å®‰è£…requirements.txt
            if Path('requirements.txt').exists():
                print(f"   ğŸ“¦ å®‰è£…è®­ç»ƒä¾èµ–...")
                result = subprocess.run([str(python_exe), '-m', 'pip', 'install', '-r', 'requirements.txt'],
                                      capture_output=True, text=True, timeout=300)

                if result.returncode == 0:
                    return True
                else:
                    print(f"   âŒ ä¾èµ–å®‰è£…å¤±è´¥:")
                    print(f"   {result.stderr}")

                    # æä¾›è§£å†³æ–¹æ¡ˆ
                    print(f"\n   ğŸ’¡ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
                    print(f"   1) ç½‘ç»œé—®é¢˜ - ä½¿ç”¨å›½å†…é•œåƒ:")
                    print(f"      {python_exe} -m pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -r requirements.txt")
                    print(f"   2) æ‰‹åŠ¨å®‰è£…:")
                    print(f"      {python_exe} -m pip install torch transformers peft trl datasets")
                    return False
            else:
                print(f"   âŒ requirements.txt æ–‡ä»¶ä¸å­˜åœ¨")
                return False

        except Exception as e:
            print(f"   å®‰è£…ä¾èµ–æ—¶å‡ºé”™: {e}")
            return False

    def _check_disk_usage(self):
        """æ£€æŸ¥ç£ç›˜ä½¿ç”¨æƒ…å†µ"""
        print("\nğŸ’½ ç£ç›˜ä½¿ç”¨æƒ…å†µ...")

        dirs_to_check = ['out/', 'datasets/', '.cache/']

        for dir_name in dirs_to_check:
            dir_path = Path(dir_name)
            if dir_path.exists():
                total_size = sum(f.stat().st_size for f in dir_path.rglob('*') if f.is_file())
                if total_size > 1024**3:  # > 1GB
                    size_str = f"{total_size / (1024**3):.1f} GB"
                else:
                    size_str = f"{total_size / (1024**2):.1f} MB"
                print(f"   ğŸ“ {dir_name}: {size_str}")
            else:
                print(f"   ğŸ“ {dir_name}: ä¸å­˜åœ¨")

    def _show_ollama_models(self):
        """æ˜¾ç¤ºOllamaæ¨¡å‹åˆ—è¡¨"""
        print("\nğŸ¤– Ollamaæ¨¡å‹åˆ—è¡¨:")
        try:
            result = subprocess.run(['ollama', 'list'], capture_output=True, text=True)
            if result.returncode == 0:
                print(result.stdout)
            else:
                print("âŒ æ— æ³•è·å–Ollamaæ¨¡å‹åˆ—è¡¨")
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")

    def _import_to_ollama(self):
        """å¯¼å…¥æ¨¡å‹åˆ°Ollama"""
        self._ensure_config_loaded()
        print("\nğŸš€ å¯¼å…¥æ¨¡å‹åˆ°Ollama")

        # æ‰«æå¯ç”¨çš„åˆå¹¶æ¨¡å‹
        out_dir = Path("out")
        if not out_dir.exists():
            print("âŒ outç›®å½•ä¸å­˜åœ¨ï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹")
            return

        merged_dirs = list(out_dir.glob("merged_*"))
        if not merged_dirs:
            print("âŒ æœªæ‰¾åˆ°å·²è®­ç»ƒçš„æ¨¡å‹")
            return

        print("\nğŸ“‹ å¯å¯¼å…¥çš„æ¨¡å‹:")
        for i, dir_path in enumerate(merged_dirs, 1):
            character = dir_path.name.replace("merged_", "")

            # å°è¯•ä»é…ç½®æ–‡ä»¶è·å–ä¸­æ–‡åç§°å’Œæè¿°
            char_config = self.config.get('characters', {}).get(character, {})
            chinese_name = char_config.get('name', character)  # å¦‚æœæ²¡æœ‰é…ç½®ï¼Œæ˜¾ç¤ºè‹±æ–‡å
            description = char_config.get('description', 'æœªé…ç½®')

            # æ˜¾ç¤ºï¼šåºå·) ä¸­æ–‡å (è‹±æ–‡ä»£ç ) - æè¿°
            print(f"   {i}) {chinese_name} ({character}) - {description}")

        try:
            choice = int(input(f"\nè¯·é€‰æ‹©æ¨¡å‹ (1-{len(merged_dirs)}): "))
            if 1 <= choice <= len(merged_dirs):
                selected_dir = merged_dirs[choice - 1]
                character = selected_dir.name.replace("merged_", "")

                # è·å–ä¸­æ–‡åç§°ç”¨äºç¡®è®¤
                char_config = self.config.get('characters', {}).get(character, {})
                chinese_name = char_config.get('name', character)

                print(f"\nâœ… å·²é€‰æ‹©: {chinese_name} ({character})")

                ollama_name = input(f"Ollamaæ¨¡å‹åç§° (é»˜è®¤: {character}-lora): ").strip()
                if not ollama_name:
                    ollama_name = f"{character}-lora"

                self._export_to_ollama(character, ollama_name)
        except (ValueError, IndexError):
            print("âŒ æ— æ•ˆé€‰æ‹©")

    def _delete_ollama_model(self):
        """åˆ é™¤Ollamaæ¨¡å‹"""
        print("\nğŸ—‘ï¸ åˆ é™¤Ollamaæ¨¡å‹")
        model_name = input("è¾“å…¥è¦åˆ é™¤çš„æ¨¡å‹åç§°: ").strip()

        if model_name:
            try:
                result = subprocess.run(['ollama', 'rm', model_name], capture_output=True, text=True)
                if result.returncode == 0:
                    print(f"âœ… å·²åˆ é™¤æ¨¡å‹: {model_name}")
                else:
                    print(f"âŒ åˆ é™¤å¤±è´¥: {result.stderr}")
            except Exception as e:
                print(f"âŒ é”™è¯¯: {e}")

    def _test_ollama_model(self):
        """æµ‹è¯•Ollamaæ¨¡å‹"""
        print("\nğŸ§ª æµ‹è¯•Ollamaæ¨¡å‹")

        # æ˜¾ç¤ºå¯ç”¨æ¨¡å‹
        self._show_ollama_models()

        model_name = input("\nè¾“å…¥è¦æµ‹è¯•çš„æ¨¡å‹åç§°: ").strip()
        if model_name:
            test_prompt = "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚"
            print(f"\næµ‹è¯•æç¤º: {test_prompt}")
            print("å›ç­”:")
            print("-" * 40)

            try:
                result = subprocess.run(['ollama', 'run', model_name],
                                     input=test_prompt, text=True, capture_output=True)
                if result.returncode == 0:
                    print(result.stdout)
                else:
                    print(f"âŒ æµ‹è¯•å¤±è´¥: {result.stderr}")
            except Exception as e:
                print(f"âŒ é”™è¯¯: {e}")

    def _confirm_and_train(self, character: str):
        """ç¡®è®¤å¹¶å¼€å§‹è®­ç»ƒ"""
        print(f"\nğŸ’¡ å‡†å¤‡è®­ç»ƒ '{character}'")

        # è¯¢é—®æ˜¯å¦å¯¼å‡ºåˆ°Ollama
        export_ollama = False
        ollama_name = None

        try:
            ollama_choice = input("è®­ç»ƒå®Œæˆåæ˜¯å¦å¯¼å…¥åˆ°Ollama? (y/N): ").strip().lower()
            if ollama_choice in ['y', 'yes']:
                export_ollama = True
                ollama_name = input(f"Ollamaæ¨¡å‹åç§° (é»˜è®¤: {character}-lora): ").strip()
                if not ollama_name:
                    ollama_name = f"{character}-lora"

            # ç›´æ¥è°ƒç”¨start_trainingï¼Œå®ƒä¼šè‡ªåŠ¨æ£€æµ‹å¹¶å¤„ç†å·²æœ‰è®­ç»ƒç»“æœ
            self.start_training(character, export_ollama=export_ollama, ollama_name=ollama_name)

        except (KeyboardInterrupt, EOFError):
            print("\nğŸ‘‹ è®­ç»ƒå·²å–æ¶ˆ")

    def check_existing_training(self, character: str):
        """æ£€æŸ¥æ˜¯å¦å·²æœ‰è®­ç»ƒç»“æœ"""
        lora_dir = Path(f"out/lora_{character}")
        merged_dir = Path(f"out/merged_{character}")

        result = {
            'has_lora': lora_dir.exists(),
            'has_merged': merged_dir.exists(),
            'lora_dir': lora_dir,
            'merged_dir': merged_dir
        }

        if result['has_lora'] or result['has_merged']:
            # è·å–è®­ç»ƒæ—¶é—´ä¿¡æ¯
            if result['has_lora']:
                try:
                    # æŸ¥æ‰¾æœ€æ–°çš„checkpointæ–‡ä»¶è·å–è®­ç»ƒæ—¶é—´
                    checkpoint_files = list(lora_dir.glob('checkpoint-*'))
                    if checkpoint_files:
                        latest_checkpoint = max(checkpoint_files, key=lambda x: x.stat().st_mtime)
                        result['last_checkpoint'] = latest_checkpoint.name
                        result['train_time'] = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(latest_checkpoint.stat().st_mtime))

                    # è¯»å–è®­ç»ƒå…ƒæ•°æ®
                    meta_file = lora_dir / "run_meta.json"
                    if meta_file.exists():
                        import json
                        with open(meta_file, 'r', encoding='utf-8') as f:
                            meta = json.load(f)
                            result['training_params'] = meta.get('args', {})
                            result['env_info'] = meta.get('env_plan', {})
                except Exception:
                    pass

            if result['has_merged']:
                try:
                    result['merged_time'] = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(merged_dir.stat().st_mtime))
                    # è®¡ç®—æ¨¡å‹å¤§å°
                    total_size = sum(f.stat().st_size for f in merged_dir.glob('*') if f.is_file())
                    result['merged_size'] = f"{total_size / (1024**3):.1f} GB"
                except Exception:
                    result['merged_size'] = "æœªçŸ¥"

        return result

    def backup_existing_training(self, character: str):
        """å¤‡ä»½ç°æœ‰è®­ç»ƒç»“æœ"""
        import shutil
        timestamp = time.strftime("%Y%m%d_%H%M%S")

        lora_dir = Path(f"out/lora_{character}")
        merged_dir = Path(f"out/merged_{character}")
        backup_base = f"out/backup_{character}_{timestamp}"

        backup_info = {}

        if lora_dir.exists():
            backup_lora = f"{backup_base}_lora"
            shutil.move(str(lora_dir), backup_lora)
            backup_info['lora'] = backup_lora
            print(f"   ğŸ“¦ LoRAæ¨¡å‹å·²å¤‡ä»½åˆ°: {backup_lora}")

        if merged_dir.exists():
            backup_merged = f"{backup_base}_merged"
            shutil.move(str(merged_dir), backup_merged)
            backup_info['merged'] = backup_merged
            print(f"   ğŸ“¦ åˆå¹¶æ¨¡å‹å·²å¤‡ä»½åˆ°: {backup_merged}")

        return backup_info

    def show_existing_training_info(self, character: str, existing_info: dict):
        """æ˜¾ç¤ºç°æœ‰è®­ç»ƒç»“æœä¿¡æ¯"""
        print(f"\nğŸ“‹ å‘ç° {character} çš„ç°æœ‰è®­ç»ƒç»“æœ:")
        print("=" * 50)

        if existing_info['has_lora']:
            print(f"ğŸ”§ LoRAé€‚é…å™¨: âœ… å­˜åœ¨")
            if 'train_time' in existing_info:
                print(f"   ğŸ“… è®­ç»ƒæ—¶é—´: {existing_info['train_time']}")
            if 'last_checkpoint' in existing_info:
                print(f"   ğŸ“Š æœ€æ–°æ£€æŸ¥ç‚¹: {existing_info['last_checkpoint']}")
            if 'training_params' in existing_info:
                params = existing_info['training_params']
                epochs = params.get('num_train_epochs', 'æœªçŸ¥')
                lr = params.get('learning_rate', 'æœªçŸ¥')
                print(f"   âš™ï¸  è®­ç»ƒå‚æ•°: epochs={epochs}, lr={lr}")

        if existing_info['has_merged']:
            print(f"ğŸ¤– åˆå¹¶æ¨¡å‹: âœ… å­˜åœ¨")
            if 'merged_time' in existing_info:
                print(f"   ğŸ“… åˆå¹¶æ—¶é—´: {existing_info['merged_time']}")
            if 'merged_size' in existing_info:
                print(f"   ğŸ“¦ æ¨¡å‹å¤§å°: {existing_info['merged_size']}")

    def handle_existing_training_choice(self, character: str):
        """å¤„ç†å·²æœ‰è®­ç»ƒç»“æœçš„ç”¨æˆ·é€‰æ‹©"""
        existing_info = self.check_existing_training(character)

        if not (existing_info['has_lora'] or existing_info['has_merged']):
            return None  # æ²¡æœ‰ç°æœ‰ç»“æœï¼Œæ­£å¸¸è®­ç»ƒ

        # æ˜¾ç¤ºç°æœ‰ç»“æœä¿¡æ¯
        self.show_existing_training_info(character, existing_info)

        print(f"\nğŸ¤” æ£€æµ‹åˆ°å·²æœ‰è®­ç»ƒç»“æœï¼Œè¯·é€‰æ‹©å¤„ç†æ–¹å¼:")
        print("1) ğŸ”„ é‡æ–°è®­ç»ƒ (è¦†ç›–ç°æœ‰ç»“æœ) - âš ï¸  Lossä¼šä»åˆå§‹å€¼é‡æ–°å¼€å§‹")
        print("2) ğŸ“¦ å¤‡ä»½åé‡æ–°è®­ç»ƒ (ä¿ç•™ç°æœ‰ç»“æœ) - âš ï¸  Lossä¼šä»åˆå§‹å€¼é‡æ–°å¼€å§‹")
        print("3) â• ç»§ç»­è®­ç»ƒ (æ–­ç‚¹ç»­è®­ï¼Œå¢åŠ æ›´å¤šepochs) - âœ… æ¨èï¼Lossä¼šä»ä¹‹å‰çš„å€¼ç»§ç»­")
        print("4) ğŸš« å–æ¶ˆè®­ç»ƒ")
        print()
        print("ğŸ’¡ æç¤ºï¼šå¦‚æœlosså·²ç»é™åˆ°0.5ä»¥ä¸‹ï¼Œå»ºè®®é€‰æ‹©'ç»§ç»­è®­ç»ƒ'ï¼Œè®©lossç»§ç»­ä¸‹é™")
        print()

        while True:
            try:
                choice = input("è¯·é€‰æ‹© (1-4): ").strip()

                if choice == "1":
                    print("ğŸ”„ å°†è¦†ç›–ç°æœ‰è®­ç»ƒç»“æœ...")
                    return "overwrite"

                elif choice == "2":
                    print("ğŸ“¦ å°†å¤‡ä»½ç°æœ‰ç»“æœåé‡æ–°è®­ç»ƒ...")
                    backup_info = self.backup_existing_training(character)
                    print("âœ… å¤‡ä»½å®Œæˆï¼Œå¼€å§‹é‡æ–°è®­ç»ƒ")
                    return "backup_and_retrain"

                elif choice == "3":
                    print("â• å°†ä»æœ€æ–°æ£€æŸ¥ç‚¹ç»§ç»­è®­ç»ƒ...")
                    if not existing_info['has_lora']:
                        print("âŒ æœªæ‰¾åˆ°LoRAæ£€æŸ¥ç‚¹ï¼Œæ— æ³•ç»§ç»­è®­ç»ƒ")
                        print("   å»ºè®®é€‰æ‹©é‡æ–°è®­ç»ƒ")
                        continue
                    return "resume"

                elif choice == "4":
                    print("ğŸš« è®­ç»ƒå·²å–æ¶ˆ")
                    return "cancel"

                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥1-4")

            except (KeyboardInterrupt, EOFError):
                print("\nğŸš« è®­ç»ƒå·²å–æ¶ˆ")
                return "cancel"

def main():
    parser = argparse.ArgumentParser(description="æ™ºèƒ½LoRAè®­ç»ƒè„šæœ¬")
    parser.add_argument("character", nargs="?", help="è¦è®­ç»ƒçš„è§’è‰²åç§°")
    parser.add_argument("--character", "-c", dest="character_flag", help="æŒ‡å®šè¦è®­ç»ƒçš„è§’è‰²")
    parser.add_argument("--list", "-l", action="store_true", help="åˆ—å‡ºæ‰€æœ‰å¯ç”¨é…ç½®")
    parser.add_argument("--scan", "-s", action="store_true", help="æ‰«ææ•°æ®é›†çŠ¶æ€")
    parser.add_argument("--background", "-b", action="store_true", help="åå°è®­ç»ƒæ¨¡å¼")
    parser.add_argument("--yes", "-y", action="store_true", help="è·³è¿‡ç¡®è®¤ï¼Œç›´æ¥å¼€å§‹è®­ç»ƒ")
    parser.add_argument("--cache", action="store_true", help="æ£€æŸ¥æ¨¡å‹ç¼“å­˜çŠ¶æ€")
    parser.add_argument("--menu", "-m", action="store_true", help="æ˜¾ç¤ºäº¤äº’å¼èœå•")
    parser.add_argument("--ollama", "-o", action="store_true", help="è®­ç»ƒåå¯¼å…¥åˆ°Ollama")
    parser.add_argument("--ollama_name", type=str, help="æŒ‡å®šOllamaæ¨¡å‹åç§°")

    # æ–°å¢ç¯å¢ƒç®¡ç†å‚æ•°
    parser.add_argument("--setup", action="store_true", help="ç¯å¢ƒåˆå§‹åŒ–è®¾ç½®")
    parser.add_argument("--env-check", action="store_true", help="å…¨é¢ç¯å¢ƒæ£€æŸ¥")
    parser.add_argument("--auto", action="store_true", help="è‡ªåŠ¨æ¨¡å¼ï¼Œè·³è¿‡ç”¨æˆ·ç¡®è®¤")

    args = parser.parse_args()

    trainer = SmartTrainer()

    # é¦–æ¬¡è¿è¡Œæ£€æµ‹ï¼šæ— å‚æ•°ä¸”æ— è™šæ‹Ÿç¯å¢ƒæ—¶è¿›å…¥å¼•å¯¼æ¨¡å¼
    if not any(vars(args).values()) and not Path('.venv').exists():
        print("ğŸ” æ£€æµ‹åˆ°é¦–æ¬¡è¿è¡Œ...")
        trainer.first_time_setup()
        return

    # å¤„ç†æ–°çš„ç¯å¢ƒç®¡ç†å‚æ•°
    if args.setup:
        print("ğŸ”§ ç¯å¢ƒåˆå§‹åŒ–è®¾ç½®")
        issues = trainer._check_environment_comprehensive()

        if not issues:
            print("\nâœ… ç¯å¢ƒå·²ç»å‡†å¤‡å¥½äº†ï¼")
            if not args.auto:
                cont = input("æ˜¯å¦è¿›å…¥ä¸»èœå•? (Y/n): ").strip().lower()
                if cont in ['', 'y', 'yes']:
                    trainer.show_main_menu()
        else:
            if args.auto:
                success = trainer._auto_setup_environment(issues)
                if success:
                    print("\nğŸ‰ ç¯å¢ƒå‡†å¤‡å®Œæˆï¼")
                    trainer.show_main_menu()
            else:
                confirm = input("\næ£€æµ‹åˆ°ç¯å¢ƒé—®é¢˜ï¼Œæ˜¯å¦è‡ªåŠ¨ä¿®å¤? (Y/n): ").strip().lower()
                if confirm in ['', 'y', 'yes']:
                    success = trainer._auto_setup_environment(issues)
                    if success:
                        print("\nğŸ‰ ç¯å¢ƒå‡†å¤‡å®Œæˆï¼")
                        cont = input("æ˜¯å¦è¿›å…¥ä¸»èœå•? (Y/n): ").strip().lower()
                        if cont in ['', 'y', 'yes']:
                            trainer.show_main_menu()
        return

    if args.env_check:
        trainer._comprehensive_environment_check()
        return

    # å¤„ç†å‘½ä»¤è¡Œå‚æ•°
    if args.menu:
        trainer.show_main_menu()
        return

    if args.list:
        trainer.list_configurations()
        return

    if args.scan:
        dataset_info = trainer.scan_datasets()
        print("\nğŸ“Š æ•°æ®é›†æ‰«æç»“æœ:")
        print("=" * 50)
        for char_name, info in dataset_info.items():
            print(f"\nğŸ“ {char_name}/")
            print(f"   è®­ç»ƒæ–‡ä»¶: {len(info['train_files'])}ä¸ª")
            for tf in info['train_files']:
                print(f"      ğŸ“„ {tf.name} ({trainer.count_samples(tf)}æ ·æœ¬)")
            print(f"   éªŒè¯æ–‡ä»¶: {len(info['val_files'])}ä¸ª")
            for vf in info['val_files']:
                print(f"      ğŸ“„ {vf.name} ({trainer.count_samples(vf)}æ ·æœ¬)")
        return

    if args.cache:
        trainer.check_model_cache()
        return

    # é€‰æ‹©è§’è‰²
    character = args.character or args.character_flag
    if character:
        print(f"ğŸ¯ æŒ‡å®šè§’è‰²: {character}")
    else:
        character = trainer.interactive_select()

    # æ£€æŸ¥å‰ç½®æ¡ä»¶
    if not trainer.check_prerequisites(character):
        print("\nğŸ’¡ å»ºè®®:")
        print("   1. æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨")
        print("   2. éªŒè¯JSONLæ ¼å¼æ˜¯å¦æ­£ç¡®")
        print("   3. è¿è¡Œ 'python smart_train.py --scan' æŸ¥çœ‹è¯¦ç»†çŠ¶æ€")
        sys.exit(1)

    # ç¡®è®¤è®­ç»ƒ
    if not args.yes:
        print(f"\nğŸ’¡ å³å°†å¼€å§‹è®­ç»ƒ '{character}'")
        try:
            confirm = input("ç¡®è®¤å¼€å§‹è®­ç»ƒ? (y/N): ").strip().lower()
            if confirm not in ['y', 'yes']:
                print("ğŸ‘‹ è®­ç»ƒå·²å–æ¶ˆ")
                return
        except (KeyboardInterrupt, EOFError):
            print("\nğŸ‘‹ è®­ç»ƒå·²å–æ¶ˆ")
            return
    else:
        print(f"\nğŸš€ è‡ªåŠ¨å¼€å§‹è®­ç»ƒ '{character}'")

    # å¼€å§‹è®­ç»ƒ
    trainer.start_training(character, args.background,
                          export_ollama=args.ollama,
                          ollama_name=args.ollama_name)

if __name__ == "__main__":
    main()