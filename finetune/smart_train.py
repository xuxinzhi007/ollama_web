#!/usr/bin/env python3
"""
æ™ºèƒ½LoRAè®­ç»ƒè„šæœ¬ - è‡ªåŠ¨åŒ¹é…æ•°æ®æ–‡ä»¶ï¼Œç®€åŒ–å·¥ä½œæµç¨‹
è§£å†³é—®é¢˜ï¼š
1. è‡ªåŠ¨æ£€æµ‹å’ŒåŒ¹é…æ•°æ®é›†æ–‡ä»¶
2. æ— éœ€æ‰‹åŠ¨æŒ‡å®šæ–‡ä»¶è·¯å¾„
3. æ™ºèƒ½å¤„ç†ç¼ºå¤±æ–‡ä»¶æƒ…å†µ
4. æé«˜æµ‹è¯•æ•ˆç‡

ä½¿ç”¨æ–¹æ³•ï¼š
  python smart_train.py                    # äº¤äº’å¼é€‰æ‹©è§’è‰²
  python smart_train.py --character linzhi # ç›´æ¥æŒ‡å®šè§’è‰²
  python smart_train.py --list             # åˆ—å‡ºæ‰€æœ‰å¯ç”¨é…ç½®
  python smart_train.py --scan             # æ‰«ææ•°æ®é›†çŠ¶æ€
"""

import os
import sys
import argparse
import json
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import subprocess
import time

class SmartTrainer:
    def __init__(self):
        self.root_dir = Path(__file__).parent
        self.datasets_dir = self.root_dir / "datasets"
        self.config_file = self.root_dir / "character_configs.yaml"
        self.config = None  # å»¶è¿ŸåŠ è½½é…ç½®

    def _ensure_config_loaded(self):
        """ç¡®ä¿é…ç½®å·²åŠ è½½"""
        if self.config is None:
            self.config = self._load_config()

    def _load_config(self) -> Dict:
        """åŠ è½½è§’è‰²é…ç½®"""
        try:
            import yaml
            with open(self.config_file, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except FileNotFoundError:
            print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.config_file}")
            sys.exit(1)
        except Exception as e:
            print(f"âŒ åŠ è½½é…ç½®å¤±è´¥: {e}")
            sys.exit(1)

    def check_model_cache(self):
        """æ£€æŸ¥æ¨¡å‹ç¼“å­˜çŠ¶æ€"""
        self._ensure_config_loaded()
        try:
            from model_cache import print_cache_status

            print("\nğŸ” æ£€æŸ¥æ¨¡å‹ç¼“å­˜çŠ¶æ€")
            print("=" * 50)

            # æ£€æŸ¥é…ç½®ä¸­çš„æ‰€æœ‰æ¨¡å‹
            models_to_check = set()

            for char_name, char_config in self.config.get('characters', {}).items():
                training_params = char_config.get('training_params', {})
                base_model = training_params.get('base_model', 'Qwen/Qwen2.5-0.5B')

                # æ ‡å‡†åŒ–æ¨¡å‹åç§°
                if base_model == 'Qwen/Qwen2.5-0.5B':
                    base_model = 'Qwen/Qwen2.5-0.5B-Instruct'

                models_to_check.add(base_model)

            # å¦‚æœæ²¡æœ‰é…ç½®ï¼Œæ£€æŸ¥é»˜è®¤æ¨¡å‹
            if not models_to_check:
                models_to_check.add('Qwen/Qwen2.5-0.5B-Instruct')

            for model in models_to_check:
                print_cache_status(model)
                print()

        except ImportError:
            print("âŒ æ— æ³•å¯¼å…¥æ¨¡å‹ç¼“å­˜æ£€æµ‹æ¨¡å—")
        except Exception as e:
            print(f"âŒ æ£€æŸ¥ç¼“å­˜æ—¶å‡ºé”™: {e}")

    def scan_datasets(self) -> Dict[str, Dict]:
        """æ‰«ææ•°æ®é›†ç›®å½•ï¼Œè‡ªåŠ¨å‘ç°å¯ç”¨çš„æ•°æ®æ–‡ä»¶"""
        print("ğŸ” æ‰«ææ•°æ®é›†...")

        dataset_info = {}

        if not self.datasets_dir.exists():
            print(f"ğŸ“ æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨: {self.datasets_dir}")
            return dataset_info

        # æ‰«æå„ä¸ªè§’è‰²ç›®å½•
        for char_dir in self.datasets_dir.iterdir():
            if not char_dir.is_dir() or char_dir.name == 'archive':
                continue

            char_name = char_dir.name
            train_files = []
            val_files = []

            # æŸ¥æ‰¾è®­ç»ƒå’ŒéªŒè¯æ–‡ä»¶
            for file_path in char_dir.glob("*.jsonl"):
                if "train" in file_path.name.lower():
                    train_files.append(file_path)
                elif "val" in file_path.name.lower():
                    val_files.append(file_path)

            if train_files or val_files:
                dataset_info[char_name] = {
                    'train_files': train_files,
                    'val_files': val_files,
                    'dir': char_dir
                }

        # æ‰«æarchiveç›®å½•ä¸­çš„å†å²æ•°æ®
        archive_dir = self.datasets_dir / "archive"
        if archive_dir.exists():
            archive_files = list(archive_dir.glob("*.jsonl"))
            if archive_files:
                dataset_info['archive'] = {
                    'train_files': [f for f in archive_files if "train" in f.name.lower()],
                    'val_files': [f for f in archive_files if "val" in f.name.lower()],
                    'dir': archive_dir
                }

        return dataset_info

    def count_samples(self, file_path: Path) -> int:
        """ç»Ÿè®¡JSONLæ–‡ä»¶ä¸­çš„æ ·æœ¬æ•°é‡"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return sum(1 for line in f if line.strip())
        except:
            return 0

    def validate_jsonl(self, file_path: Path) -> Tuple[bool, str]:
        """éªŒè¯JSONLæ–‡ä»¶æ ¼å¼"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                for i, line in enumerate(f):
                    if not line.strip():
                        continue
                    try:
                        data = json.loads(line)
                        if 'messages' not in data:
                            return False, f"ç¬¬{i+1}è¡Œç¼ºå°‘'messages'å­—æ®µ"
                        if not isinstance(data['messages'], list):
                            return False, f"ç¬¬{i+1}è¡Œ'messages'ä¸æ˜¯æ•°ç»„"
                    except json.JSONDecodeError as e:
                        return False, f"ç¬¬{i+1}è¡ŒJSONæ ¼å¼é”™è¯¯: {e}"
            return True, "æ ¼å¼æ­£ç¡®"
        except Exception as e:
            return False, f"æ–‡ä»¶è¯»å–é”™è¯¯: {e}"

    def list_configurations(self):
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„è§’è‰²é…ç½®"""
        self._ensure_config_loaded()
        print("\nğŸ“‹ å¯ç”¨è§’è‰²é…ç½®:")
        print("=" * 50)

        dataset_info = self.scan_datasets()

        for char_name, char_config in self.config.get('characters', {}).items():
            print(f"\nğŸ­ è§’è‰²: {char_name}")
            print(f"   åç§°: {char_config.get('name', 'N/A')}")
            print(f"   æè¿°: {char_config.get('description', 'N/A')}")

            # æ£€æŸ¥é…ç½®çš„æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            data_files = char_config.get('data_files', {})
            train_file = data_files.get('train')
            val_file = data_files.get('val')

            print(f"   é…ç½®çš„è®­ç»ƒæ–‡ä»¶: {train_file}")
            print(f"   é…ç½®çš„éªŒè¯æ–‡ä»¶: {val_file}")

            # æ£€æŸ¥å®é™…æ–‡ä»¶çŠ¶æ€
            if char_name in dataset_info:
                info = dataset_info[char_name]
                print(f"   ğŸ” å‘ç°çš„è®­ç»ƒæ–‡ä»¶: {len(info['train_files'])}ä¸ª")
                for tf in info['train_files']:
                    count = self.count_samples(tf)
                    print(f"      ğŸ“„ {tf.name} ({count}æ ·æœ¬)")

                print(f"   ğŸ” å‘ç°çš„éªŒè¯æ–‡ä»¶: {len(info['val_files'])}ä¸ª")
                for vf in info['val_files']:
                    count = self.count_samples(vf)
                    print(f"      ğŸ“„ {vf.name} ({count}æ ·æœ¬)")
            else:
                print(f"   âš ï¸  æœªå‘ç° {char_name} çš„æ•°æ®æ–‡ä»¶")

        # æ˜¾ç¤ºæœªé…ç½®çš„æ•°æ®é›†
        unconfigured = set(dataset_info.keys()) - set(self.config.get('characters', {}).keys())
        if unconfigured:
            print(f"\nğŸ“‚ å‘ç°æœªé…ç½®çš„æ•°æ®é›†:")
            for char_name in unconfigured:
                if char_name == 'archive':
                    continue
                info = dataset_info[char_name]
                print(f"   ğŸ“ {char_name}/")
                print(f"      è®­ç»ƒæ–‡ä»¶: {len(info['train_files'])}ä¸ª")
                print(f"      éªŒè¯æ–‡ä»¶: {len(info['val_files'])}ä¸ª")

    def auto_match_files(self, character: str) -> Tuple[Optional[str], Optional[str]]:
        """è‡ªåŠ¨åŒ¹é…è§’è‰²çš„è®­ç»ƒå’ŒéªŒè¯æ–‡ä»¶"""
        self._ensure_config_loaded()
        dataset_info = self.scan_datasets()

        # é¦–å…ˆæ£€æŸ¥é…ç½®æ–‡ä»¶ä¸­æŒ‡å®šçš„è·¯å¾„
        char_config = self.config.get('characters', {}).get(character)
        if char_config:
            data_files = char_config.get('data_files', {})
            train_path = data_files.get('train')
            val_path = data_files.get('val')

            if train_path and val_path:
                train_full = self.root_dir / train_path
                val_full = self.root_dir / val_path

                if train_full.exists() and val_full.exists():
                    print(f"âœ… ä½¿ç”¨é…ç½®æ–‡ä»¶æŒ‡å®šçš„æ•°æ®:")
                    print(f"   è®­ç»ƒ: {train_path} ({self.count_samples(train_full)}æ ·æœ¬)")
                    print(f"   éªŒè¯: {val_path} ({self.count_samples(val_full)}æ ·æœ¬)")
                    return str(train_full), str(val_full)

        # å¦‚æœé…ç½®æ–‡ä»¶è·¯å¾„ä¸å­˜åœ¨ï¼Œå°è¯•è‡ªåŠ¨åŒ¹é…
        if character in dataset_info:
            info = dataset_info[character]

            # é€‰æ‹©æœ€å¤§çš„è®­ç»ƒæ–‡ä»¶
            train_file = None
            if info['train_files']:
                train_file = max(info['train_files'], key=lambda f: self.count_samples(f))

            # é€‰æ‹©éªŒè¯æ–‡ä»¶
            val_file = None
            if info['val_files']:
                val_file = info['val_files'][0]  # é€šå¸¸åªæœ‰ä¸€ä¸ªéªŒè¯æ–‡ä»¶

            if train_file and val_file:
                print(f"ğŸ¯ è‡ªåŠ¨åŒ¹é…çš„æ•°æ®æ–‡ä»¶:")
                print(f"   è®­ç»ƒ: {train_file.name} ({self.count_samples(train_file)}æ ·æœ¬)")
                print(f"   éªŒè¯: {val_file.name} ({self.count_samples(val_file)}æ ·æœ¬)")
                return str(train_file), str(val_file)

            elif train_file:
                print(f"âš ï¸  åªæ‰¾åˆ°è®­ç»ƒæ–‡ä»¶: {train_file.name} ({self.count_samples(train_file)}æ ·æœ¬)")
                print(f"   ç¼ºå°‘éªŒè¯æ–‡ä»¶ï¼Œå¯èƒ½å½±å“è®­ç»ƒæ•ˆæœ")
                return str(train_file), None

        return None, None

    def interactive_select(self) -> str:
        """äº¤äº’å¼é€‰æ‹©è§’è‰²"""
        self._ensure_config_loaded()
        dataset_info = self.scan_datasets()
        characters = list(self.config.get('characters', {}).keys())

        print("\nğŸ­ è¯·é€‰æ‹©è¦è®­ç»ƒçš„è§’è‰²:")
        print("=" * 40)

        for i, char_name in enumerate(characters, 1):
            char_config = self.config['characters'][char_name]
            name = char_config.get('name', char_name)
            desc = char_config.get('description', 'æ— æè¿°')

            # æ£€æŸ¥æ•°æ®å¯ç”¨æ€§ï¼ˆä¼˜å…ˆæ£€æŸ¥é…ç½®æ–‡ä»¶è·¯å¾„ï¼‰
            status = "âŒ æ— æ•°æ®"

            # é¦–å…ˆæ£€æŸ¥é…ç½®æ–‡ä»¶ä¸­æŒ‡å®šçš„è·¯å¾„
            char_config = self.config['characters'][char_name]
            data_files = char_config.get('data_files', {})
            train_path = data_files.get('train')
            val_path = data_files.get('val')

            train_count = 0
            val_count = 0

            # ä¼˜å…ˆæ£€æŸ¥é…ç½®æ–‡ä»¶æŒ‡å®šçš„è·¯å¾„
            config_files_exist = False
            if train_path:
                train_full = self.root_dir / train_path
                if train_full.exists():
                    train_count = self.count_samples(train_full)
                    config_files_exist = True

            if val_path:
                val_full = self.root_dir / val_path
                if val_full.exists():
                    val_count = self.count_samples(val_full)

            # å¦‚æœé…ç½®æ–‡ä»¶è·¯å¾„æ— æ•ˆæˆ–ä¸å­˜åœ¨ï¼Œå†æ£€æŸ¥æ‰«æç»“æœ
            if not config_files_exist and char_name in dataset_info:
                info = dataset_info[char_name]
                if info['train_files']:
                    train_count = sum(self.count_samples(f) for f in info['train_files'])
                if info['val_files']:
                    val_count = sum(self.count_samples(f) for f in info['val_files'])

            if train_count > 0:
                status = f"âœ… {train_count}è®­ç»ƒæ ·æœ¬"
                if val_count > 0:
                    status += f", {val_count}éªŒè¯æ ·æœ¬"

            print(f"{i:2d}. {name} - {desc}")
            print(f"    {status}")

        while True:
            try:
                choice = input(f"\nè¯·è¾“å…¥é€‰æ‹© (1-{len(characters)}): ").strip()
                if not choice:
                    continue

                idx = int(choice) - 1
                if 0 <= idx < len(characters):
                    return characters[idx]
                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
            except ValueError:
                print("âŒ è¯·è¾“å…¥æ•°å­—")
            except KeyboardInterrupt:
                print("\nğŸ‘‹ è®­ç»ƒå·²å–æ¶ˆ")
                sys.exit(0)

    def check_prerequisites(self, character: str) -> bool:
        """æ£€æŸ¥è®­ç»ƒå‰ç½®æ¡ä»¶"""
        self._ensure_config_loaded()
        print(f"\nğŸ” æ£€æŸ¥ {character} çš„è®­ç»ƒå‰ç½®æ¡ä»¶...")

        # æ£€æŸ¥è§’è‰²é…ç½®
        if character not in self.config.get('characters', {}):
            print(f"âŒ è§’è‰²é…ç½®ä¸å­˜åœ¨: {character}")
            return False

        # æ£€æŸ¥æ•°æ®æ–‡ä»¶
        train_path, val_path = self.auto_match_files(character)
        if not train_path:
            print(f"âŒ æœªæ‰¾åˆ° {character} çš„è®­ç»ƒæ•°æ®")
            print(f"   è¯·ç¡®ä¿åœ¨ä»¥ä¸‹ä½ç½®æ”¾ç½®æ•°æ®æ–‡ä»¶:")
            print(f"   - datasets/{character}/train.jsonl")
            print(f"   - datasets/{character}/val.jsonl")
            return False

        # éªŒè¯æ•°æ®æ ¼å¼
        print("ğŸ” éªŒè¯æ•°æ®æ ¼å¼...")
        valid, msg = self.validate_jsonl(Path(train_path))
        if not valid:
            print(f"âŒ è®­ç»ƒæ•°æ®æ ¼å¼é”™è¯¯: {msg}")
            return False

        if val_path:
            valid, msg = self.validate_jsonl(Path(val_path))
            if not valid:
                print(f"âŒ éªŒè¯æ•°æ®æ ¼å¼é”™è¯¯: {msg}")
                return False

        # æ£€æŸ¥æ ·æœ¬æ•°é‡
        train_count = self.count_samples(Path(train_path))
        if train_count < 10:
            print(f"âš ï¸  è®­ç»ƒæ ·æœ¬æ•°é‡è¾ƒå°‘: {train_count} (å»ºè®® â‰¥ 10)")

        print(f"âœ… å‰ç½®æ¡ä»¶æ£€æŸ¥é€šè¿‡")
        return True

    def show_main_menu(self):
        """æ˜¾ç¤ºä¸»èœå•ï¼ˆæ•´åˆquick_start.shåŠŸèƒ½ï¼‰"""
        while True:
            print("\n" + "="*50)
            print("ğŸš€ æ™ºèƒ½LoRAè®­ç»ƒç³»ç»Ÿ - ä¸»èœå•")
            print("="*50)
            print("1) ğŸ­ è§’è‰²è®­ç»ƒï¼ˆæ™ºèƒ½æ–‡ä»¶åŒ¹é…ï¼‰")
            print("2) ğŸ“Š æ•°æ®é›†ç®¡ç†")
            print("3) ğŸ” ç³»ç»ŸçŠ¶æ€æ£€æŸ¥")
            print("4) ğŸ¤– Ollamaæ¨¡å‹ç®¡ç†")
            print("5) ğŸ§ª æ¨¡å‹æµ‹è¯•")
            print("0) é€€å‡º")
            print()

            try:
                choice = input("è¯·é€‰æ‹© (0-5): ").strip()

                if choice == "1":
                    self._menu_character_training()
                elif choice == "2":
                    self._menu_dataset_management()
                elif choice == "3":
                    self._menu_system_status()
                elif choice == "4":
                    self._menu_ollama_management()
                elif choice == "5":
                    self._menu_model_testing()
                elif choice == "0":
                    print("ğŸ‘‹ å†è§ï¼")
                    break
                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©")

            except (KeyboardInterrupt, EOFError):
                print("\nğŸ‘‹ å†è§ï¼")
                break

    def _menu_character_training(self):
        """èœå•ï¼šè§’è‰²è®­ç»ƒ"""
        print("\nğŸ­ è§’è‰²è®­ç»ƒé€‰é¡¹:")
        print("1) äº¤äº’å¼é€‰æ‹©è§’è‰²")
        print("2) æŸ¥çœ‹æ‰€æœ‰é…ç½®")
        print("3) æ‰«ææ•°æ®é›†çŠ¶æ€")
        print("4) æ£€æŸ¥æ¨¡å‹ç¼“å­˜")

        choice = input("é€‰æ‹© (1-4): ").strip()

        if choice == "1":
            character = self.interactive_select()
            if self.check_prerequisites(character):
                self._confirm_and_train(character)
        elif choice == "2":
            self.list_configurations()
        elif choice == "3":
            self._show_dataset_scan()
        elif choice == "4":
            self.check_model_cache()

    def _menu_dataset_management(self):
        """èœå•ï¼šæ•°æ®é›†ç®¡ç†"""
        print("\nğŸ“Š æ•°æ®é›†ç®¡ç†:")
        print("1) æ‰«ææ‰€æœ‰æ•°æ®é›†")
        print("2) éªŒè¯æ•°æ®æ ¼å¼")
        print("3) æŸ¥çœ‹æ•°æ®ç»Ÿè®¡")

        choice = input("é€‰æ‹© (1-3): ").strip()

        if choice == "1":
            self._show_dataset_scan()
        elif choice == "2":
            self._validate_all_datasets()
        elif choice == "3":
            self._show_dataset_stats()

    def _menu_system_status(self):
        """èœå•ï¼šç³»ç»ŸçŠ¶æ€"""
        print("\nğŸ” ç³»ç»ŸçŠ¶æ€æ£€æŸ¥:")
        print("1) æ£€æŸ¥æ¨¡å‹ç¼“å­˜")
        print("2) æ£€æŸ¥è®­ç»ƒç¯å¢ƒ")
        print("3) å…¨é¢ç¯å¢ƒè¯Šæ–­")  # æ–°å¢
        print("4) ç¯å¢ƒè®¾ç½®åŠ©æ‰‹")   # æ–°å¢
        print("5) æŸ¥çœ‹ç£ç›˜ä½¿ç”¨")

        choice = input("é€‰æ‹© (1-5): ").strip()

        if choice == "1":
            self.check_model_cache()
        elif choice == "2":
            self._check_training_environment()
        elif choice == "3":
            self._comprehensive_environment_check()  # æ–°å¢
        elif choice == "4":
            self._environment_setup_helper()  # æ–°å¢
        elif choice == "5":
            self._check_disk_usage()

    def _comprehensive_environment_check(self):
        """å…¨é¢ç¯å¢ƒè¯Šæ–­"""
        issues = self._check_environment_comprehensive()

        if not issues:
            print("\nğŸ‰ ç¯å¢ƒæ£€æŸ¥å®Œæˆ - æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼")
        else:
            print(f"\nâš ï¸  å‘ç° {len(issues)} ä¸ªç¯å¢ƒé—®é¢˜")
            print("\nğŸ’¡ è§£å†³å»ºè®®:")

            if 'python_version' in issues:
                print("   â€¢ Pythonç‰ˆæœ¬: è¯·å‡çº§åˆ°3.10+")
            if 'virtual_env' in issues:
                print("   â€¢ è™šæ‹Ÿç¯å¢ƒ: è¿è¡Œ python smart_train.py --setup åˆ›å»ºç¯å¢ƒ")
            if 'dependencies' in issues:
                print("   â€¢ ä¾èµ–åŒ…: è¿è¡Œ pip install -r requirements.txt")
            if 'ollama' in issues:
                print("   â€¢ OllamaæœåŠ¡: è®¿é—® https://ollama.com/ å®‰è£…")

            print(f"\nğŸ› ï¸  å¿«é€Ÿä¿®å¤: python smart_train.py --setup")

    def _environment_setup_helper(self):
        """ç¯å¢ƒè®¾ç½®åŠ©æ‰‹"""
        print("\nğŸ› ï¸  ç¯å¢ƒè®¾ç½®åŠ©æ‰‹")
        print("=" * 40)

        print("1) ğŸ”§ è‡ªåŠ¨ç¯å¢ƒå‡†å¤‡ (æ¨è)")
        print("2) ğŸ“‹ æ‰‹åŠ¨è®¾ç½®æŒ‡å—")
        print("3) ğŸ” é—®é¢˜è¯Šæ–­")
        print("4) ğŸ”„ é‡ç½®ç¯å¢ƒ")

        choice = input("\né€‰æ‹©æ“ä½œ (1-4): ").strip()

        if choice == "1":
            # è‡ªåŠ¨ç¯å¢ƒå‡†å¤‡
            issues = self._check_environment_comprehensive()
            if not issues:
                print("\nâœ… ç¯å¢ƒå·²ç»å‡†å¤‡å¥½äº†ï¼")
            else:
                confirm = input("\næ£€æµ‹åˆ°ç¯å¢ƒé—®é¢˜ï¼Œæ˜¯å¦è‡ªåŠ¨ä¿®å¤? (Y/n): ").strip().lower()
                if confirm in ['', 'y', 'yes']:
                    self._auto_setup_environment(issues)

        elif choice == "2":
            # æ‰‹åŠ¨è®¾ç½®æŒ‡å—
            self._show_manual_setup_guide()

        elif choice == "3":
            # é—®é¢˜è¯Šæ–­
            self._diagnose_environment_issues()

        elif choice == "4":
            # é‡ç½®ç¯å¢ƒ
            self._reset_environment()

    def _show_manual_setup_guide(self):
        """æ˜¾ç¤ºæ‰‹åŠ¨è®¾ç½®æŒ‡å—"""
        print("\nğŸ“‹ æ‰‹åŠ¨ç¯å¢ƒè®¾ç½®æŒ‡å—")
        print("=" * 40)

        print("\n1ï¸âƒ£ åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ:")
        print("   python3 -m venv .venv")

        print("\n2ï¸âƒ£ æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ:")
        import platform
        if platform.system() == 'Windows':
            print("   .venv\\Scripts\\activate")
        else:
            print("   source .venv/bin/activate")

        print("\n3ï¸âƒ£ å®‰è£…ä¾èµ–:")
        print("   pip install -U pip")
        print("   pip install -r requirements.txt")

        print("\n4ï¸âƒ£ éªŒè¯å®‰è£…:")
        print("   python smart_train.py --env-check")

        print("\n5ï¸âƒ£ å®‰è£…Ollama (å¯é€‰):")
        print("   è®¿é—® https://ollama.com/ ä¸‹è½½å®‰è£…")

    def _diagnose_environment_issues(self):
        """è¯Šæ–­ç¯å¢ƒé—®é¢˜"""
        print("\nğŸ” ç¯å¢ƒé—®é¢˜è¯Šæ–­")
        print("=" * 40)

        issues = self._check_environment_comprehensive()

        if not issues:
            print("\nâœ… æ²¡æœ‰å‘ç°é—®é¢˜ï¼ç¯å¢ƒé…ç½®è‰¯å¥½ã€‚")
            return

        print(f"\nğŸ”§ è¯Šæ–­ç»“æœå’Œè§£å†³æ–¹æ¡ˆ:")

        for issue in issues:
            if issue == 'python_version':
                print(f"\nâŒ Pythonç‰ˆæœ¬é—®é¢˜:")
                print(f"   å½“å‰ç‰ˆæœ¬è¿‡ä½ï¼Œéœ€è¦Python 3.10+")
                self._show_python_upgrade_guide()

            elif issue == 'virtual_env':
                print(f"\nâŒ è™šæ‹Ÿç¯å¢ƒé—®é¢˜:")
                print(f"   æœªæ£€æµ‹åˆ°è™šæ‹Ÿç¯å¢ƒ")
                print(f"   è§£å†³æ–¹æ¡ˆ: python3 -m venv .venv")

            elif issue == 'dependencies':
                print(f"\nâŒ ä¾èµ–åŒ…é—®é¢˜:")
                print(f"   è®­ç»ƒä¾èµ–æœªå®Œæ•´å®‰è£…")
                print(f"   è§£å†³æ–¹æ¡ˆ: pip install -r requirements.txt")

            elif issue == 'ollama':
                print(f"\nâš ï¸  OllamaæœåŠ¡é—®é¢˜:")
                print(f"   Ollamaæœªå®‰è£…æˆ–ä¸å¯ç”¨")
                print(f"   è§£å†³æ–¹æ¡ˆ: è®¿é—® https://ollama.com/ å®‰è£…")
                print(f"   æ³¨æ„: Ollamaä¸æ˜¯è®­ç»ƒå¿…éœ€çš„ï¼Œåªåœ¨å¯¼å…¥æ¨¡å‹æ—¶éœ€è¦")

    def _reset_environment(self):
        """é‡ç½®ç¯å¢ƒ"""
        print("\nğŸ”„ ç¯å¢ƒé‡ç½®")
        print("=" * 40)

        print("âš ï¸  è¿™å°†åˆ é™¤ç°æœ‰çš„è™šæ‹Ÿç¯å¢ƒå¹¶é‡æ–°åˆ›å»º")
        confirm = input("ç¡®è®¤è¦é‡ç½®ç¯å¢ƒå—? (y/N): ").strip().lower()

        if confirm in ['y', 'yes']:
            import shutil

            # åˆ é™¤ç°æœ‰è™šæ‹Ÿç¯å¢ƒ
            if Path('.venv').exists():
                print("ğŸ—‘ï¸  åˆ é™¤ç°æœ‰è™šæ‹Ÿç¯å¢ƒ...")
                shutil.rmtree('.venv')
                print("   âœ… åˆ é™¤å®Œæˆ")

            # é‡æ–°åˆ›å»ºç¯å¢ƒ
            print("ğŸ”§ é‡æ–°åˆ›å»ºç¯å¢ƒ...")
            if self._create_virtual_environment():
                print("   âœ… è™šæ‹Ÿç¯å¢ƒåˆ›å»ºæˆåŠŸ")

                if self._install_dependencies():
                    print("   âœ… ä¾èµ–å®‰è£…å®Œæˆ")
                    print("\nğŸ‰ ç¯å¢ƒé‡ç½®å®Œæˆï¼")
                else:
                    print("   âŒ ä¾èµ–å®‰è£…å¤±è´¥")
            else:
                print("   âŒ è™šæ‹Ÿç¯å¢ƒåˆ›å»ºå¤±è´¥")
        else:
            print("ğŸ‘‹ é‡ç½®å·²å–æ¶ˆ")

    def _menu_ollama_management(self):
        """èœå•ï¼šOllamaç®¡ç†"""
        print("\nğŸ¤– Ollamaæ¨¡å‹ç®¡ç†:")
        print("1) æŸ¥çœ‹Ollamaæ¨¡å‹åˆ—è¡¨")
        print("2) å¯¼å…¥è®­ç»ƒå¥½çš„æ¨¡å‹åˆ°Ollama")
        print("3) åˆ é™¤Ollamaæ¨¡å‹")

        choice = input("é€‰æ‹© (1-3): ").strip()

        if choice == "1":
            self._show_ollama_models()
        elif choice == "2":
            self._import_to_ollama()
        elif choice == "3":
            self._delete_ollama_model()

    def _menu_model_testing(self):
        """èœå•ï¼šæ¨¡å‹æµ‹è¯•"""
        self._test_ollama_model()

    def start_training(self, character: str, background: bool = False, export_ollama: bool = False, ollama_name: str = None):
        """å¯åŠ¨è®­ç»ƒ"""
        self._ensure_config_loaded()
        print(f"\nğŸš€ å¯åŠ¨ {character} çš„LoRAè®­ç»ƒ...")

        # è·å–è§’è‰²é…ç½®
        char_config = self.config.get('characters', {}).get(character)
        if not char_config:
            print(f"âŒ æœªæ‰¾åˆ°è§’è‰²é…ç½®: {character}")
            return

        # è·å–æ•°æ®æ–‡ä»¶è·¯å¾„
        train_path, val_path = self.auto_match_files(character)
        if not train_path:
            print(f"âŒ æœªæ‰¾åˆ°è®­ç»ƒæ•°æ®æ–‡ä»¶")
            return

        # è·å–è®­ç»ƒå‚æ•°
        training_params = char_config.get('training_params', {})

        # æ£€æŸ¥æ˜¯å¦å·²æœ‰è®­ç»ƒç»“æœå¹¶å¤„ç†ç”¨æˆ·é€‰æ‹©
        choice = self.handle_existing_training_choice(character)
        if choice == "cancel":
            return

        resume_from_checkpoint = None
        if choice == "resume":
            # æ–­ç‚¹ç»­è®­æ¨¡å¼
            lora_dir = Path(f"out/lora_{character}")
            checkpoint_files = list(lora_dir.glob('checkpoint-*'))
            if checkpoint_files:
                # æ‰¾åˆ°æœ€æ–°çš„checkpoint
                latest_checkpoint = max(checkpoint_files, key=lambda x: x.stat().st_mtime)
                resume_from_checkpoint = str(latest_checkpoint)
                print(f"ğŸ“ å°†ä»æ£€æŸ¥ç‚¹ç»§ç»­è®­ç»ƒ: {latest_checkpoint.name}")

        # æ„å»ºè®­ç»ƒå‘½ä»¤
        cmd = [
            sys.executable, "train_lora.py",
            "--train_jsonl", train_path,
            "--output_dir", f"out/lora_{character}"
        ]

        # æ·»åŠ éªŒè¯æ•°æ®
        if val_path:
            cmd.extend(["--val_jsonl", val_path])

        # æ·»åŠ è®­ç»ƒå‚æ•°
        if 'epochs' in training_params:
            cmd.extend(["--num_train_epochs", str(training_params['epochs'])])
        if 'learning_rate' in training_params:
            cmd.extend(["--learning_rate", str(training_params['learning_rate'])])
        if 'lora_r' in training_params:
            cmd.extend(["--lora_r", str(training_params['lora_r'])])
        if 'lora_alpha' in training_params:
            cmd.extend(["--lora_alpha", str(training_params['lora_alpha'])])
        if 'lora_dropout' in training_params:
            cmd.extend(["--lora_dropout", str(training_params['lora_dropout'])])

        # æ–­ç‚¹ç»­è®­å‚æ•°
        if resume_from_checkpoint:
            cmd.extend(["--resume_from_checkpoint", resume_from_checkpoint])

        # é»˜è®¤å‚æ•°
        cmd.extend([
            "--merge_and_save",  # è‡ªåŠ¨åˆå¹¶å¹¶ä¿å­˜
            "--merged_dir", f"out/merged_{character}"
        ])

        print(f"ğŸ“ æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")

        if background:
            print("ğŸ”„ åå°è®­ç»ƒæ¨¡å¼...")
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                bufsize=1,
                universal_newlines=True
            )

            # å®æ—¶æ˜¾ç¤ºè¾“å‡º
            for line in process.stdout:
                print(line.rstrip())

            process.wait()

            if process.returncode == 0:
                print(f"ğŸ‰ {character} è®­ç»ƒå®Œæˆ!")
                print(f"   LoRAæ¨¡å‹: out/lora_{character}")
                print(f"   åˆå¹¶æ¨¡å‹: out/merged_{character}")
                return_code = process.returncode
            else:
                print(f"âŒ {character} è®­ç»ƒå¤±è´¥ (é€€å‡ºç : {process.returncode})")
                return_code = process.returncode
        else:
            # ç›´æ¥æ‰§è¡Œï¼Œç”¨æˆ·å¯ä»¥çœ‹åˆ°å®æ—¶è¾“å‡º
            result = subprocess.run(cmd)
            if result.returncode == 0:
                print(f"ğŸ‰ {character} è®­ç»ƒå®Œæˆ!")
                print(f"   LoRAæ¨¡å‹: out/lora_{character}")
                print(f"   åˆå¹¶æ¨¡å‹: out/merged_{character}")
            else:
                print(f"âŒ {character} è®­ç»ƒå¤±è´¥")
            return_code = result.returncode

        # è®­ç»ƒå®Œæˆåçš„å‹å¥½æç¤ºå’ŒOllamaå¯¼å…¥å¤„ç†
        if return_code == 0:
            if export_ollama:
                self._export_to_ollama(character, ollama_name)
            else:
                self._show_post_training_options(character, ollama_name)

    def _show_post_training_options(self, character: str, ollama_name: str = None):
        """è®­ç»ƒå®Œæˆåæ˜¾ç¤ºåç»­é€‰é¡¹"""
        print("\n" + "=" * 60)
        print("ğŸ‰ è®­ç»ƒå®Œæˆï¼ä¸‹ä¸€æ­¥æ“ä½œ")
        print("=" * 60)
        print(f"âœ… æ¨¡å‹å·²è®­ç»ƒå®Œæˆï¼š{character}")
        print(f"ğŸ“ æ–‡ä»¶ä½ç½®ï¼šout/merged_{character}/")
        print()
        print("âš ï¸  æ³¨æ„ï¼šæ¨¡å‹ç›®å‰è¿˜æ²¡æœ‰å¯¼å…¥åˆ°Ollamaï¼Œæ— æ³•ç›´æ¥ä½¿ç”¨")
        print()
        print("ğŸ“‹ åç»­é€‰é¡¹ï¼š")
        print("1) ğŸš€ å¯¼å…¥åˆ°Ollamaï¼ˆæ¨èï¼‰- å¯ä»¥ç«‹å³ä½¿ç”¨ ollama run å‘½ä»¤")
        print("2) ğŸ“¦ ç¨åå¯¼å…¥ - è¿”å›ä¸»èœå•ï¼Œé€šè¿‡ 4)Ollamaæ¨¡å‹ç®¡ç† å¯¼å…¥")
        print("3) ğŸ  è¿”å›ä¸»èœå• - ç»§ç»­å…¶ä»–æ“ä½œ")
        print("4) ğŸ‘‹ é€€å‡ºç³»ç»Ÿ")
        print()

        while True:
            try:
                choice = input("è¯·é€‰æ‹© (1-4): ").strip()

                if choice == "1":
                    # è¯¢é—®Ollamaæ¨¡å‹åç§°
                    if not ollama_name:
                        default_name = f"{character}-lora"
                        ollama_name = input(f"è¯·è¾“å…¥Ollamaæ¨¡å‹åç§° (é»˜è®¤: {default_name}): ").strip()
                        if not ollama_name:
                            ollama_name = default_name

                    success = self._export_to_ollama(character, ollama_name)
                    if success:
                        print(f"\nğŸ‰ å¯¼å…¥æˆåŠŸï¼ç°åœ¨å¯ä»¥ä½¿ç”¨ï¼š")
                        print(f"   ollama run {ollama_name}")
                        print()
                        input("æŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")
                    break

                elif choice == "2":
                    print("\nğŸ’¡ æç¤ºï¼šç¨åå¯é€šè¿‡ä¸»èœå• -> 4)Ollamaæ¨¡å‹ç®¡ç† -> 2)å¯¼å…¥è®­ç»ƒå¥½çš„æ¨¡å‹ æ¥å¯¼å…¥")
                    input("æŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")
                    break

                elif choice == "3":
                    print("\nğŸ  è¿”å›ä¸»èœå•...")
                    break

                elif choice == "4":
                    print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼")
                    sys.exit(0)

                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥1-4")

            except (KeyboardInterrupt, EOFError):
                print("\n\nğŸ  è¿”å›ä¸»èœå•...")
                break

    def _export_to_ollama(self, character: str, ollama_name: str = None):
        """å¯¼å‡ºåˆ°Ollama"""
        if not ollama_name:
            ollama_name = f"{character}-lora"

        print(f"\nğŸš€ å¯¼å‡ºåˆ°Ollama: {ollama_name}")

        # ä½¿ç”¨ç»å¯¹è·¯å¾„å¹¶éªŒè¯ç›®å½•å­˜åœ¨
        merged_dir = Path(f"out/merged_{character}").resolve()
        if not merged_dir.exists():
            print(f"âŒ åˆå¹¶æ¨¡å‹ä¸å­˜åœ¨: {merged_dir}")
            print("   è¯·ç¡®ä¿è®­ç»ƒæ—¶ä½¿ç”¨äº† --merge_and_save å‚æ•°")
            return False

        # éªŒè¯æ¨¡å‹æ–‡ä»¶æ˜¯å¦å®Œæ•´
        model_files = ["model.safetensors", "pytorch_model.bin"]  # æ”¯æŒæ–°æ—§æ ¼å¼
        has_model = any((merged_dir / f).exists() for f in model_files)

        required_files = ["config.json", "tokenizer.json"]
        missing_files = []
        for file_name in required_files:
            if not (merged_dir / file_name).exists():
                missing_files.append(file_name)

        if not has_model:
            missing_files.append("model.safetensors æˆ– pytorch_model.bin")

        if missing_files:
            print(f"âš ï¸  æ¨¡å‹æ–‡ä»¶ä¸å®Œæ•´ï¼Œç¼ºå°‘: {', '.join(missing_files)}")
            print("   æ¨¡å‹å¯èƒ½ä»å¯ä½¿ç”¨ï¼Œä½†å»ºè®®é‡æ–°è®­ç»ƒ")

        print(f"ğŸ“ æ¨¡å‹è·¯å¾„: {merged_dir}")
        print(f"ğŸ“¦ æ¨¡å‹å¤§å°: {sum(f.stat().st_size for f in merged_dir.glob('*')) / (1024**3):.1f} GB")

        # åˆ›å»ºOllama Modelfile (ä½¿ç”¨ç»å¯¹è·¯å¾„å’Œå®Œæ•´è§’è‰²é…ç½®)
        self._ensure_config_loaded()
        char_config = self.config.get('characters', {}).get(character, {})
        system_prompt = char_config.get('system_prompt', f'ä½ æ˜¯{character}ï¼Œè¯·ä¿æŒè§’è‰²ç‰¹å¾è¿›è¡Œå¯¹è¯ã€‚')

        modelfile_content = f"""FROM {merged_dir}
PARAMETER temperature 0.3
PARAMETER top_p 0.8
PARAMETER top_k 40
SYSTEM \"\"\"{system_prompt}\"\"\"
"""

        try:
            # ä½¿ç”¨ollama createå‘½ä»¤
            import tempfile
            with tempfile.NamedTemporaryFile(mode='w', suffix='.modelfile', delete=False) as f:
                f.write(modelfile_content)
                modelfile_path = f.name

            cmd = f"ollama create {ollama_name} -f {modelfile_path}"
            print(f"æ‰§è¡Œ: {cmd}")

            result = subprocess.run(cmd, shell=True, capture_output=True, text=True)

            if result.returncode == 0:
                print(f"âœ… æˆåŠŸå¯¼å…¥åˆ°Ollama: {ollama_name}")
                print(f"ğŸ§ª æµ‹è¯•å‘½ä»¤: ollama run {ollama_name}")
                return True
            else:
                print(f"âŒ å¯¼å…¥å¤±è´¥: {result.stderr}")
                return False

        except Exception as e:
            print(f"âŒ å¯¼å‡ºè¿‡ç¨‹å‡ºé”™: {e}")
            return False

    def _show_dataset_scan(self):
        """æ˜¾ç¤ºæ•°æ®é›†æ‰«æç»“æœ"""
        dataset_info = self.scan_datasets()
        print("\nğŸ“Š æ•°æ®é›†æ‰«æç»“æœ:")
        print("=" * 50)
        for char_name, info in dataset_info.items():
            print(f"\nğŸ“ {char_name}/")
            print(f"   è®­ç»ƒæ–‡ä»¶: {len(info['train_files'])}ä¸ª")
            for tf in info['train_files']:
                print(f"      ğŸ“„ {tf.name} ({self.count_samples(tf)}æ ·æœ¬)")
            print(f"   éªŒè¯æ–‡ä»¶: {len(info['val_files'])}ä¸ª")
            for vf in info['val_files']:
                print(f"      ğŸ“„ {vf.name} ({self.count_samples(vf)}æ ·æœ¬)")

    def _validate_all_datasets(self):
        """éªŒè¯æ‰€æœ‰æ•°æ®é›†æ ¼å¼"""
        dataset_info = self.scan_datasets()
        print("\nğŸ” éªŒè¯æ•°æ®é›†æ ¼å¼...")

        for char_name, info in dataset_info.items():
            print(f"\nğŸ“ {char_name}:")

            for file_list, file_type in [(info['train_files'], 'è®­ç»ƒ'), (info['val_files'], 'éªŒè¯')]:
                for file_path in file_list:
                    valid, msg = self.validate_jsonl(file_path)
                    status = "âœ…" if valid else "âŒ"
                    print(f"   {status} {file_type}æ–‡ä»¶ {file_path.name}: {msg}")

    def _show_dataset_stats(self):
        """æ˜¾ç¤ºæ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
        dataset_info = self.scan_datasets()
        print("\nğŸ“Š æ•°æ®é›†ç»Ÿè®¡:")
        print("=" * 50)

        total_train = 0
        total_val = 0

        for char_name, info in dataset_info.items():
            train_count = sum(self.count_samples(f) for f in info['train_files'])
            val_count = sum(self.count_samples(f) for f in info['val_files'])

            print(f"ğŸ“ {char_name}: {train_count}è®­ç»ƒæ ·æœ¬ + {val_count}éªŒè¯æ ·æœ¬")
            total_train += train_count
            total_val += val_count

        print(f"\nğŸ“ˆ æ€»è®¡: {total_train}è®­ç»ƒæ ·æœ¬ + {total_val}éªŒè¯æ ·æœ¬")

    def _check_training_environment(self):
        """æ£€æŸ¥è®­ç»ƒç¯å¢ƒ"""
        print("\nğŸ” æ£€æŸ¥è®­ç»ƒç¯å¢ƒ...")

        try:
            # æ£€æŸ¥Pythonç‰ˆæœ¬
            import sys
            print(f"   ğŸ Python: {sys.version}")

            # æ£€æŸ¥å…³é”®åº“
            libs = ['torch', 'transformers', 'peft', 'trl', 'datasets']
            for lib in libs:
                try:
                    module = __import__(lib)
                    version = getattr(module, '__version__', 'unknown')
                    print(f"   âœ… {lib}: {version}")
                except ImportError:
                    print(f"   âŒ {lib}: æœªå®‰è£…")

            # æ£€æŸ¥è®¾å¤‡
            try:
                import torch
                device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
                print(f"   ğŸ–¥ï¸  è®¾å¤‡: {device}")
            except:
                print(f"   âš ï¸  è®¾å¤‡: æ— æ³•æ£€æµ‹")

        except Exception as e:
            print(f"   âŒ ç¯å¢ƒæ£€æŸ¥å¤±è´¥: {e}")

    def first_time_setup(self):
        """é¦–æ¬¡è¿è¡Œå¼•å¯¼è®¾ç½®"""
        print("ğŸš€ LoRAæ™ºèƒ½è®­ç»ƒç³»ç»Ÿ - é¦–æ¬¡è¿è¡Œæ£€æµ‹")
        print("=" * 50)

        # å…¨é¢ç¯å¢ƒæ£€æµ‹
        issues = self._check_environment_comprehensive()

        if not issues:
            print("\nğŸ‰ ç¯å¢ƒæ£€æŸ¥å®Œæˆ - æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼")
            print("ç°åœ¨å¯ä»¥å¼€å§‹ä½¿ç”¨è®­ç»ƒç³»ç»Ÿäº†ï¼\n")
            self.show_main_menu()
            return

        # æ˜¾ç¤ºé—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ
        print(f"\nâš ï¸  å‘ç° {len(issues)} ä¸ªç¯å¢ƒé—®é¢˜ï¼Œéœ€è¦åˆå§‹åŒ–è®¾ç½®")
        print("\nğŸ“‹ æ¨èæ“ä½œæµç¨‹ï¼š")
        if 'python_version' in issues:
            print("1ï¸âƒ£ å‡çº§Pythonç‰ˆæœ¬ (å¿…éœ€)")
        if 'virtual_env' in issues:
            print("1ï¸âƒ£ åˆ›å»ºè™šæ‹Ÿç¯å¢ƒå¹¶å®‰è£…ä¾èµ– (å¿…éœ€)")
        if 'dependencies' in issues:
            print("2ï¸âƒ£ å®‰è£…è®­ç»ƒä¾èµ– (å¿…éœ€)")
        if 'ollama' in issues:
            print("3ï¸âƒ£ å®‰è£…OllamaæœåŠ¡ (è®­ç»ƒå®Œæˆåå¯¼å…¥æ¨¡å‹éœ€è¦)")

        try:
            # è¯¢é—®æ˜¯å¦è‡ªåŠ¨ä¿®å¤
            if 'python_version' in issues:
                print("\nâŒ Pythonç‰ˆæœ¬è¿‡ä½ï¼Œè¯·å…ˆå‡çº§Pythonå†è¿è¡Œ")
                self._show_python_upgrade_guide()
                return

            confirm = input("\næ˜¯å¦ç«‹å³è¿›è¡Œç¯å¢ƒåˆå§‹åŒ–? (Y/n): ").strip().lower()
            if confirm in ['', 'y', 'yes']:
                success = self._auto_setup_environment(issues)
                if success:
                    print("\nğŸ‰ ç¯å¢ƒå‡†å¤‡å®Œæˆï¼")

                    cont = input("ç»§ç»­è¿›å…¥è®­ç»ƒç³»ç»Ÿ? (Y/n): ").strip().lower()
                    if cont in ['', 'y', 'yes']:
                        self.show_main_menu()
                else:
                    print("\nâš ï¸  ç¯å¢ƒå‡†å¤‡é‡åˆ°é—®é¢˜ï¼Œè¯·æŸ¥çœ‹ä¸Šæ–¹é”™è¯¯ä¿¡æ¯")
                    print("å¯ä»¥å°è¯•æ‰‹åŠ¨è§£å†³é—®é¢˜åé‡æ–°è¿è¡Œ")
            else:
                print("\nğŸ’¡ æ‚¨å¯ä»¥ç¨åä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è¿›è¡Œç¯å¢ƒå‡†å¤‡ï¼š")
                print("   python smart_train.py --setup")

        except (KeyboardInterrupt, EOFError):
            print("\n\nğŸ‘‹ è®¾ç½®å·²å–æ¶ˆ")

    def _check_environment_comprehensive(self):
        """å…¨é¢ç¯å¢ƒæ£€æŸ¥"""
        print("\nğŸ” æ­£åœ¨æ£€æŸ¥è¿è¡Œç¯å¢ƒ...")

        issues = []

        # 1. ç³»ç»Ÿå¹³å°æ£€æµ‹
        import platform
        system = platform.system()
        print(f"   ğŸ’» æ“ä½œç³»ç»Ÿ: {system} {platform.release()}")

        # 2. Pythonç‰ˆæœ¬æ£€æŸ¥
        python_status = self._check_python_version()
        if not python_status['compatible']:
            issues.append('python_version')

        # 3. è™šæ‹Ÿç¯å¢ƒæ£€æµ‹
        venv_status = self._check_virtual_environment()
        if not venv_status['active'] and not venv_status['exists']:
            issues.append('virtual_env')
        elif venv_status['exists'] and not venv_status['active']:
            print(f"   ğŸ’¡ æç¤º: æ£€æµ‹åˆ°è™šæ‹Ÿç¯å¢ƒä½†æœªæ¿€æ´»ï¼Œè¯·è¿è¡Œ: source .venv/bin/activate")

        # 4. ä¾èµ–æ£€æŸ¥ï¼ˆåªæœ‰åœ¨è™šæ‹Ÿç¯å¢ƒæ¿€æ´»æ—¶æ‰æ£€æŸ¥ï¼‰
        if venv_status['active'] or not Path('.venv').exists():
            deps_status = self._check_dependencies_simple()
            if deps_status['missing']:
                issues.append('dependencies')
        else:
            print(f"   ğŸ“š è®­ç»ƒä¾èµ–: éœ€è¦æ¿€æ´»è™šæ‹Ÿç¯å¢ƒåæ£€æŸ¥")

        # 5. OllamaæœåŠ¡æ£€æµ‹
        ollama_status = self._check_ollama_service()
        if not ollama_status['available']:
            issues.append('ollama')

        return issues

    def _check_python_version(self):
        """æ£€æŸ¥Pythonç‰ˆæœ¬"""
        import sys

        version = sys.version_info
        version_str = f"{version.major}.{version.minor}.{version.micro}"

        # è¦æ±‚Python >= 3.10
        compatible = version.major >= 3 and version.minor >= 10

        if compatible:
            print(f"   ğŸ Python: {version_str} âœ…")
        else:
            print(f"   ğŸ Python: {version_str} âŒ (éœ€è¦ â‰¥ 3.10)")

        return {
            'compatible': compatible,
            'version': version_str,
            'major': version.major,
            'minor': version.minor
        }

    def _check_virtual_environment(self):
        """æ£€æŸ¥è™šæ‹Ÿç¯å¢ƒçŠ¶æ€"""
        import sys

        # æ£€æŸ¥æ˜¯å¦åœ¨è™šæ‹Ÿç¯å¢ƒä¸­
        in_venv = (hasattr(sys, 'real_prefix') or
                   (hasattr(sys, 'base_prefix') and sys.base_prefix != sys.prefix))

        venv_exists = Path('.venv').exists()

        if in_venv and venv_exists:
            print(f"   ğŸ“¦ è™šæ‹Ÿç¯å¢ƒ: å·²æ¿€æ´» âœ…")
        elif venv_exists:
            print(f"   ğŸ“¦ è™šæ‹Ÿç¯å¢ƒ: å­˜åœ¨ä½†æœªæ¿€æ´» âš ï¸")
        elif in_venv:
            print(f"   ğŸ“¦ è™šæ‹Ÿç¯å¢ƒ: åœ¨å…¶ä»–è™šæ‹Ÿç¯å¢ƒä¸­ âš ï¸")
        else:
            print(f"   ğŸ“¦ è™šæ‹Ÿç¯å¢ƒ: ä¸å­˜åœ¨ âŒ")

        return {
            'active': in_venv,
            'exists': venv_exists,
            'path': Path('.venv').resolve() if venv_exists else None
        }

    def _check_dependencies_simple(self):
        """ç®€å•ä¾èµ–æ£€æŸ¥"""
        required_libs = ['torch', 'transformers', 'peft', 'trl', 'datasets']
        missing = []
        installed = []

        for lib in required_libs:
            try:
                module = __import__(lib)
                version = getattr(module, '__version__', 'unknown')
                print(f"   ğŸ“š {lib}: {version} âœ…")
                installed.append(lib)
            except ImportError:
                print(f"   ğŸ“š {lib}: æœªå®‰è£… âŒ")
                missing.append(lib)

        return {
            'missing': missing,
            'installed': installed
        }

    def _check_ollama_service(self):
        """æ£€æŸ¥OllamaæœåŠ¡çŠ¶æ€"""
        try:
            result = subprocess.run(['ollama', '--version'],
                                  capture_output=True, text=True, timeout=5)
            if result.returncode == 0:
                version = result.stdout.strip().split()[-1] if result.stdout.strip() else "æœªçŸ¥ç‰ˆæœ¬"
                print(f"   ğŸ¤– OllamaæœåŠ¡: {version} âœ…")
                return {'available': True, 'version': version}

        except (subprocess.TimeoutExpired, FileNotFoundError, subprocess.CalledProcessError):
            print(f"   ğŸ¤– OllamaæœåŠ¡: æœªå®‰è£… âš ï¸ (è®­ç»ƒåå¯¼å…¥æ¨¡å‹éœ€è¦)")

        return {'available': False, 'version': None}

    def _show_python_upgrade_guide(self):
        """æ˜¾ç¤ºPythonå‡çº§æŒ‡å—"""
        import platform
        system = platform.system().lower()

        print(f"\nğŸ’¡ Pythonå‡çº§æŒ‡å—:")
        if 'darwin' in system:  # macOS
            print("   # macOS (æ¨èä½¿ç”¨Homebrew)")
            print("   brew install python@3.11")
            print("   # æˆ–ä½¿ç”¨pyenv")
            print("   brew install pyenv")
            print("   pyenv install 3.11.5")
            print("   pyenv global 3.11.5")
        elif 'linux' in system:  # Linux
            print("   # Ubuntu/Debian")
            print("   sudo apt update")
            print("   sudo apt install python3.11 python3.11-venv python3.11-pip")
            print("   # CentOS/RHEL")
            print("   sudo yum install python3.11")
        elif 'windows' in system:  # Windows
            print("   # Windows")
            print("   1. è®¿é—® https://www.python.org/downloads/")
            print("   2. ä¸‹è½½Python 3.11+å®‰è£…åŒ…")
            print("   3. å®‰è£…æ—¶å‹¾é€‰ 'Add Python to PATH'")

        print(f"\nç„¶åé‡æ–°è¿è¡Œ: python3.11 smart_train.py")

    def _auto_setup_environment(self, issues):
        """è‡ªåŠ¨ç¯å¢ƒè®¾ç½®"""
        print(f"\nğŸ”§ å¼€å§‹ç¯å¢ƒåˆå§‹åŒ–...")

        success = True

        # 1. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
        if 'virtual_env' in issues:
            print(f"\n1ï¸âƒ£ åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ...")
            if self._create_virtual_environment():
                print(f"   âœ… è™šæ‹Ÿç¯å¢ƒåˆ›å»ºæˆåŠŸ: .venv/")
            else:
                print(f"   âŒ è™šæ‹Ÿç¯å¢ƒåˆ›å»ºå¤±è´¥")
                success = False
                return False

        # 2. å®‰è£…ä¾èµ–
        if 'dependencies' in issues or 'virtual_env' in issues:
            print(f"\n2ï¸âƒ£ å®‰è£…è®­ç»ƒä¾èµ–...")
            if self._install_dependencies():
                print(f"   âœ… ä¾èµ–å®‰è£…å®Œæˆ")
            else:
                print(f"   âŒ ä¾èµ–å®‰è£…å¤±è´¥")
                success = False

        # 3. éªŒè¯ç¯å¢ƒ
        if success:
            print(f"\n3ï¸âƒ£ éªŒè¯ç¯å¢ƒ...")
            issues_after = self._check_environment_comprehensive()
            # å¿½ç•¥ollamaé—®é¢˜ï¼Œå› ä¸ºä¸æ˜¯å¿…éœ€çš„
            critical_issues = [i for i in issues_after if i != 'ollama']
            if not critical_issues:
                print(f"   âœ… ç¯å¢ƒéªŒè¯é€šè¿‡")
            else:
                print(f"   âš ï¸  ä»æœ‰é—®é¢˜: {', '.join(critical_issues)}")
                success = False

        # 4. Ollamaæç¤º
        if 'ollama' in issues:
            print(f"\nğŸ’¡ å…³äºOllamaæœåŠ¡ï¼š")
            print(f"   è®­ç»ƒå®Œæˆåéœ€è¦Ollamaæ¥ä½¿ç”¨æ¨¡å‹")
            print(f"   å®‰è£…æ–¹æ³•: https://ollama.com/")
            print(f"   ä¹Ÿå¯ä»¥è®­ç»ƒå®Œæˆåå†å®‰è£…")

        return success

    def _create_virtual_environment(self):
        """åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ"""
        try:
            # ä½¿ç”¨å½“å‰Pythonåˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
            result = subprocess.run([sys.executable, '-m', 'venv', '.venv'],
                                  capture_output=True, text=True, timeout=60)
            return result.returncode == 0
        except Exception as e:
            print(f"   åˆ›å»ºè™šæ‹Ÿç¯å¢ƒæ—¶å‡ºé”™: {e}")
            return False

    def _install_dependencies(self):
        """å®‰è£…ä¾èµ–"""
        try:
            # ç¡®å®špythonå¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„
            if Path('.venv').exists():
                if sys.platform == 'win32':
                    python_exe = Path('.venv/Scripts/python.exe')
                else:
                    python_exe = Path('.venv/bin/python')
            else:
                python_exe = Path(sys.executable)

            if not python_exe.exists():
                print(f"   âŒ Pythonå¯æ‰§è¡Œæ–‡ä»¶ä¸å­˜åœ¨: {python_exe}")
                return False

            # å‡çº§pip
            print(f"   ğŸ“¦ å‡çº§pipå·¥å…·...")
            result = subprocess.run([str(python_exe), '-m', 'pip', 'install', '-U', 'pip'],
                                  capture_output=True, text=True, timeout=120)

            if result.returncode != 0:
                print(f"   âš ï¸  pipå‡çº§å¤±è´¥: {result.stderr}")

            # å®‰è£…requirements.txt
            if Path('requirements.txt').exists():
                print(f"   ğŸ“¦ å®‰è£…è®­ç»ƒä¾èµ–...")
                result = subprocess.run([str(python_exe), '-m', 'pip', 'install', '-r', 'requirements.txt'],
                                      capture_output=True, text=True, timeout=300)

                if result.returncode == 0:
                    return True
                else:
                    print(f"   âŒ ä¾èµ–å®‰è£…å¤±è´¥:")
                    print(f"   {result.stderr}")

                    # æä¾›è§£å†³æ–¹æ¡ˆ
                    print(f"\n   ğŸ’¡ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
                    print(f"   1) ç½‘ç»œé—®é¢˜ - ä½¿ç”¨å›½å†…é•œåƒ:")
                    print(f"      {python_exe} -m pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -r requirements.txt")
                    print(f"   2) æ‰‹åŠ¨å®‰è£…:")
                    print(f"      {python_exe} -m pip install torch transformers peft trl datasets")
                    return False
            else:
                print(f"   âŒ requirements.txt æ–‡ä»¶ä¸å­˜åœ¨")
                return False

        except Exception as e:
            print(f"   å®‰è£…ä¾èµ–æ—¶å‡ºé”™: {e}")
            return False

    def _check_disk_usage(self):
        """æ£€æŸ¥ç£ç›˜ä½¿ç”¨æƒ…å†µ"""
        print("\nğŸ’½ ç£ç›˜ä½¿ç”¨æƒ…å†µ...")

        dirs_to_check = ['out/', 'datasets/', '.cache/']

        for dir_name in dirs_to_check:
            dir_path = Path(dir_name)
            if dir_path.exists():
                total_size = sum(f.stat().st_size for f in dir_path.rglob('*') if f.is_file())
                if total_size > 1024**3:  # > 1GB
                    size_str = f"{total_size / (1024**3):.1f} GB"
                else:
                    size_str = f"{total_size / (1024**2):.1f} MB"
                print(f"   ğŸ“ {dir_name}: {size_str}")
            else:
                print(f"   ğŸ“ {dir_name}: ä¸å­˜åœ¨")

    def _show_ollama_models(self):
        """æ˜¾ç¤ºOllamaæ¨¡å‹åˆ—è¡¨"""
        print("\nğŸ¤– Ollamaæ¨¡å‹åˆ—è¡¨:")
        try:
            result = subprocess.run(['ollama', 'list'], capture_output=True, text=True)
            if result.returncode == 0:
                print(result.stdout)
            else:
                print("âŒ æ— æ³•è·å–Ollamaæ¨¡å‹åˆ—è¡¨")
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")

    def _import_to_ollama(self):
        """å¯¼å…¥æ¨¡å‹åˆ°Ollama"""
        self._ensure_config_loaded()
        print("\nğŸš€ å¯¼å…¥æ¨¡å‹åˆ°Ollama")

        # æ‰«æå¯ç”¨çš„åˆå¹¶æ¨¡å‹
        out_dir = Path("out")
        if not out_dir.exists():
            print("âŒ outç›®å½•ä¸å­˜åœ¨ï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹")
            return

        merged_dirs = list(out_dir.glob("merged_*"))
        if not merged_dirs:
            print("âŒ æœªæ‰¾åˆ°å·²è®­ç»ƒçš„æ¨¡å‹")
            return

        print("\nğŸ“‹ å¯å¯¼å…¥çš„æ¨¡å‹:")
        for i, dir_path in enumerate(merged_dirs, 1):
            character = dir_path.name.replace("merged_", "")

            # å°è¯•ä»é…ç½®æ–‡ä»¶è·å–ä¸­æ–‡åç§°å’Œæè¿°
            char_config = self.config.get('characters', {}).get(character, {})
            chinese_name = char_config.get('name', character)  # å¦‚æœæ²¡æœ‰é…ç½®ï¼Œæ˜¾ç¤ºè‹±æ–‡å
            description = char_config.get('description', 'æœªé…ç½®')

            # æ˜¾ç¤ºï¼šåºå·) ä¸­æ–‡å (è‹±æ–‡ä»£ç ) - æè¿°
            print(f"   {i}) {chinese_name} ({character}) - {description}")

        try:
            choice = int(input(f"\nè¯·é€‰æ‹©æ¨¡å‹ (1-{len(merged_dirs)}): "))
            if 1 <= choice <= len(merged_dirs):
                selected_dir = merged_dirs[choice - 1]
                character = selected_dir.name.replace("merged_", "")

                # è·å–ä¸­æ–‡åç§°ç”¨äºç¡®è®¤
                char_config = self.config.get('characters', {}).get(character, {})
                chinese_name = char_config.get('name', character)

                print(f"\nâœ… å·²é€‰æ‹©: {chinese_name} ({character})")

                ollama_name = input(f"Ollamaæ¨¡å‹åç§° (é»˜è®¤: {character}-lora): ").strip()
                if not ollama_name:
                    ollama_name = f"{character}-lora"

                self._export_to_ollama(character, ollama_name)
        except (ValueError, IndexError):
            print("âŒ æ— æ•ˆé€‰æ‹©")

    def _delete_ollama_model(self):
        """åˆ é™¤Ollamaæ¨¡å‹"""
        print("\nğŸ—‘ï¸ åˆ é™¤Ollamaæ¨¡å‹")
        model_name = input("è¾“å…¥è¦åˆ é™¤çš„æ¨¡å‹åç§°: ").strip()

        if model_name:
            try:
                result = subprocess.run(['ollama', 'rm', model_name], capture_output=True, text=True)
                if result.returncode == 0:
                    print(f"âœ… å·²åˆ é™¤æ¨¡å‹: {model_name}")
                else:
                    print(f"âŒ åˆ é™¤å¤±è´¥: {result.stderr}")
            except Exception as e:
                print(f"âŒ é”™è¯¯: {e}")

    def _test_ollama_model(self):
        """æµ‹è¯•Ollamaæ¨¡å‹"""
        print("\nğŸ§ª æµ‹è¯•Ollamaæ¨¡å‹")

        # æ˜¾ç¤ºå¯ç”¨æ¨¡å‹
        self._show_ollama_models()

        model_name = input("\nè¾“å…¥è¦æµ‹è¯•çš„æ¨¡å‹åç§°: ").strip()
        if model_name:
            test_prompt = "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚"
            print(f"\næµ‹è¯•æç¤º: {test_prompt}")
            print("å›ç­”:")
            print("-" * 40)

            try:
                result = subprocess.run(['ollama', 'run', model_name],
                                     input=test_prompt, text=True, capture_output=True)
                if result.returncode == 0:
                    print(result.stdout)
                else:
                    print(f"âŒ æµ‹è¯•å¤±è´¥: {result.stderr}")
            except Exception as e:
                print(f"âŒ é”™è¯¯: {e}")

    def _confirm_and_train(self, character: str):
        """ç¡®è®¤å¹¶å¼€å§‹è®­ç»ƒ"""
        print(f"\nğŸ’¡ å‡†å¤‡è®­ç»ƒ '{character}'")

        # è¯¢é—®æ˜¯å¦å¯¼å‡ºåˆ°Ollama
        export_ollama = False
        ollama_name = None

        try:
            ollama_choice = input("è®­ç»ƒå®Œæˆåæ˜¯å¦å¯¼å…¥åˆ°Ollama? (y/N): ").strip().lower()
            if ollama_choice in ['y', 'yes']:
                export_ollama = True
                ollama_name = input(f"Ollamaæ¨¡å‹åç§° (é»˜è®¤: {character}-lora): ").strip()
                if not ollama_name:
                    ollama_name = f"{character}-lora"

            # ç›´æ¥è°ƒç”¨start_trainingï¼Œå®ƒä¼šè‡ªåŠ¨æ£€æµ‹å¹¶å¤„ç†å·²æœ‰è®­ç»ƒç»“æœ
            self.start_training(character, export_ollama=export_ollama, ollama_name=ollama_name)

        except (KeyboardInterrupt, EOFError):
            print("\nğŸ‘‹ è®­ç»ƒå·²å–æ¶ˆ")

    def check_existing_training(self, character: str):
        """æ£€æŸ¥æ˜¯å¦å·²æœ‰è®­ç»ƒç»“æœ"""
        lora_dir = Path(f"out/lora_{character}")
        merged_dir = Path(f"out/merged_{character}")

        result = {
            'has_lora': lora_dir.exists(),
            'has_merged': merged_dir.exists(),
            'lora_dir': lora_dir,
            'merged_dir': merged_dir
        }

        if result['has_lora'] or result['has_merged']:
            # è·å–è®­ç»ƒæ—¶é—´ä¿¡æ¯
            if result['has_lora']:
                try:
                    # æŸ¥æ‰¾æœ€æ–°çš„checkpointæ–‡ä»¶è·å–è®­ç»ƒæ—¶é—´
                    checkpoint_files = list(lora_dir.glob('checkpoint-*'))
                    if checkpoint_files:
                        latest_checkpoint = max(checkpoint_files, key=lambda x: x.stat().st_mtime)
                        result['last_checkpoint'] = latest_checkpoint.name
                        result['train_time'] = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(latest_checkpoint.stat().st_mtime))

                    # è¯»å–è®­ç»ƒå…ƒæ•°æ®
                    meta_file = lora_dir / "run_meta.json"
                    if meta_file.exists():
                        import json
                        with open(meta_file, 'r', encoding='utf-8') as f:
                            meta = json.load(f)
                            result['training_params'] = meta.get('args', {})
                            result['env_info'] = meta.get('env_plan', {})
                except Exception:
                    pass

            if result['has_merged']:
                try:
                    result['merged_time'] = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(merged_dir.stat().st_mtime))
                    # è®¡ç®—æ¨¡å‹å¤§å°
                    total_size = sum(f.stat().st_size for f in merged_dir.glob('*') if f.is_file())
                    result['merged_size'] = f"{total_size / (1024**3):.1f} GB"
                except Exception:
                    result['merged_size'] = "æœªçŸ¥"

        return result

    def backup_existing_training(self, character: str):
        """å¤‡ä»½ç°æœ‰è®­ç»ƒç»“æœ"""
        import shutil
        timestamp = time.strftime("%Y%m%d_%H%M%S")

        lora_dir = Path(f"out/lora_{character}")
        merged_dir = Path(f"out/merged_{character}")
        backup_base = f"out/backup_{character}_{timestamp}"

        backup_info = {}

        if lora_dir.exists():
            backup_lora = f"{backup_base}_lora"
            shutil.move(str(lora_dir), backup_lora)
            backup_info['lora'] = backup_lora
            print(f"   ğŸ“¦ LoRAæ¨¡å‹å·²å¤‡ä»½åˆ°: {backup_lora}")

        if merged_dir.exists():
            backup_merged = f"{backup_base}_merged"
            shutil.move(str(merged_dir), backup_merged)
            backup_info['merged'] = backup_merged
            print(f"   ğŸ“¦ åˆå¹¶æ¨¡å‹å·²å¤‡ä»½åˆ°: {backup_merged}")

        return backup_info

    def show_existing_training_info(self, character: str, existing_info: dict):
        """æ˜¾ç¤ºç°æœ‰è®­ç»ƒç»“æœä¿¡æ¯"""
        print(f"\nğŸ“‹ å‘ç° {character} çš„ç°æœ‰è®­ç»ƒç»“æœ:")
        print("=" * 50)

        if existing_info['has_lora']:
            print(f"ğŸ”§ LoRAé€‚é…å™¨: âœ… å­˜åœ¨")
            if 'train_time' in existing_info:
                print(f"   ğŸ“… è®­ç»ƒæ—¶é—´: {existing_info['train_time']}")
            if 'last_checkpoint' in existing_info:
                print(f"   ğŸ“Š æœ€æ–°æ£€æŸ¥ç‚¹: {existing_info['last_checkpoint']}")
            if 'training_params' in existing_info:
                params = existing_info['training_params']
                epochs = params.get('num_train_epochs', 'æœªçŸ¥')
                lr = params.get('learning_rate', 'æœªçŸ¥')
                print(f"   âš™ï¸  è®­ç»ƒå‚æ•°: epochs={epochs}, lr={lr}")

        if existing_info['has_merged']:
            print(f"ğŸ¤– åˆå¹¶æ¨¡å‹: âœ… å­˜åœ¨")
            if 'merged_time' in existing_info:
                print(f"   ğŸ“… åˆå¹¶æ—¶é—´: {existing_info['merged_time']}")
            if 'merged_size' in existing_info:
                print(f"   ğŸ“¦ æ¨¡å‹å¤§å°: {existing_info['merged_size']}")

    def handle_existing_training_choice(self, character: str):
        """å¤„ç†å·²æœ‰è®­ç»ƒç»“æœçš„ç”¨æˆ·é€‰æ‹©"""
        existing_info = self.check_existing_training(character)

        if not (existing_info['has_lora'] or existing_info['has_merged']):
            return None  # æ²¡æœ‰ç°æœ‰ç»“æœï¼Œæ­£å¸¸è®­ç»ƒ

        # æ˜¾ç¤ºç°æœ‰ç»“æœä¿¡æ¯
        self.show_existing_training_info(character, existing_info)

        print(f"\nğŸ¤” æ£€æµ‹åˆ°å·²æœ‰è®­ç»ƒç»“æœï¼Œè¯·é€‰æ‹©å¤„ç†æ–¹å¼:")
        print("1) ğŸ”„ é‡æ–°è®­ç»ƒ (è¦†ç›–ç°æœ‰ç»“æœ)")
        print("2) ğŸ“¦ å¤‡ä»½åé‡æ–°è®­ç»ƒ (ä¿ç•™ç°æœ‰ç»“æœ)")
        print("3) â• ç»§ç»­è®­ç»ƒ (æ–­ç‚¹ç»­è®­ï¼Œå¢åŠ æ›´å¤šepochs)")
        print("4) ğŸš« å–æ¶ˆè®­ç»ƒ")
        print()

        while True:
            try:
                choice = input("è¯·é€‰æ‹© (1-4): ").strip()

                if choice == "1":
                    print("ğŸ”„ å°†è¦†ç›–ç°æœ‰è®­ç»ƒç»“æœ...")
                    return "overwrite"

                elif choice == "2":
                    print("ğŸ“¦ å°†å¤‡ä»½ç°æœ‰ç»“æœåé‡æ–°è®­ç»ƒ...")
                    backup_info = self.backup_existing_training(character)
                    print("âœ… å¤‡ä»½å®Œæˆï¼Œå¼€å§‹é‡æ–°è®­ç»ƒ")
                    return "backup_and_retrain"

                elif choice == "3":
                    print("â• å°†ä»æœ€æ–°æ£€æŸ¥ç‚¹ç»§ç»­è®­ç»ƒ...")
                    if not existing_info['has_lora']:
                        print("âŒ æœªæ‰¾åˆ°LoRAæ£€æŸ¥ç‚¹ï¼Œæ— æ³•ç»§ç»­è®­ç»ƒ")
                        print("   å»ºè®®é€‰æ‹©é‡æ–°è®­ç»ƒ")
                        continue
                    return "resume"

                elif choice == "4":
                    print("ğŸš« è®­ç»ƒå·²å–æ¶ˆ")
                    return "cancel"

                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥1-4")

            except (KeyboardInterrupt, EOFError):
                print("\nğŸš« è®­ç»ƒå·²å–æ¶ˆ")
                return "cancel"

def main():
    parser = argparse.ArgumentParser(description="æ™ºèƒ½LoRAè®­ç»ƒè„šæœ¬")
    parser.add_argument("character", nargs="?", help="è¦è®­ç»ƒçš„è§’è‰²åç§°")
    parser.add_argument("--character", "-c", dest="character_flag", help="æŒ‡å®šè¦è®­ç»ƒçš„è§’è‰²")
    parser.add_argument("--list", "-l", action="store_true", help="åˆ—å‡ºæ‰€æœ‰å¯ç”¨é…ç½®")
    parser.add_argument("--scan", "-s", action="store_true", help="æ‰«ææ•°æ®é›†çŠ¶æ€")
    parser.add_argument("--background", "-b", action="store_true", help="åå°è®­ç»ƒæ¨¡å¼")
    parser.add_argument("--yes", "-y", action="store_true", help="è·³è¿‡ç¡®è®¤ï¼Œç›´æ¥å¼€å§‹è®­ç»ƒ")
    parser.add_argument("--cache", action="store_true", help="æ£€æŸ¥æ¨¡å‹ç¼“å­˜çŠ¶æ€")
    parser.add_argument("--menu", "-m", action="store_true", help="æ˜¾ç¤ºäº¤äº’å¼èœå•")
    parser.add_argument("--ollama", "-o", action="store_true", help="è®­ç»ƒåå¯¼å…¥åˆ°Ollama")
    parser.add_argument("--ollama_name", type=str, help="æŒ‡å®šOllamaæ¨¡å‹åç§°")

    # æ–°å¢ç¯å¢ƒç®¡ç†å‚æ•°
    parser.add_argument("--setup", action="store_true", help="ç¯å¢ƒåˆå§‹åŒ–è®¾ç½®")
    parser.add_argument("--env-check", action="store_true", help="å…¨é¢ç¯å¢ƒæ£€æŸ¥")
    parser.add_argument("--auto", action="store_true", help="è‡ªåŠ¨æ¨¡å¼ï¼Œè·³è¿‡ç”¨æˆ·ç¡®è®¤")

    args = parser.parse_args()

    trainer = SmartTrainer()

    # é¦–æ¬¡è¿è¡Œæ£€æµ‹ï¼šæ— å‚æ•°ä¸”æ— è™šæ‹Ÿç¯å¢ƒæ—¶è¿›å…¥å¼•å¯¼æ¨¡å¼
    if not any(vars(args).values()) and not Path('.venv').exists():
        print("ğŸ” æ£€æµ‹åˆ°é¦–æ¬¡è¿è¡Œ...")
        trainer.first_time_setup()
        return

    # å¤„ç†æ–°çš„ç¯å¢ƒç®¡ç†å‚æ•°
    if args.setup:
        print("ğŸ”§ ç¯å¢ƒåˆå§‹åŒ–è®¾ç½®")
        issues = trainer._check_environment_comprehensive()

        if not issues:
            print("\nâœ… ç¯å¢ƒå·²ç»å‡†å¤‡å¥½äº†ï¼")
            if not args.auto:
                cont = input("æ˜¯å¦è¿›å…¥ä¸»èœå•? (Y/n): ").strip().lower()
                if cont in ['', 'y', 'yes']:
                    trainer.show_main_menu()
        else:
            if args.auto:
                success = trainer._auto_setup_environment(issues)
                if success:
                    print("\nğŸ‰ ç¯å¢ƒå‡†å¤‡å®Œæˆï¼")
                    trainer.show_main_menu()
            else:
                confirm = input("\næ£€æµ‹åˆ°ç¯å¢ƒé—®é¢˜ï¼Œæ˜¯å¦è‡ªåŠ¨ä¿®å¤? (Y/n): ").strip().lower()
                if confirm in ['', 'y', 'yes']:
                    success = trainer._auto_setup_environment(issues)
                    if success:
                        print("\nğŸ‰ ç¯å¢ƒå‡†å¤‡å®Œæˆï¼")
                        cont = input("æ˜¯å¦è¿›å…¥ä¸»èœå•? (Y/n): ").strip().lower()
                        if cont in ['', 'y', 'yes']:
                            trainer.show_main_menu()
        return

    if args.env_check:
        trainer._comprehensive_environment_check()
        return

    # å¤„ç†å‘½ä»¤è¡Œå‚æ•°
    if args.menu:
        trainer.show_main_menu()
        return

    if args.list:
        trainer.list_configurations()
        return

    if args.scan:
        dataset_info = trainer.scan_datasets()
        print("\nğŸ“Š æ•°æ®é›†æ‰«æç»“æœ:")
        print("=" * 50)
        for char_name, info in dataset_info.items():
            print(f"\nğŸ“ {char_name}/")
            print(f"   è®­ç»ƒæ–‡ä»¶: {len(info['train_files'])}ä¸ª")
            for tf in info['train_files']:
                print(f"      ğŸ“„ {tf.name} ({trainer.count_samples(tf)}æ ·æœ¬)")
            print(f"   éªŒè¯æ–‡ä»¶: {len(info['val_files'])}ä¸ª")
            for vf in info['val_files']:
                print(f"      ğŸ“„ {vf.name} ({trainer.count_samples(vf)}æ ·æœ¬)")
        return

    if args.cache:
        trainer.check_model_cache()
        return

    # é€‰æ‹©è§’è‰²
    character = args.character or args.character_flag
    if character:
        print(f"ğŸ¯ æŒ‡å®šè§’è‰²: {character}")
    else:
        character = trainer.interactive_select()

    # æ£€æŸ¥å‰ç½®æ¡ä»¶
    if not trainer.check_prerequisites(character):
        print("\nğŸ’¡ å»ºè®®:")
        print("   1. æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨")
        print("   2. éªŒè¯JSONLæ ¼å¼æ˜¯å¦æ­£ç¡®")
        print("   3. è¿è¡Œ 'python smart_train.py --scan' æŸ¥çœ‹è¯¦ç»†çŠ¶æ€")
        sys.exit(1)

    # ç¡®è®¤è®­ç»ƒ
    if not args.yes:
        print(f"\nğŸ’¡ å³å°†å¼€å§‹è®­ç»ƒ '{character}'")
        try:
            confirm = input("ç¡®è®¤å¼€å§‹è®­ç»ƒ? (y/N): ").strip().lower()
            if confirm not in ['y', 'yes']:
                print("ğŸ‘‹ è®­ç»ƒå·²å–æ¶ˆ")
                return
        except (KeyboardInterrupt, EOFError):
            print("\nğŸ‘‹ è®­ç»ƒå·²å–æ¶ˆ")
            return
    else:
        print(f"\nğŸš€ è‡ªåŠ¨å¼€å§‹è®­ç»ƒ '{character}'")

    # å¼€å§‹è®­ç»ƒ
    trainer.start_training(character, args.background,
                          export_ollama=args.ollama,
                          ollama_name=args.ollama_name)

if __name__ == "__main__":
    main()